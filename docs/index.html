<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.20">
<meta name="author" content="System: v0.9.16 | Docbook: v0916.1.0.0 | www.kernel0.org">
<title>RK0: The Real-Time Kernel '0'</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/styles/github.min.css">
</head>
<body class="book toc2 toc-left data-line-1">
<div id="header">
<h1>RK0: The Real-Time Kernel '0'</h1>
<div class="details">
<span id="author" class="author">System: v0.9.16 | Docbook: v0916.1.0.0 | www.kernel0.org</span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#the_kernel_at_a_glance">1. THE KERNEL AT A GLANCE</a>
<ul class="sectlevel2">
<li><a href="#the_design_approach">1.1. The design approach</a>
<ul class="sectlevel3">
<li><a href="#architecture">1.1.1. Architecture</a></li>
<li><a href="#programming_with_rk0">1.1.2. Programming with RK0</a></li>
<li><a href="#suitable_applications">1.1.3. Suitable Applications</a></li>
</ul>
</li>
<li><a href="#kernel_services">1.2. Kernel Services</a></li>
</ul>
</li>
<li><a href="#task_scheduler">2. <strong>Task Scheduler</strong></a>
<ul class="sectlevel4">
<li><a href="#scheduler_design_internals">2.1. Scheduler Design Internals</a></li>
<li><a href="#scheduler_data_structures">2.2. Scheduler Data Structures</a></li>
</ul>
</li>
<li><a href="#timers_and_delays">3. Timers and Delays</a>
<ul class="sectlevel2">
<li><a href="#busy_delay">3.1. Busy delay</a></li>
<li><a href="#sleep_timers">3.2. Sleep Timers</a>
<ul class="sectlevel3">
<li><a href="#sleep_delay">3.2.1. Sleep Delay</a></li>
<li><a href="#compensated_sleep_delays">3.2.2. Compensated Sleep Delays</a>
<ul class="sectlevel4">
<li><a href="#sleeptimers">3.2.2.1. Periodic Release Sleep</a></li>
<li><a href="#sleep_until_local_anchor_base">3.2.2.2. Sleep Until (local anchor base)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#blocking_time_out">3.3. Blocking Time-out</a></li>
<li><a href="#callouttimers">3.4. Callout Timers (Application Timers)</a></li>
<li><a href="#systick">3.5. System Tick</a></li>
<li><a href="#systask">3.6. System Tasks</a></li>
</ul>
</li>
<li><a href="#memory_allocator">4. Memory Allocator</a>
<ul class="sectlevel2">
<li><a href="#how_it_works">4.1. How it works</a></li>
</ul>
</li>
<li><a href="#inter_task_communication">5. <strong><em>Inter-Task Communication</em></strong></a>
<ul class="sectlevel2">
<li><a href="#directsignals">5.1. Task Events (Task Event Flags)</a>
<ul class="sectlevel4">
<li><a href="#supervisortask">5.1.1. Usage Example: Supervisor Task</a></li>
</ul>
</li>
<li><a href="#semaphore">5.2. Semaphore</a>
<ul class="sectlevel4">
<li><a href="#counting_semaphore_and_binary_semaphores">5.2.1. Counting Semaphore and Binary Semaphores</a></li>
<li><a href="#semaphores_in_rk0">5.2.2. Semaphores in RK0</a></li>
<li><a href="#flushing">5.2.3. Flushing or Broadcast</a>
<ul class="sectlevel5">
<li><a href="#boundedbufsol">Bounded Buffer with Semaphores</a></li>
</ul>
</li>
<li><a href="#mutex">5.2.4. Mutex Semaphore (Locks)</a>
<ul class="sectlevel4">
<li><a href="#priority_inversion_and_pip">5.2.4.1. Priority Inversion and PIP</a></li>
</ul>
</li>
<li><a href="#mutexes_vs_binary_semaphores">5.2.5. Mutexes vs Binary Semaphores</a></li>
</ul>
</li>
<li><a href="#scheduler_lock">5.3. Scheduler Lock</a></li>
<li><a href="#sleep_queue">5.4. Sleep Queue</a></li>
<li><a href="#conditional_critical_regions">5.5. Conditional Critical Regions</a>
<ul class="sectlevel3">
<li><a href="#monitorinvariant">5.5.1. Monitor Invariants</a></li>
<li><a href="#signalling_discipline">5.5.2. Signalling Discipline</a></li>
<li><a href="#condition_variable_model_for_mesa_monitors">5.5.3. Condition Variable Model for (Mesa) Monitors</a>
<ul class="sectlevel4">
<li><a href="#usage_example_synchronisation_barrier">5.5.3.1. Usage Example: Synchronisation Barrier</a></li>
<li><a href="#readerswriterslock">5.5.3.2. Usage Example: Readers Writers Lock</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#message_queue">5.6. Message Queue</a>
<ul class="sectlevel3">
<li><a href="#size_of_a_message">5.6.1. Size of a Message</a></li>
<li><a href="#blocking_and_non_blocking_behaviour">5.6.2. Blocking and non-blocking behaviour</a></li>
<li><a href="#ownership_and_priority_inversion">5.6.3. Ownership and Priority Inversion</a></li>
<li><a href="#notify_callback">5.6.4. Notify callback</a></li>
<li><a href="#usage_examples">5.6.5. Usage Examples</a>
<ul class="sectlevel4">
<li><a href="#mail_queue_pattern">5.6.5.1. Mail Queue pattern</a></li>
<li><a href="#averaging_sensor_values">5.6.5.2. Averaging Sensor Values</a></li>
<li><a href="#queue_select_using_notify_callback">5.6.5.3. Queue Select using Notify Callback</a></li>
<li><a href="#synchronous_client_server_procedure_call">5.6.5.4. Synchronous Client-Server Procedure Call</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#mrm">5.7. Most-Recent Message Protocol (MRM)</a>
<ul class="sectlevel3">
<li><a href="#functional_description">5.7.1. Functional Description</a></li>
<li><a href="#mrm_control_block_configuration">5.7.2. MRM Control Block Configuration</a></li>
<li><a href="#usage_example">5.7.3. Usage Example</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#error_handling">6. <em><strong>Error Handling</strong></em></a>
<ul class="sectlevel2">
<li><a href="#fail_fast">6.1. Fail fast</a></li>
<li><a href="#stack_overflow">6.2. Stack Overflow</a></li>
<li><a href="#deadlocks">6.3. Deadlocks</a></li>
</ul>
</li>
<li><a href="#rk0_services_api">7. <em><strong>RK0 Services API</strong></em></a>
<ul class="sectlevel2">
<li><a href="#convention">7.1. Convention</a></li>
<li><a href="#return_values">7.2. Return Values</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<!-- toc disabled -->
</div>
</div>
<div class="sect1 data-line-14">
<h2 id="the_kernel_at_a_glance">1. THE KERNEL AT A GLANCE</h2>
<div class="sectionbody">
<div class="sect2 data-line-17">
<h3 id="the_design_approach">1.1. The design approach</h3>
<div class="exampleblock data-line-19">
<div class="content">
<div class="paragraph data-line-20">
<p><em>RK0 Blog</em>: <a href="https://kernel0.org/2025/05/16/about-processes-tasks-and-threads/">About Processes, Tasks and Threads</a></p>
</div>
</div>
</div>
<div class="sect3 data-line-23">
<h4 id="architecture">1.1.1. Architecture</h4>
<div class="paragraph data-line-25">
<p>The layered architecture can be split&#8201;&#8212;&#8201;roughly&#8201;&#8212;&#8201;into two: a top and a bottom layer. On the top, the <em>Executive</em> manages the resources needed by the application.</p>
</div>
<div class="paragraph data-line-27">
<p>On the bottom, the <em>Low-level Scheduler</em> works as a software extension of the CPU.</p>
</div>
<div class="paragraph data-line-29">
<p>Together, they implement the <em>Task</em> abstraction. This primitive is the <em>Concurrency Unit</em> and follows the <em>Thread</em> model. A <em>Task</em> is a <em>thread</em>.</p>
</div>
<div class="imageblock data-line-33">
<div class="content">
<img src="https://kernel0org.wordpress.com/wp-content/uploads/2026/02/layeredkernel.png" alt="layeredkernel" width="50%">
</div>
</div>
<div class="paragraph data-line-36">
<p>In systems design jargon, the Executive enforces policy (what should happen). The Low-level Scheduler provides the mechanism (how it gets done). The services are the primitives that gradually translate policy decisions into concrete actions executed by the Scheduler.</p>
</div>
<div class="paragraph data-line-39">
<p>RK0&#8217;s goal is determinism on low-end devices. Its multitasking engine does not split user space from kernel space.
Tasks execute in privileged mode and use a dedicated process stack pointer, distinct from the system stack. The rationale:</p>
</div>
<div class="ulist data-line-42">
<ul>
<li class="data-line-42">
<p>Application tasks are not unknown entities at run time.</p>
</li>
<li class="data-line-44">
<p>Implementing system calls as traps either forces a non-preemptive kernel, or increases complexity in critical paths, degrading determinism.</p>
</li>
<li class="data-line-46">
<p>Relying on the ARMv6/7-M MPU decreases memory usage efficiency and introduces latency on control paths. It does not fit RK0’s deterministic execution model.</p>
</li>
</ul>
</div>
</div>
<div class="sect3 data-line-49">
<h4 id="programming_with_rk0">1.1.2. Programming with RK0</h4>
<div class="paragraph data-line-51">
<p>RK0 is designed so that it does not get in the programmer’s way.</p>
</div>
<div class="paragraph data-line-53">
<p>It aims to be transparent, composable, deterministic, and with clear semantics.</p>
</div>
<div class="paragraph data-line-55">
<p>Transparent means that the kernel does not hide its primitives behind opaque pointers nor introduce unexpected side effects.</p>
</div>
<div class="paragraph data-line-57">
<p>Its components are composable because each feature is self-contained yet designed to work with others.</p>
</div>
<div class="paragraph data-line-59">
<p>Clear semantics means mechanisms behave as expected across different usage patterns.</p>
</div>
<div class="paragraph data-line-61">
<p>Determinism is pursued by avoiding execution paths whose worst case cannot be bounded or reasoned about in advance.</p>
</div>
<div class="paragraph data-line-63">
<p>When possible, operations are O(1), rely on word-aligned memory, and use static allocation.</p>
</div>
<div class="paragraph data-line-65">
<p>When dynamic allocation is unavoidable, its worst-case behaviour can still be characterised offline (unless the application itself prevents any meaningful offline bound).</p>
</div>
</div>
<div class="sect3 data-line-67">
<h4 id="suitable_applications">1.1.3. Suitable Applications</h4>
<div class="paragraph data-line-70">
<p>Given the architecture, <em>RK0</em> targets applications with the following characteristics:</p>
</div>
<div class="olist arabic data-line-72">
<ol class="arabic">
<li class="data-line-72">
<p>They are designed to handle particular devices in which real-time responsiveness is imperative.</p>
</li>
<li class="data-line-73">
<p>Applications and middleware may be implemented alongside appropriate drivers.</p>
</li>
<li class="data-line-74">
<p>Drivers may even include the application itself.</p>
</li>
<li class="data-line-75">
<p><em>Untested programs are not loaded</em>: After the software has been tested, it can be assumed reliable.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2 data-line-77">
<h3 id="kernel_services">1.2. Kernel Services</h3>
<div class="paragraph data-line-79">
<p><em>RK0</em> has <em>Core Services</em> (always enabled) and optional services (enabled by configuration).</p>
</div>
<div class="paragraph data-line-81">
<p><em>Core Services</em>:</p>
</div>
<div class="ulist data-line-83">
<ul>
<li class="data-line-83">
<p>Scheduler</p>
</li>
<li class="data-line-84">
<p>Partition Memory Allocator</p>
</li>
<li class="data-line-85">
<p>Timer Delays</p>
</li>
<li class="data-line-86">
<p>Task&#8217;s Event Register</p>
</li>
</ul>
</div>
<div class="paragraph data-line-88">
<p><em>Optional Services</em></p>
</div>
<div class="ulist data-line-90">
<ul>
<li class="data-line-90">
<p>Application Timer (Callouts)</p>
</li>
<li class="data-line-91">
<p>Sleep Queues</p>
</li>
<li class="data-line-92">
<p>Counting/Binary Semaphores</p>
</li>
<li class="data-line-93">
<p>Mutex Semaphores</p>
</li>
<li class="data-line-94">
<p>Message Queue (and its extension Ports)</p>
</li>
<li class="data-line-95">
<p>Most-Recent Message Protocol (MRM)</p>
</li>
</ul>
</div>
<div class="paragraph data-line-97">
<p>When compiled with only <em>Core Services</em>, one gets a functional Executive with less than ~3 KB ROM.</p>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-100">
<h2 id="task_scheduler">2. <strong>Task Scheduler</strong></h2>
<div class="sectionbody">
<div class="paragraph data-line-102">
<p><em>RK0</em> employs a priority-based preemptive scheduler, aligned with a Rate-Monotonic Assignment. Tasks are typically assigned priorities according to their request rates - i.e., tasks with shorter periods are assigned to higher priorities. The highest priority is represented by the value '0'; the lowest is represented by the value '31'.</p>
</div>
<div class="exampleblock data-line-106">
<div class="content">
<div class="paragraph data-line-107">
<p><em><strong>RK0 Blog:</strong></em>
<a href="https://kernel0.org/2025/06/08/about-real-time-tasks-responsiveness-x-throughput/">About Real-Time, Responsiveness and Throughput</a></p>
</div>
</div>
</div>
<div class="paragraph data-line-112">
<p>An essential characteristic of the scheduler is that it is a <em>preemptive run-to-completion</em> scheduler. This term, '<em>run-to-completion</em>' has slightly different meanings depending on the context. It is often related to strictly cooperative schedulers, in the sense
tasks must <em>yield</em> the processor. Otherwise, they monopolise the CPU.</p>
</div>
<div class="paragraph data-line-116">
<p>The Ready Queue table is an array of queues, which the index represents the
priority</p>
</div>
<div class="listingblock data-line-119">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Ready Table

[][]...[] | Ready Tasks with Priority 31
[][]...[]
[][]...[]
     .
     .
     .
[][]...[] | Ready Tasks with Priority 0</code></pre>
</div>
</div>
<div class="paragraph data-line-131">
<p>In <em>RK0</em>, tasks with the same priority work cooperatively. This is different from schedulers that employ a <em>time-slice</em> (quantum) for round-robin: after the slice expires, the task is put at the <em>tail</em> of the <em>Ready Queue</em>.</p>
</div>
<div class="paragraph data-line-133">
<p>The term <em>run-to-completion</em> here is to be interpreted as follows:</p>
</div>
<div class="ulist data-line-135">
<ul>
<li class="data-line-135">
<p>The scheduler&#8217;s behaviour is to choose the highest priority READY task to run. Always.</p>
</li>
<li class="data-line-136">
<p>The scheduler works on a First-In-First-Out discipline for tasks with the same priority.</p>
</li>
<li class="data-line-137">
<p>A task must switch to the <em>READY</em> state before being eligible for scheduling.</p>
</li>
<li class="data-line-138">
<p>A task will switch from <em>RUNNING</em> to <em>READY</em> if yielding or if being preempted by a higher priority task. Otherwise it can only go to a <em>WAITING</em> state, and eventually switch back to <em>READY</em>.</p>
</li>
<li class="data-line-139">
<p>When a task is preempted by a higher priority task, it switches from <em>RUNNING</em> to <em>READY</em> and is placed back on the <em>head</em> position of its Ready Queue. This means that it will be resumed as soon as it is the highest priority ready task again.</p>
</li>
<li class="data-line-140">
<p>On the contrary, if a task <em>yields</em>, it tells the scheduler it has completed its cycle. Then, it will be enqueued on the ready queue tail - the last queue position.</p>
</li>
<li class="data-line-141">
<p>When a task <em>waits</em> it is suspended until a condition is satisfied.</p>
</li>
<li class="data-line-142">
<p>When the condition is satisfied, it switches from <em>WAITING</em> to <em>READY</em>, and is enqueued on the tail.</p>
</li>
<li class="data-line-143">
<p>So, tasks with the same priority cooperate by either <em>yielding</em> or <em>waiting</em>.</p>
</li>
<li class="data-line-144">
<p>If a task never yields or waits, other tasks with the same or lower priority <em>will starve</em>.</p>
</li>
<li class="data-line-145">
<p>Finally, Tasks with the same priority are <em>initially</em> placed on the <em>Ready Queue</em> associated with that priority in the order they are <em>created</em>.</p>
</li>
</ul>
</div>
<div class="admonitionblock note data-line-149">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph data-line-150">
<p><em>RK0</em> can handle context-switching with an extended frame when a float-point co-processor is available. This must be informed when compiling by defining the symbol <code>__FPU_PRESENT=1</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect4 data-line-153">
<h5 id="scheduler_design_internals">2.1. Scheduler Design Internals</h5>
<div class="paragraph data-line-155">
<p>A notable scheduler characteristic is constant-time complexity (<em>O(1)</em>) with low latency. This was achieved by carefully composing the data structures and an efficient <em>'choose-next'</em> algorithm, detailed below.</p>
</div>
</div>
<div class="sect4 data-line-157">
<h5 id="scheduler_data_structures">2.2. Scheduler Data Structures</h5>
<div class="sect5 data-line-159">
<h6 id="task_control_block">Task Control Block</h6>
<div class="paragraph data-line-161">
<p>Every primitive is associated to a data structure we refer to as its <em>Control Block</em>. A Task Control Block is a record for stack, resources, and time management. The table below partially represents a Task Control Block (as this document is live, this might not reflect the exact fields of the current version).</p>
</div>
<table class="tableblock frame-all grid-all stretch data-line-164">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Task Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Task name</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Task ID</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Status</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Assigned Priority</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Effective Priority</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Saved Stack Pointer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stack Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stack Size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Event Register Control Block</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Last wake-time</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Next wake-time</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Time-out Flag</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Preemption Flag</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Owned Resources List</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting Resources List</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Timeout List Node</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCB List Node</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-185">
<p>Tasks are static&#8201;&#8212;&#8201;they are not created (or destroyed) on runtime. There is no fork or join.</p>
</div>
<div class="paragraph data-line-187">
<p>In practice, tasks are either <em>RUNNING</em> or '<em>waiting</em>' for their turn to run.</p>
</div>
<div class="imageblock data-line-190">
<div class="content">
<img src="https://kernel0org.wordpress.com/wp-content/uploads/2026/02/schdatastruct.png" alt="schdatastruct" width="90%">
</div>
</div>
<div class="paragraph data-line-193">
<p>We need to define  <em>WAITING</em> and <em>READY</em> clearly:</p>
</div>
<div class="ulist data-line-195">
<ul>
<li class="data-line-195">
<p>A <em>READY</em> task will be dispatched; therefore, switch to <em>RUNNING</em> whenever it is the highest priority <em>READY</em> task.</p>
</li>
<li class="data-line-197">
<p>A WAITING task depends on a condition—generalised as an event—to transition to the READY state.</p>
</li>
<li class="data-line-199">
<p>Events that are not strictly time-related can be bounded by an upper limit of N ticks, or can be unbounded (the task waits indefinitely, i.e. “forever”). A task may also check for an event without blocking at all, using <code>try</code> semantics.</p>
</li>
<li class="data-line-201">
<p>Logically, the <em>WAITING</em> state will assume different pseudo-states related to the kind of event that will switch a task to <em>READY</em>:</p>
</li>
<li class="data-line-203">
<p>SLEEPING: the task is either waiting for an event associated with an <code>RK_SLEEP_QUEUE</code> object, or sleeping for a given amount of time with no explicit kernel object associated. The various <code>SLEEPING_*</code> states are explained throughout this document.</p>
</li>
<li class="data-line-205">
<p>PENDING: the task has suspended itself, waiting for a combination of Event Flags on its Event Register. When this combination is satisfied, it switches to READY.</p>
</li>
<li class="data-line-207">
<p>BLOCKED: the task is blocked on a mutex or semaphore. When a token becomes available, or the mutex is unlocked, it switches to READY.</p>
</li>
<li class="data-line-209">
<p>SENDING/RECEIVING: a producer task, when blocking on a Message Passing object, switches its status to SENDING; a consumer switches to RECEIVING. When, respectively, a slot or a message becomes available, the task switches to READY.</p>
</li>
</ul>
</div>
<div class="exampleblock data-line-210">
<div class="content">
<div class="paragraph data-line-211">
<p><strong><em>The scheduler rules, not the heap.</em></strong></p>
</div>
<div class="paragraph data-line-213">
<p><em>RK0</em> tasks are static.</p>
</div>
<div class="paragraph data-line-215">
<p>It’s a design decision rooted in real-time correctness.</p>
</div>
<div class="paragraph data-line-217">
<p>Besides an application-specific system software does not need to treat tasks as 'unknown' objects.</p>
</div>
<div class="paragraph data-line-220">
<p>The wins:</p>
</div>
<div class="ulist data-line-222">
<ul>
<li class="data-line-222">
<p>A memory layout the systems programmer knows.</p>
</li>
<li class="data-line-223">
<p>No alignment traps.</p>
</li>
<li class="data-line-224">
<p>Link-time visibility:</p>
<div class="ulist data-line-225">
<ul>
<li class="data-line-225">
<p>Each task’s stack is a named symbol in the linker map.</p>
</li>
<li class="data-line-226">
<p>You can inspect and verify the memory layout before flashing.</p>
</li>
<li class="data-line-227">
<p>A simple <code>objdump</code> reveals all stack allocations — that’s peace of mind.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect5 data-line-232">
<h6 id="task_queues">Task Queues</h6>
<div class="paragraph data-line-233">
<p>The backbone of the queues where tasks will wait for their turn to run is a circular doubly linked list: removing any item from a double list takes O(1) (provided we don’t need to search the item). As the kernel knows each task’s address, adding and removing is always O(1). Singly linked lists can’t achieve O(1) for removal.</p>
</div>
</div>
<div class="sect5 data-line-235">
<h6 id="ready_queue_table">Ready Queue Table</h6>
<div class="paragraph data-line-237">
<p>Another design choice to achieve O(1) is the global ready queue, which is a table of FIFO queues—each queue dedicated to a priority—and not a single ordered queue. So, enqueuing a ready task is always O(1). Given the sorting needed, the time complexity would be O(n) if tasks were placed on a single ready queue.</p>
</div>
</div>
<div class="sect5 data-line-239">
<h6 id="waiting_queues">Waiting Queues</h6>
<div class="paragraph data-line-241">
<p>The scheduler does not have a unique waiting queue. Every kernel object that can block a task has an associated waiting queue. Because these queues are a scheduler component, <em>they follow a priority discipline</em>: the highest priority task is dequeued first, <em>always</em>.</p>
</div>
<div class="paragraph data-line-243">
<p>When an event capable of switching tasks from <em>WAITING</em> to <em>READY</em> happens, one or more tasks (depending on the mechanism) are then placed on the ready list, unique to their priority. Now, they are waiting to be picked by the scheduler—that is the definition of <em>READY</em>.</p>
</div>
</div>
<div class="sect5 data-line-245">
<h6 id="the_scheduling_algorithm">The scheduling algorithm</h6>
<div class="paragraph data-line-247">
<p>As the ready queue table is indexed by priority - the index 0 points to the queue of ready tasks with priority 0, and so forth, and there are 32 possible priorities - a 32-bit integer can represent the state of the ready queue table. It is a BITMAP:</p>
</div>
<div class="listingblock data-line-249">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">The BITMAP computation: ((1a) OR (1b)) AND (2), s.t.:

(1a) Every Time a task is readied, update: BITMAP |= (1U &lt;&lt; task-&gt;priority );
(1b) Every Time an empty READY QUEUE becomes non-empty, update: BITMAP |= (1U &lt;&lt; queueIndex)
(2): Every Time READY QUEUE becomes empty, update: BITMAP &amp;= ~(1U &lt;&lt; queueIndex);
EXAMPLE:

  Ready Queue Index :     (6)5 4 3 2 1 0
          Not empty :      1 1 1 0 0 1 0
                           -------------&gt;
                 (LOW)  Effective Priority  (HIGH)
In this case, the scenario is a system with 7 priority task levels. Queues with priorities 6, 5, 4, and 1 are not empty.</code></pre>
</div>
</div>
<div class="paragraph data-line-266">
<p>Having the Ready Queue Table bitmap, we find the highest priority non-empty task list as follows:</p>
</div>
<div class="paragraph data-line-268">
<p>(1) Isolate the <strong>rightmost</strong> '1':</p>
</div>
<div class="listingblock data-line-270">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">RBITMAP = BITMAP &amp; -BITMAP. (- is the bitwise operator for two's complement: ~BITMAP + 1) `</code></pre>
</div>
</div>
<div class="paragraph data-line-274">
<p>In this case:</p>
</div>
<div class="listingblock data-line-276">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">                           [31]       [0]  :  Bit Position
                             0...1110010   :  BITMAP
                             1...0001110   : -BITMAP
                            =============
                             0...0000010   :  RBITMAP
                                     [1]</code></pre>
</div>
</div>
<div class="paragraph data-line-286">
<p><em>The rationale here is that, for a number N, its 2’s complement -N, flips all bits - except the rightmost '1' (by adding '1') . Then, N &amp; -N results in a word with all 0-bits except for the less significant '1'.</em></p>
</div>
<div class="paragraph data-line-288">
<p>(2) Extract the <strong>rightmost '1' <em>position</em></strong>:</p>
</div>
<div class="ulist data-line-290">
<ul>
<li class="data-line-290">
<p>For ARMv7M, we benefit from the <code>CLZ</code> instruction to count the <em>leading zeroes</em>. As they are the number of zeroes on the left of the rightmost bit, '1', this value is subtracted from 31 to find the Ready Queue index.</p>
</li>
</ul>
</div>
<div class="listingblock data-line-292">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">RK_FORCE_INLINE static inline
unsigned __getReadyPrio(unsigned readyQBitmap)
{
    unsigned ret;
    __ASM volatile (
        "clz    %0, %1     \n"
        "neg    %0, %0     \n"
        "add    %0, %0, #31\n"
        : "=&amp;r" (ret)
        : "r" (readyQBitmap)
        :
    );
    return (ret);
}</code></pre>
</div>
</div>
<div class="paragraph data-line-309">
<p>This instruction would return #30, and #31 - #30 = #01 in the example above.</p>
</div>
<div class="ulist data-line-312">
<ul>
<li class="data-line-312">
<p>For ARMv6M there is no suitable hardware instruction. The algorithm is written in C and counts the <em>trailing zeroes</em>, thus, the index number. Although it might vary depending on your compiler settings, it takes ~11 cycles (<em>note it is still O(1)</em>):</p>
</li>
</ul>
</div>
<div class="listingblock data-line-315">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/*
  De Brujin's multiply+LUT
  (Hacker's Delight book)
*/

/* table is on a ram section  for efficiency */
RK_SECTION(getReadyTable)
const static unsigned readyPrioTbl[32] =
{
 0, 1, 28, 2, 29, 14, 24, 3, 30, 22, 20, 15, 25, 17, 4, 8,
 31, 27, 13, 23, 21, 19, 16, 7, 26, 12, 18, 6, 11, 5, 10, 9
};

RK_FORCE_INLINE static inline
unsigned __getReadyPrio(unsigned readyQBitmap)
{
    unsigned mult = readyQBitmap * 0x077CB531U;

    /* Shift right the top 5 bits
     */
    unsigned idx = (mult &gt;&gt; 27);

    /* LUT */
    unsigned ret = (unsigned)readyPrioTbl[idx];
    return (ret);
}</code></pre>
</div>
</div>
<div class="paragraph data-line-344">
<p>For the example above, <code>mult = 0x2 * 0x077CB531 = 0x0EF96A62</code>. The 5 leftmost bits (the index) are <code>00001</code> &#8594; <code>table[1] = 1</code>.</p>
</div>
<div class="paragraph data-line-346">
<p>During a context switch, the procedures to find the highest priority non-empty ready queue table index are as follows:</p>
</div>
<div class="listingblock data-line-348">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">static inline RK_PRIO kCalcNextTaskPrio_(VOID)
{
    if (readyQBitMask == 0U)
    {
        return (idleTaskPrio);
    }
    readyQRightMask = readyQBitMask &amp; -readyQBitMask;
    RK_PRIO prioVal = (RK_PRIO) (__getReadyPrio(readyQRightMask));
    return (prioVal);
}

VOID kSwtch(VOID)
{
    /* O(1) complexity */
	nextTaskPrio = kCalcNextTaskPrio_();

	RK_TCB* nextRunPtr = NULL;

	/* O(1) complexity */
	kTCBQDeq(&amp;readyQueue[nextTaskPrio], &amp;nextRunPtr);

	runPtr = nextRunPtr;

}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-378">
<h2 id="timers_and_delays">3. Timers and Delays</h2>
<div class="sectionbody">
<div class="sect2 data-line-380">
<h3 id="busy_delay">3.1. Busy delay</h3>
<div class="paragraph data-line-382">
<p>A busy-wait delay <code>kBusyDelay(t)</code> keeps a task spinning for <code>t</code> ticks. That is, the task does nothing but does not suspend or yield (but can be preempted). This service finds its use when simulating workloads.</p>
</div>
<div class="admonitionblock tip data-line-385">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-387">
<p>Context switching is probably the most significant overhead on a kernel. The time spent on the System Tick handler contributes to much of this overhead.</p>
</div>
<div class="paragraph data-line-389">
<p>Design Choice:</p>
</div>
<div class="ulist data-line-391">
<ul>
<li class="data-line-391">
<p>Timers are kept on a single list; only the head element needs to be updated using a delta-queue approach.</p>
</li>
<li class="data-line-393">
<p>Application Timers that trigger callbacks are run on a deferred, non-preemptible system task.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-395">
<p>Benefits:</p>
</div>
<div class="ulist data-line-397">
<ul>
<li class="data-line-397">
<p>Keep the overhead of updating timers as minimal as possible with the delta queue;</p>
</li>
<li class="data-line-399">
<p>Deferring the Application Timer to a high-priority, non-preemptible system task meet the requested callback period while keeping the ability to track system ticks.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<table class="tableblock frame-all grid-all stretch data-line-404">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Timeout Node</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Timeout Type</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Absolute Interval (Ticks)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Relative Interval (Ticks)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting Queue Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Next Timeout Node</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Previous Timeout Node</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-414">
<p>Every task is prone to events triggered by timers described in this section. Every Task Control Block has a node to <em>a timeout list</em>.
This list is doubly linked treated a delta-sequence.</p>
</div>
<div class="paragraph data-line-417">
<p>A set <code>T<sub>set</sub>  = {(T1,8), (T2,6), (T3,10)}</code> will be started at a relative time <code>0</code> as a sequence <code>T<sub>seq</sub>  = &lt;(T2,6), (T1,2), (T3,2)&gt;</code>.</p>
</div>
<div class="paragraph data-line-419">
<p>Thus, for every system tick, only the head element on the list needs to be decreased&#8201;&#8212;&#8201;yielding O(1) on <em>decreasing</em>, that happens on the Hardware interrupt for the <em>System Tick</em>.</p>
</div>
<div class="paragraph data-line-421">
<p>The ordering for the delta-queue is not O(1), it is O(n).  A decrease happens on every SysTick interrupt; and the ordering happens only when adding a new node  to the list.</p>
</div>
</div>
<div class="sect2 data-line-423">
<h3 id="sleep_timers">3.2. Sleep Timers</h3>
<div class="paragraph data-line-425">
<p>There are three <code>sleep</code> primitives in RK0&#8201;&#8212;&#8201;they behave differently.</p>
</div>
<div class="sect3 data-line-427">
<h4 id="sleep_delay">3.2.1. Sleep Delay</h4>
<div class="paragraph data-line-428">
<p>The <code>sleepdelay()</code> (aliased as <code>sleep()</code>) puts a  task to sleep for the exact number of <code>t</code> ticks on every call&#8201;&#8212;&#8201;no matter when the last call has happened.</p>
</div>
<div class="paragraph data-line-430">
<p><em>Example</em>:</p>
</div>
<div class="listingblock data-line-431">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">VOID Task1(VOID* args)
{
    RK_UNUSEARGS
    UINT count = 0;
    while (1)
    {

        logPost("Task1: sleep");
        kSleep(300);
        /* wake here */
        count += 1U;
        if (count &gt;= 5)
        {
            kDelay(25); /* spin */
            count=0;
            /* every 5 activations there will be a drift */
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph data-line-452">
<p>Output:</p>
</div>
<div class="listingblock data-line-453">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">0 ms :: Task1: sleep
300 ms :: Task1: sleep  &lt;-- +300
600 ms :: Task1: sleep  &lt;-- +300
900 ms :: Task1: sleep  &lt;-- +300
1200 ms :: Task1: sleep &lt;-- +300
1525 ms :: Task1: sleep &lt;-- +325
1825 ms :: Task1: sleep &lt;-- +300
2125 ms :: Task1: sleep &lt;-- +300
2425 ms :: Task1: sleep
2725 ms :: Task1: sleep
3050 ms :: Task1: sleep
3350 ms :: Task1: sleep
3650 ms :: Task1: sleep
3950 ms :: Task1: sleep
4250 ms :: Task1: sleep
4575 ms :: Task1: sleep</code></pre>
</div>
</div>
</div>
<div class="sect3 data-line-472">
<h4 id="compensated_sleep_delays">3.2.2. Compensated Sleep Delays</h4>
<div class="paragraph data-line-474">
<p>These are suspensions that recompute the time considering the drift between calls. They are typically used to create periodic tasks with explicit periods.
The general pattern is:</p>
</div>
<div class="listingblock data-line-477">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">VOID Task(VOID *args)
{
    &lt;initialisation&gt;

    while(1)
    {
        &lt;periodic code&gt;; /* this has an execution time */
        scheduleNext(PERIOD); /* cycle is finished: compute delay to keep PERIOD */
    }
}</code></pre>
</div>
</div>
<div class="paragraph data-line-489">
<p>The RMS algorithm considers all tasks have a common phase grid, that is when they are made READY, or are eligible to be scheduled.
This means that from the very first activation, the time elapsed is already take into account to when the next release should happen.</p>
</div>
<div class="paragraph data-line-492">
<p>Nevertheless, it is common for kernels to provide sleep primitives that take into account a local anchor time normally set on the <code>&lt;initialisation&gt;</code> code&#8201;&#8212;&#8201;and will work as <code>waitUntil(&amp;anchor, PERIOD)</code>. RK0 provides both, and they suit different cases, as exposed below.</p>
</div>
<div class="sect4 data-line-496">
<h5 id="sleeptimers">3.2.2.1. Periodic Release Sleep</h5>
<div class="paragraph data-line-498">
<p><code>sleeprelease(P)</code> is used to delay a task so it is released on periodic rate.
The sleep time is recalculated by the kernel on every call.</p>
</div>
<div class="paragraph data-line-501">
<p>If the task wakes late by <code>N</code> ticks with <code>0 &lt; N &lt; P</code>, the kernel compensates by scheduling the next wake earlier (shortening the next sleep) so that over two periods the phase is preserved:</p>
</div>
<div class="paragraph data-line-503">
<p>Say a task is expected to return from its <code>k<sub>eth</sub></code> sleep at <code>T<sub>k+1</sub> = T<sub>k</sub> + P [ticks]</code>. If the task is resumed at <code>T<sub>k+1</sub> = T<sub>k</sub> + P + N</code>, upon detecting this drift, the kernel sets: <code>(T<sub>k+2</sub> = T<sub>k+1</sub> + P - N)</code> for <code>N &lt; P</code>.</p>
</div>
<div class="paragraph data-line-505">
<p>This can be rewritten as:</p>
</div>
<div class="paragraph data-line-507">
<p><code>(T<sub>k+2</sub> = T<sub>k</sub> + P + N + P - N) &#8592;&#8594;
(T<sub>k+2</sub> - T<sub>k</sub> = 2P)</code></p>
</div>
<div class="paragraph data-line-510">
<p><em>Example:</em></p>
</div>
<div class="listingblock data-line-512">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">VOID Task1(VOID* args)
{
    RK_UNUSEARGS
    UINT count = 0;
    while (1)
    {

       logPost("Task1 released.");

        count += 1U;
        if (count &gt;= 5)
        {
            kDelay(25); /* spin */
            count=0;
        }

        kSleepRelease(300); /*P=300 ticks; tick=1ms*/


    }
}</code></pre>
</div>
</div>
<div class="paragraph data-line-537">
<p>Output:</p>
</div>
<div class="listingblock data-line-539">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">.
.

/* R is release time */

1200 ms :: Task1: sleep periodic (R==4P)        (n)
1525 ms :: Task1: sleep periodic (5P&lt;R&lt;6P)       |
1800 ms :: Task1: sleep periodic (6P)            |
2100 ms :: Task1: sleep periodic (7P)            |
2400 ms :: Task1: sleep periodic (8P)            |
2700 ms :: Task1: sleep periodic (9P)            |
3025 ms :: Task1: sleep periodic (10P&lt;R&lt;11P)     |
3300 ms :: Task1: sleep periodic (11P)           |
3600 ms :: Task1: sleep periodic (12P)           |
3900 ms :: Task1: sleep periodic (13P)           |
4200 ms :: Task1: sleep periodic (14P)           |
4525 ms :: Task1: sleep periodic (15P&lt;R&lt;16P)     |
4800 ms :: Task1: sleep periodic (16P)          (m)  m-n=12
.                                              -----
.                                           Phase=3600=12xP
.</code></pre>
</div>
</div>
<div class="paragraph data-line-564">
<p>This mechanism is phase-locked. When the lateness is greater or equal to <code>P</code> it <em>skips</em> one or more releases to stay locked to the phase grid. In some sense, the <code>period</code> value can be seen as a <em>deadline</em>&#8201;&#8212;&#8201;if not met, the scheduler rejects to run on that activation.</p>
</div>
<div class="paragraph data-line-566">
<p><code>sleeprelease()</code> makes easier to perform worst-response time analysis on periodic tasks.</p>
</div>
<div class="admonitionblock important data-line-569">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
A set of periodic tasks must have priorities assigned properly (highest request rate, highest priority&#8201;&#8212;&#8201;the lower the period, the higher the priority). For <code>sleeprelease()</code> this is mandatory given the common phase grid.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4 data-line-572">
<h5 id="sleep_until_local_anchor_base">3.2.2.2. Sleep Until (local anchor base)</h5>
<div class="paragraph data-line-574">
<p><code>sleepuntil(anchor, period)</code> is somehow similar to <code>sleeprelease()</code>, but differs in two important aspects:</p>
</div>
<div class="ulist data-line-576">
<ul>
<li class="data-line-576">
<p>The reference used to calculate how long to suspend to keep its rate is local to each task. It means the time before the first time the task is dispatched is dismissed.</p>
</li>
<li class="data-line-578">
<p>A late release longer than 1 period will return and run immediately. It prioritises execution count within a time-window - not the phase across releases.</p>
</li>
</ul>
</div>
<hr>
<div class="paragraph data-line-582">
<p>The snippet belows clearly demonstrates how each mechanism handles lateness that are longer than 1 period:</p>
</div>
<div class="listingblock data-line-584">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">/* Every 3rd call both tasks will add up a delay longer than the task's period */

VOID HTask(VOID* args) /* higher priority: Period is 300 ticks */
{
    RK_UNUSEARGS
    UINT count = 0;
    while (1)
    {

        logPost("Higher: begin\r\n");
        /* wake here */
        count += 1U;
        kDelay(5);
        if (count &gt;= 3)
        {
            kSleep(400); /* suspend */
            count=0;
        }
        logPost("Higher: end\r\n");
        kSleepRelease(300);

    }
}


VOID LTask(VOID *args) /* lower priority: Period is 400 ticks */
{
    RK_UNUSEARGS
    RK_TICK anchor = kTickGet();
    UINT count=0;
    while (1)
    {

        logPost("Lower: begin\r\n");
        /* wake here */
        count += 1U;
        kDelay(5);
        if (count &gt;= 3)
        {
            kSleep(500);
            count=0;
        }
        logPost("Lower: end\r\n");
        kSleepUntil(&amp;anchor, 400);
    }
}</code></pre>
</div>
</div>
<div class="paragraph data-line-633">
<p>Output:</p>
</div>
<div class="listingblock data-line-634">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">       0 ms :: Higher: begin
       5 ms :: Higher: end
       5 ms :: Lower: begin
      10 ms :: Lower: end
     300 ms :: Higher: begin
     305 ms :: Higher: end
     405 ms :: Lower: begin
     410 ms :: Lower: end

    /* H 3rd run, expected next at 900ms */
     600 ms :: Higher: begin


   /* L 3rd run, expected next at 1205 ms */
     805 ms :: Lower: begin

    /* H Drift: 1005ms - 600ms = 405 ms &gt; 300ms */
    1005 ms :: Higher end

    /* H released again @ next multiple of 300. */
    1200 ms :: Higher: begin
    1205 ms :: Higher: end

   /* L Drift: 1310ms - 805ms = 505 ms &gt; 400ms */
    1310 ms :: Lower: end
    /* it runs again  immediately */
    1310 ms :: Lower: begin</code></pre>
</div>
</div>
<hr>
<div class="admonitionblock tip data-line-665">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
One normally does not write a code with periodic tasks expecting they will
not keep their rate. But on the field a transient overload might cause it to
happen. If it does, you choose the policy that is best-fit for your task: preserve phase (skip) or preserve execution count.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect2 data-line-670">
<h3 id="blocking_time_out">3.3. Blocking Time-out</h3>
<div class="paragraph data-line-672">
<p>These are internal timers associated with kernel calls that are blocking. Thus, establishing an upper-bound waiting time might benefit them. When the time for unblocking is up, the kernel call returns, indicating a timeout. This value is passed as a number of ticks.</p>
</div>
<div class="paragraph data-line-674">
<p>When blocking is associated with a kernel object (other than the Task Control Block), the timeout node will store the object waiting for queue&#8217;s address, so it can be removed if time expires.</p>
</div>
<div class="paragraph data-line-676">
<p>A kernel call is made non-blocking, that is <em>try semantics</em>, by assigning the value <code>RK_NO_WAIT</code>, the function returns immediately if unsuccessful.
The value <code>RK_WAIT_FOREVER</code> suspends a task indefinitely until the condition is satisfied.
Timeout values above <code>RK_MAX_PERIOD</code> are invalid.</p>
</div>
<div class="paragraph data-line-680">
<p>In practice, we often block either using <code>RK_WAIT_FOREVER</code> or do not block (<em>try semantics</em>, <code>RK_NO_WAIT</code>).</p>
</div>
<div class="paragraph data-line-682">
<p>Use a bounded timeout only when you expect occasional misses and you know how to handle them.</p>
</div>
<div class="admonitionblock caution data-line-685">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<div class="paragraph data-line-686">
<p>Importantly, <em>an ISR shall <strong>never</strong> block</em>. Any blocking call from an ISR is invalid and triggers fault handling when error checking is enabled.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2 data-line-690">
<h3 id="callouttimers">3.4. Callout Timers (Application Timers)</h3>
<table class="tableblock frame-all grid-all stretch data-line-693">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Timer Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Option: Reload/One-Shot</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Phase (Initial Delay)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Callout Function Pointer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Callout Argument</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Timeout Node</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-703">
<p>These are Application Timers that will issue a callback when expiring.
In addition to a callout function, an Application Timer receives an initial phase delay and a period and can choose to run once (one-shot) or auto-reload itself.</p>
</div>
<div class="paragraph data-line-706">
<p>The callback runs within a System Task with priority 0 and is non-preemptible, which makes the scheduler prioritise it over other tasks. Callouts must be short and unblocking, as they can cause high CPU contention.</p>
</div>
<div class="paragraph data-line-708">
<p>Application Timers (with autoreload) will keep track of delays in between activations.</p>
</div>
</div>
<div class="sect2 data-line-712">
<h3 id="systick">3.5. System Tick</h3>
<div class="paragraph data-line-714">
<p>A dedicated peripheral that generates an interrupt after a defined period provides the kernel time reference. For ARMv6/7M, this peripheral is the built-in SysTick, a 24-bit counter timer.
The handler performs some housekeeping on every tick and assesses the need to call a context switch.</p>
</div>
<div class="paragraph data-line-717">
<p>The 'housekeeping' accounts for global timer tracking and any tick-dependent condition that might change a task status.
When a timer expires, it may switch a task from <code>WAITING</code> to <code>READY</code> or schedule a callback. For callbacks, execution is deferred to the <code>PostProcSysTask</code> system task, where callbacks run and timer state is updated.</p>
</div>
<div class="paragraph data-line-720">
<p>Note that tasks might switch from <code>WAITING</code> to <code>READY</code> for reasons other than tick-related. In these cases, context switching might be triggered immediately if the readied task can preempt the running task.</p>
</div>
</div>
<div class="sect2 data-line-723">
<h3 id="systask">3.6. System Tasks</h3>
<div class="paragraph data-line-725">
<p>There are two <em>System Tasks</em>: the <em>Idle Task</em> and the <em>PostProcSysTask</em>.</p>
</div>
<div class="paragraph data-line-727">
<p>The <em>PostProcSysTask</em> is currently used for timer callouts.
Nominally its priority is <code>0</code>, but in practice it can be seen as priority <code>-1</code>, because it always takes precedence over user tasks with priority <code>0</code>. <em>It cannot be preempted</em> by user tasks, so timer callouts must be short. If an application timer callback needs heavier processing than a simple time-mark, use a periodic task with <code>kSleepPeriodic()</code> and defer that work.</p>
</div>
<div class="paragraph data-line-730">
<p>The <em>Idle Task</em> runs whenever there is no other ready task to be dispatched. The CPU enters on <em>low-power</em>. The kernel assigns the <em>Idle Task</em> priority during initialisation, taking into account all priorities the user has defined. Unless user tasks occupy all 32 priorities, the Idle Task is treated as an ordinary lowest priority and has a position in the ready queue table. Otherwise, it is selected if <em>Ready Queue Bitmap</em> is <code>0x00000000</code>.</p>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-735">
<h2 id="memory_allocator">4. Memory Allocator</h2>
<div class="sectionbody">
<table class="tableblock frame-all grid-all stretch data-line-738">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Memory Allocator Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Associated Block Pool</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of Blocks</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Block Size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of Free Blocks</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Free Block List</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-747">
<p>The standard C library <code>malloc()</code>  leads to fragmentation and (also, because of that) is highly indeterministic. Unless we use it once - to allocate memory before starting up, it doesn’t fit. But often, we need to 'multiplex' memory amongst tasks over time, that is, to dynamically allocate and deallocate.</p>
</div>
<div class="paragraph data-line-749">
<p>To avoid fragmentation, we use fixed-size memory blocks. A simple approach would be a static table marking each block as free or taken. With this pattern, you will need to 'search' for the next available block, if any - the time for searching changes - bounding this search to a maximum number of blocks, or <em>O(n)</em>.
To optimise, an approach is to keep track of what is free using a dynamic table—a linked list of addresses. Now we have <em>O(1)</em>.</p>
</div>
<div class="paragraph data-line-752">
<p>We use "meta-data" to initialise the linked list. Every address holds the "next" address value. All addresses are within the range of a pool of fixed-size blocks.
This approach limits the minimal size of a block to the size of a memory address—32 bits for our supported architecture.</p>
</div>
<div class="paragraph data-line-755">
<p>Yet, this is the cheapest way to store meta-data. If not stored on the empty address itself, an extra 32-bit variable would be needed for each block, so it could have a size of less than 32 bits.</p>
</div>
<div class="admonitionblock tip data-line-758">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-759">
<p>Allocating memory at runtime is a major source of latency (1), indeterministic (2) behaviour, and footprint overhead (3).</p>
</div>
<div class="paragraph data-line-761">
<p>Design choice: the allocator&#8217;s design achieves low-cost, deterministic, fragmentation-free memory management by using fixed-size word-aligned block sizes (1)(2) and embedding metadata within the memory blocks themselves (3).</p>
</div>
<div class="paragraph data-line-763">
<p>Benefits: Run-time memory allocation benefits have no real-time drawbacks.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note data-line-768">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The kernel will always round up the block size to the next multiple of 4. Say the user creates a memory pool, assigning blocks to be 6-byte wide; they will turn into 8-byte blocks.
</td>
</tr>
</table>
</div>
<div class="sect2 data-line-770">
<h3 id="how_it_works">4.1. How it works</h3>
<div class="paragraph data-line-772">
<p>When a routine calls <code>alloc()</code>, the address to be returned is the one a "free list" is pointing to, say <code>addr1</code>. Before returning <code>addr1</code> to the caller, we update the free list to point to the value stored within <code>addr1</code> - say <code>addr8</code> at that moment.</p>
</div>
<div class="paragraph data-line-774">
<p>When a routine calls <code>free(addr1)</code>, we overwrite whatever has been written in addr1 with the value-free list point to (if no more <code>alloc()</code> were issued, it would still be <code>addr8</code>), and <code>addr1</code> becomes the free list head again.</p>
</div>
<div class="paragraph data-line-776">
<p>Allocating and deallocating fixed-size blocks using this structure and storing meta-data this way is as deterministic (<em>O(1)</em>) and economical as we can get for dynamic memory allocation.</p>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-780">
<h2 id="inter_task_communication">5. <strong><em>Inter-Task Communication</em></strong></h2>
<div class="sectionbody">
<div class="exampleblock data-line-782">
<div class="content">
<div class="paragraph data-line-783">
<p>RK0 Blog:</p>
</div>
<div class="ulist data-line-785">
<ul>
<li class="data-line-785">
<p><a href="https://kernel0.org/2025/01/08/inter-task-communication-on-embedded-operating-systems/">About Inter-Task Communication - Part 1</a></p>
</li>
<li class="data-line-787">
<p><a href="https://kernel0.org/2025/01/09/about-inter-task-communication-p2/">About Inter-Task Communication - Part 2</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph data-line-792">
<p>Inter-Task Communication (ITC) refers to the mechanisms that enable tasks to coordinate/cooperate/synchronise by means of sending or receiving information that falls into two logical categories: <em>Signals</em> or <em>Messages</em>.</p>
</div>
<div class="ulist data-line-794">
<ul>
<li class="data-line-794">
<p><strong><em>Signals</em></strong>: A <em>Signal is either present or absent</em>. Its meaning is implicit.</p>
</li>
<li class="data-line-796">
<p><strong><em>Messages</em></strong>: A <em>Message</em> is a means of coordinating and exchanging information altogether. Different from a <em>Signal</em>, a Message needs to be parsed (interpreted).</p>
</li>
</ul>
</div>
<div class="sect2 data-line-799">
<h3 id="directsignals">5.1. Task Events (Task Event Flags)</h3>
<table class="tableblock frame-all grid-all stretch data-line-802">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Within Task Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Event Register (32 flags)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Required Signal Flags</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Options (ALL/ANY)</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-809">
<p>Each Task Control Block stores a 32-bit event register (one event per bit). A set bit means an event is pending.</p>
</div>
<div class="paragraph data-line-811">
<p>The API is bit-mask oriented:</p>
</div>
<div class="ulist data-line-813">
<ul>
<li class="data-line-813">
<p><code>kTaskEventSet(task, mask)</code> posts flags with OR semantics.</p>
</li>
<li class="data-line-814">
<p><code>kTaskEventGet(required, RK_EVENT_ANY|RK_EVENT_ALL, &amp;got, timeout)</code> waits until the required pattern is met.</p>
</li>
<li class="data-line-815">
<p><code>kTaskEventQuery(task, &amp;flags)</code> reads current flags.</p>
</li>
<li class="data-line-816">
<p><code>kTaskEventClear(task, mask)</code> clears selected flags.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-818">
<p>If the required pattern is not met, the task can block (logical state: <code>SLEEPING_EVENT</code>) until timeout or until another task posts matching flags.</p>
</div>
<div class="paragraph data-line-820">
<p>On successful <code>get()</code>, the matched required positions are cleared from the task event register.</p>
</div>
<div class="paragraph data-line-822">
<p><code>0x00</code> is invalid as a <code>set()</code> mask and as <code>required</code> for <code>get()</code>.</p>
</div>
<div class="sect4 data-line-826">
<h5 id="supervisortask">5.1.1. Usage Example: Supervisor Task</h5>
<div class="paragraph data-line-829">
<p>One common pattern is to start each loop by checking pending events. In a supervisor task, this becomes an event hub.</p>
</div>
<div class="listingblock data-line-831">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* events */
#define CO2_HIGH_EVENT           RK_EVENT_01
#define O2_LOW_EVENT             RK_EVENT_02
#define HUM_HIGH_EVENT           RK_EVENT_03
#define TEMP_HIG_EVENT           RK_EVENT_04



/* task handles */
#define TEMPERATURE_TASK         tempCtl
#define PRESSURE_TASK            pressCt
#define HUM_TASK                 humCtl


VOID SupervisorTask(VOID *args)
{
    RK_UNUSEARGS;

    while(1)

    {
        ULONG gotFlags = 0UL;

        RK_ERR err = kTaskEventGet(0xFFFF,
                                 RK_FLAGS_ANY,
                                 &amp;gotFlags,
                                 SUPERVISOR_T_PERIOD);

        if (err == RK_ERR_SUCCESS &amp;&amp; gotFlags != 0)
        {
                switch (gotFlags)
                {

                  /* map  events combination to signal handlers */



                }
            }
        }

        /* if there is anything to do if time out */
    }
}</code></pre>
</div>
</div>
<div class="paragraph data-line-879">
<p>Task Events are the only ITC primitive that cannot be disabled; they are a <em>Core Mechanism</em>.</p>
</div>
<div class="admonitionblock note data-line-882">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph data-line-883">
<p>RK0 does not implement BSD/UNIX-like asynchronous signals (POSIX style).</p>
</div>
<div class="paragraph data-line-885">
<p>Tasks explicitly wait (<code>get()</code>) for bit patterns, and others <code>set()</code> bit patterns, making
the scheduler aware of all blocking conditions.</p>
</div>
<div class="paragraph data-line-888">
<p>Thus, unlike traditional asynchronous signal mechanisms (as BSD/UNIX Signals), no code is ever executed at an arbitrary instruction boundary.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2 data-line-891">
<h3 id="semaphore">5.2. Semaphore</h3>
<table class="tableblock frame-all grid-all stretch data-line-893">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Semaphore Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Counter (Unsigned Integer)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum Value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting Queue</p></td>
</tr>
</tbody>
</table>
<div class="exampleblock data-line-900">
<div class="content">
<div class="paragraph data-line-901">
<p>A semaphore S is a nonnegative integer variable, apart from the operations it is subjected to. S is initialized to a nonnegative value. The two operations, called P and V, are defined as follows:</p>
</div>
<div class="paragraph data-line-903">
<p><code>P(S): if S &gt; 0 then S := S-1, else the process is suspended until S &gt; 0.</code></p>
</div>
<div class="paragraph data-line-905">
<p><code>V(S): if there are processes waiting, then one of them is resumed; else S := S+1.</code></p>
</div>
<div class="paragraph data-line-907">
<p>(Dijkstra, 1968)</p>
</div>
</div>
</div>
<div class="paragraph data-line-910">
<p><em>Semaphores</em> are <em>public</em> kernel objects for signalling and waiting on countable events.</p>
</div>
<div class="paragraph data-line-912">
<p><code>V()</code> in RK0 semaphores maps to <code>post()</code> and <code>P()</code> to <code>pend()</code>.</p>
</div>
<div class="sect4 data-line-916">
<h5 id="counting_semaphore_and_binary_semaphores">5.2.1. Counting Semaphore and Binary Semaphores</h5>
<div class="paragraph data-line-918">
<p>The typical use case for semaphores is as a "credit tracker": use <code>pend()</code> to consume a credit and <code>post()</code> to return a credit (for example, free slots in a queue). These are <em>Counting Semaphores</em>.</p>
</div>
<div class="paragraph data-line-920">
<p>A <em>Binary Semaphore</em> is a counting semaphore with maximum value <code>1</code>: the state is either available or unavailable.</p>
</div>
<div class="paragraph data-line-922">
<p>Binary semaphores are often used for task-to-task or ISR-to-task synchronisation, and sometimes for mutual exclusion (with caveats discussed later).</p>
</div>
</div>
<div class="sect4 data-line-924">
<h5 id="semaphores_in_rk0">5.2.2. Semaphores in RK0</h5>
<div class="paragraph data-line-926">
<p>To initialise a semaphore in RK0, provide two values: initial count and maximum count. When the counter is at maximum, <code>post()</code> does not increment it and returns <code>RK_ERR_SEMA_FULL</code>.</p>
</div>
<div class="paragraph data-line-928">
<p>A <em>Binary Semaphore</em> is therefore created by setting maximum count to <code>1</code>. A counting semaphore that is intended never to saturate can use <code>UINT32_MAX</code>.</p>
</div>
<div class="paragraph data-line-930">
<p>Besides <code>init()</code>, <code>post()</code>, and <code>pend()</code>, <code>query()</code> inspects current state: non-negative means current count; negative means number of tasks waiting.</p>
</div>
</div>
<div class="sect3 data-line-934">
<h4 id="flushing">5.2.3. Flushing or Broadcast</h4>
<div class="paragraph data-line-936">
<p>A <code>flush()</code> is a <em>broadcast</em> signal: it releases all tasks currently pending on the semaphore. If successful, the semaphore counter remains <code>0</code>.</p>
</div>
<div class="admonitionblock warning data-line-940">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Flushing/broadcasting must be used with care. Releasing many tasks at once can increase scheduling pressure and hurt response time.
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-942">
<p>Flushing is allowed from ISRs but you should have a good reason. Nevertheless,
they are deferred to the <em>PostProcSysTask</em> - so they will happen asynchronously.</p>
</div>
<div class="sect5 data-line-946">
<h6 id="boundedbufsol">Bounded Buffer with Semaphores</h6>
<div class="paragraph data-line-948">
<p>Items are buffered within a memory region whose capacity is <code>K</code> items.</p>
</div>
<div class="paragraph data-line-950">
<p>Thus:  <code>0  <span class="underline">&lt;</span>  (Number of Inserted) – (Number of Extracted) <span class="underline">&lt;</span>  K</code>.</p>
</div>
<div class="paragraph data-line-952">
<p>Using semaphores the pattern is as follows:</p>
</div>
<div class="olist arabic data-line-954">
<ol class="arabic">
<li class="data-line-954">
<p>A semaphore with <code>K</code> tokens to track free slots, preventing producers from proceeding when there are no free slots.</p>
</li>
<li class="data-line-955">
<p>Another semaphore, with <code>K</code> tokens, for the number of items, not allowing consumers to proceed if there are no items.</p>
</li>
<li class="data-line-956">
<p>A 1-token semaphore so only one task manipulates the buffer at a time.</p>
</li>
</ol>
</div>
<div class="listingblock data-line-959">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* a ring buffer of items */
#define BUFSIZ (K)
static ITEM_t buf[BUFSIZ]={0};
static UINT getIdx = 0U;
static UINT putIdx = 0U;
/* this indexes==0 could either mean FULL or EMPTY for a regular
circular buffer with wrap-around.
With semaphores the state is well defined.
*/

RK_SEMAPHORE  itemSema;
RK_SEMAPHORE  slotSema;
RK_SEMAPHORE  acquireSema;


VOID kApplicationInit(VOID)
{

  /*buffer is initialised empty */
    kSemaphoreInit
    (   &amp;itemSema,
        0,   /* no item  */
        K    /*max items */
    );

    kSemaphoreInit
    (   &amp;slotSema,
        K, /* K free slots */
        K  /* max slots */
    );

    /* and free */
    kSemaphoreInit
    (   &amp;acquireSema,
        1, /* free to access */
        1  /* 1 max task allowed */
    );


VOID PutItem(ITEM_t* insertItemPtr)
{
    /* wait for room */
    kSemaphorePend(&amp;slotSema, RK_WAIT_FOREVER);

    /* wait for availability */

    kSemaphorePend(&amp;acquireSema,  RK_WAIT_FOREVER);
    buf[putIdx] = *insertItemPtr;
    putIdx += 1U; putIdx %= BUFSIZ;
    /* signal availability */
    kSemaphorePost(&amp;acquireSema);

    /* signal item */
    kSemaphorePost(&amp;itemSema);
}


 VOID GetItem(ITEM_t* extractItemPtr )
{

    /* wait for an item */
    kSemaphorePend(&amp;item, RK_WAIT_FOREVER);

    /* wait for availability */
    kSemaphorePend(&amp;acquireSema,  RK_WAIT_FOREVER);

    *extractItemPtr = buf[getIdx];
    getIdx+=1U; getIdx %= BUFSIZ;

    /* signal availability */
    kSemaphorePost(&amp;acquireSema);

    /* signal room */
    kSemaphorePost(&amp;slotSema);
}</code></pre>
</div>
</div>
<hr>
<div class="paragraph data-line-1039">
<p><em>The solution above has Put() and Get() as blocking methods.</em></p>
</div>
<div class="paragraph data-line-1041">
<p><em>If the producer and the consumer run at different rates,  eventually, they will synchronise to the lowest rate.</em></p>
</div>
<div class="paragraph data-line-1043">
<p><em>The numbers below are from a run with a buffer of 32 items (integers being incremented are the produced data).</em></p>
</div>
<div class="paragraph data-line-1045">
<p><em>The producer is twice faster than the consumer. Initially at every 2 insertions there is a single remove. Eventually, the buffer is filled up, and tasks run at lockstep (put, get, put, get&#8230;&#8203;), at the consumer pace:</em></p>
</div>
<div class="listingblock data-line-1047">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Put 59 &lt;-
Put 60 &lt;-
------
Got 30 -&gt;
------
Put 61 &lt;-
Put 62 &lt;-
------
Got 31 -&gt;
------
Put 63 &lt;-
Put 64 &lt;-
--------
Got 32  | -&gt;
Put 65  . &lt;-
       &lt;x&gt;[Full Queue, Producer blocks]
Got 33  | -&gt;  [Consumer unblocks producer...]
Put 66  . &lt;-
       &lt;x&gt;[Full Queue]
Got 34  | -&gt;  [Consumer unblocks producer...]
Put 67  . &lt;-
       &lt;x&gt;[Full Queue]</code></pre>
</div>
</div>
<hr>
</div>
</div>
<div class="sect3 data-line-1077">
<h4 id="mutex">5.2.4. Mutex Semaphore (Locks)</h4>
<table class="tableblock frame-all grid-all stretch data-line-1080">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Mutex Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Locked State (Boolean)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Owner</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Protocol Flag (<code>RK_NO_INHERIT</code> / <code>RK_INHERIT</code>)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting Queue</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mutex Node (list node within the owner TCB)</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-1090">
<p>Some regions are critical and must not be executed by more than one task at once. Acquiring (<code>lock()</code>) a mutex before entering and releasing (<code>unlock()</code>) after leaving makes the region mutually exclusive.</p>
</div>
<div class="paragraph data-line-1092">
<p>A <em>Mutex</em> is a binary semaphore with ownership: once a task locks a mutex only that task can unlock it.</p>
</div>
<div class="paragraph data-line-1094">
<p>If a task tries to acquire a locked mutex, it switches to <code>BLOCKED</code> until the owner unlocks it. When released, the highest-priority waiter is dequeued first.
Unlike semaphores, unlocking by a non-owner is invalid and rejected.</p>
</div>
<div class="paragraph data-line-1097">
<p>Mutexes are only for mutual exclusion; they are not signalling primitives.</p>
</div>
<div class="paragraph data-line-1099">
<p><em>PS: RK0 mutexes are non-recursive. Re-entrant locking of the same mutex returns <code>RK_ERR_MUTEX_REC_LOCK</code> and is considered a fault.</em></p>
</div>
<hr>
<div class="sect4 data-line-1104">
<h5 id="priority_inversion_and_pip">5.2.4.1. Priority Inversion and PIP</h5>
<div class="paragraph data-line-1107">
<p>Let TH, TM, and TL be three tasks with priority high (H), medium (M) and low (L), respectively. Say TH is dispatched and blocks on a mutex that 'TL' has acquired (i.e.: <em>"TL is blocking TH</em>").</p>
</div>
<div class="paragraph data-line-1109">
<p>If 'TM' does not need the resource, it will run and preempt 'TL'. And, by transition, 'TH'.</p>
</div>
<div class="paragraph data-line-1111">
<p>From now on, 'TH' has an <em>unbounded waiting time</em> because any task with priority higher than 'L' that does not need the resource indirectly prevents it from being unblocked&#8201;&#8212;&#8201;<em>awful.</em></p>
</div>
<div class="paragraph data-line-1113">
<p>The Priority Inheritance (PI) Protocol avoids this unbounded waiting. It is characterised by an invariant, simply put:</p>
</div>
<div class="exampleblock data-line-1115">
<div class="content">
<div class="paragraph data-line-1116">
<p>PIP Invariant:
<em>At any instant a Task assumes the highest priority among  the tasks it is blocking</em>.</p>
</div>
</div>
</div>
<div class="paragraph data-line-1120">
<p>If employed on the situation described above, task TM cannot preempt TL, whose effective priority would have been raised to 'H'.</p>
</div>
<div class="paragraph data-line-1122">
<p>It is straightforward to reason about this when you consider the scenario of a single mutex.</p>
</div>
<div class="paragraph data-line-1124">
<p>When locks nest, the protocol also needs to be:</p>
</div>
<div class="ulist data-line-1126">
<ul>
<li class="data-line-1126">
<p>Transitive: if T1 blocks T2 and T2 blocks T3, the highest priority (T3) must propagate back to T1 through T2.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-1128">
<p>This is the hard part of a correct implementation: updates must preserve the invariant across changing wait chains and multiple mutexes.</p>
</div>
<div class="admonitionblock tip data-line-1131">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-1132">
<p>This blog shows an even more intricate case of priority inversion handling.</p>
</div>
<div class="paragraph data-line-1134">
<p><a href="https://kernel0.org/2026/01/12/transitive-priority-inheritance-on-mutexes/">RK0 Blog: Transitive Priority Inheritance on RK0 mutexes</a></p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-1137">
<p>Below, a PIP-only case in which locks nest:</p>
</div>
<div class="listingblock data-line-1139">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* Task1 has the Highest nominal priority */
/* Task2 has the Medium nominal priority */
/* Task3 has Lowest nominal priority */

/* Note Task3 starts as 1 and 2 are delayed */

RK_DECLARE_TASK(task1Handle, Task1, stack1, STACKSIZE)
RK_DECLARE_TASK(task2Handle, Task2, stack2, STACKSIZE)
RK_DECLARE_TASK(task3Handle, Task3, stack3, STACKSIZE)


RK_MUTEX mutexA;
RK_MUTEX mutexB;

VOID kApplicationInit(VOID)
{
	K_ASSERT(!kCreateTask(&amp;task1Handle, Task1, RK_NO_ARGS, "Task1", stack1, \
		STACKSIZE, 1, RK_PREEMPT));
	K_ASSERT(!kCreateTask(&amp;task2Handle, Task2, RK_NO_ARGS, "Task2", stack2, \
		STACKSIZE, 2, RK_PREEMPT));
	K_ASSERT(!kCreateTask(&amp;task3Handle, Task3, RK_NO_ARGS, "Task3", stack3, \
		STACKSIZE, 3, RK_PREEMPT));

/* mutexes initialised with priority inheritance enabled */
	kMutexInit(&amp;mutexA, RK_INHERIT);
	kMutexInit(&amp;mutexB, RK_INHERIT);
}



VOID Task3(VOID *args)
{
	RK_UNUSEARGS
	while (1)
	{
		printf("@ %lums: [TL] Attempting to LOCK 'A' | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);

		kMutexLock(&amp;mutexA, RK_WAIT_FOREVER);

		printf("@ %lums: [TL] LOCKED 'A' (in CS) | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);

		kDelay(60); /* &lt;-- important */

		printf("@%lums: [TL] About to UNLOCK 'A' | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);

		kMutexUnlock(&amp;mutexA);

		printf("---&gt;");
		printf("@%lums: [TL] Exit CS | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);

		kSleep(4);
	}
}

VOID Task2(VOID *args)
{
	RK_UNUSEARGS
	while (1)
	{
		kSleep(5);

		printf("@%lums: [TM] Attempting to LOCK 'B' | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);
		kMutexLock(&amp;mutexB, RK_WAIT_FOREVER);

		printf("@%lums: [TM] LOCKED 'B', now trying to LOCK 'A' | Eff: %d | Nom: %d\r\n",
			   kTickGet(), runPtr-&gt;priority, runPtr-&gt;prioNominal);
		kMutexLock(&amp;mutexA, RK_WAIT_FOREVER);

		printf("@%lums: [TM] LOCKED 'A' (in CS) | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);
		kMutexUnlock(&amp;mutexA);

		printf("@%lums: [TM] UNLOCKING 'B' | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);

		kMutexUnlock(&amp;mutexB);

		printf("---&gt;");

		printf("@%lums: [TM] Exit CS | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);
	}
}

VOID Task1(VOID *args)
{
	RK_UNUSEARGS
	while (1)
	{
		kSleep(2);

		printf("@%lums: [TH] Attempting to LOCK 'B'| Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);

		kMutexLock(&amp;mutexB, RK_WAIT_FOREVER);

		printf("@%lums: [TH] LOCKED 'B' (in CS)  | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);

		kMutexUnlock(&amp;mutexB);

		printf("---&gt;");

		printf("@%lums: [TH] Exit CS | Eff: %d | Nom: %d\r\n", kTickGet(),
			   runPtr-&gt;priority, runPtr-&gt;prioNominal);
	}
}</code></pre>
</div>
</div>
<div class="paragraph data-line-1256">
<p><em>Result and comments</em>:</p>
</div>
<div class="listingblock data-line-1259">
<div class="content">
<pre>&gt;&gt;&gt;&gt; TL locks 'A'. Higher priority tasks are sleeping. &lt;&lt;&lt;&lt;

@ 14720ms: [TL] Attempting to LOCK 'A' | Eff: 3 | Nom: 3
@ 14720ms: [TL] LOCKED 'A' (in CS) | Eff: 3 | Nom: 3

@14721ms: [TM] Attempting to LOCK 'B' | Eff: 2 | Nom: 2

&gt;&gt;&gt;&gt; TM acquires 'B' and is blocked by TL on 'A'. TL inherits TM's  priority. &lt;&lt;&lt;&lt;

@14721ms: [TM] LOCKED 'B', now trying to LOCK 'A' | Eff: 2 | Nom: 2

&gt;&gt;&gt;&gt; TH will blocked by TM on 'B': &lt;&lt;&lt;&lt;

@14722ms: [TH] Attempting to LOCK 'B'| Eff: 1 | Nom: 1

&gt;&gt;&gt;&gt; TM inherits TH's priority. TL inherits TH's priority via TM. &lt;&lt;&lt;&lt;

@14780ms: [TL] About to UNLOCK 'A' | Eff: 1 | Nom: 3

&gt;&gt;&gt;&gt; Upon unlocking 'A', TL is preempted by TM. It means TL's priority has been restored, as it is no longer blocking a higher priority task. &lt;&lt;&lt;&lt;


&gt;&gt;&gt;&gt; Now TM acquires 'A' &lt;&lt;&lt;&lt;

@14780ms: [TM] LOCKED 'A' (in CS) | Eff: 1 | Nom: 2

&gt;&gt;&gt;&gt; After releasing 'A', but before releasing 'B', TM's priority is still '1', as it is blocking TH while holding 'B'. &lt;&lt;&lt;&lt;

@14780ms: [TM] UNLOCKING 'B' | Eff: 1 | Nom: 2

&gt;&gt;&gt;&gt; Upon unlocking 'B' TM is preempted by TH. (TM's priority has been restored.) &lt;&lt;&lt;&lt;

@14780ms: [TH] LOCKED 'B' (in CS)  | Eff: 1 | Nom: 1

&gt;&gt;&gt; RESULT: even though priority inversion was enforced, tasks leave the nested lock ordered by their nominal priority. &lt;&lt;&lt;

---&gt;@14780ms: [TH] Exit CS | Eff: 1 | Nom: 1
---&gt;@14780ms: [TM] Exit CS | Eff: 2 | Nom: 2
---&gt;@14780ms: [TL] Exit CS | Eff: 3 | Nom: 3</pre>
</div>
</div>
<div class="paragraph data-line-1302">
<p>Importantly, the worst-case time is bounded by the time the lowest priority task holds a lock (60 ms in the example: 14720ms → 14780ms).</p>
</div>
<div class="paragraph data-line-1304">
<p>As for each priority update we check each waiting queue for each mutex a task owns, t he time-complexity is linear <code>O(owner*mutex)</code>. But, typically no task ever holds more than a few mutexes. Yet, one should not be encouraged to nest locks if not needed.</p>
</div>
</div>
</div>
<div class="sect3 data-line-1307">
<h4 id="mutexes_vs_binary_semaphores">5.2.5. Mutexes vs Binary Semaphores</h4>
<div class="paragraph data-line-1309">
<p>There is (or used to be) a lot of fuss about whether binary semaphores are appropriate to use as locks. As a practical guideline, if all tasks sharing the resource have the same priority, using a binary semaphore <em>can be appropriate</em>&#8201;&#8212;&#8201;because a binary semaphore is considerably faster. It all depends on the case.</p>
</div>
<div class="paragraph data-line-1311">
<p>The drawback is the lack of ownership: any task can accidentally release the resource. On a large codebase, this can become a real problem. Nonetheless, this is a problem for semaphores in general.</p>
</div>
<div class="paragraph data-line-1313">
<p>For tasks with different priorities, binary semaphores should never be considered for mutual exclusion unless priority inversion is not a problem (how?).</p>
</div>
<div class="paragraph data-line-1315">
<p>Counting semaphores initialised as 1 is too risky. Besides the priority inversion, if the count ever increases above 1, mutual exclusion is lost, and multiple tasks can enter the critical section at once.</p>
</div>
</div>
</div>
<div class="sect2 data-line-1318">
<h3 id="scheduler_lock">5.3. Scheduler Lock</h3>
<div class="paragraph data-line-1320">
<p>Often, we need a task to perform operations without being preempted. A mutex serialises access to a code region but does not prevent a task from being preempted while operating on data. Depending on the case, this can lead to inconsistent data state.</p>
</div>
<div class="paragraph data-line-1322">
<p>An aggressive way is to disable interrupts globally. For kernel services often it is the only way to keep data integrity. On the higher level it is feasible for very short operations and/or when you need to protect data from interrupts altogether.</p>
</div>
<div class="paragraph data-line-1324">
<p>A less aggressive approach is to make the task non-preemptible with <code>kSchLock()</code> before entering the critical region and <code>kSchUnlock()</code> when leaving. This way, interrupts are still being sensed, and even higher-priority tasks might switch to a ready state, but the running thread will not be preempted.</p>
</div>
<div class="paragraph data-line-1326">
<p>The priority inversion it potentially causes is bounded. If a higher-priority task is readied while the scheduler is locked, the context switch happens immediately after unlocking.</p>
</div>
<div class="paragraph data-line-1328">
<p>Note that for locking/unlocking the scheduler the global interrupts will be disabled for the time to increment/decrement a counter, therefore, if your atomic operation is as short as that (3 to 4 cycles), disabling/enabling global interrupts is a better alternative.</p>
</div>
<hr>
<div class="paragraph data-line-1331">
<p><em>To add to the discussion, when two threads need to access the same data to 'read-modify-write', a lock-free mechanism is the LDREX/STREX operations of ARMv7M (or more generally C11 atomics). They do not avoid preemptions, and particularly in ARMv7m, if the data is touched by an ISR before the store-exclusive concludes, the ownership is lost. Typically used for multi-core spin-locking.</em></p>
</div>
<hr>
</div>
<div class="sect2 data-line-1335">
<h3 id="sleep_queue">5.4. Sleep Queue</h3>
<table class="tableblock frame-all grid-all stretch data-line-1337">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Sleep Queue Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Task Waiting Queue</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-1342">
<p><code>RK_SLEEP_QUEUE</code> is a queue of tasks sleeping until explicitly woken.</p>
</div>
<div class="paragraph data-line-1344">
<p>This primitive was formerly named <code>RK_EVENT</code>. Queue names usually reflect the condition they represent (for example, <code>notFull</code>, <code>notEmpty</code>, <code>goWriters</code>, <code>goReaders</code>).</p>
</div>
<div class="paragraph data-line-1346">
<p>An <em>RK_SLEEP_QUEUE</em> is stateless: it does not record whether an event has happened. Therefore <code>kSleepQueueWait(&amp;q, timeout)</code> always attempts to sleep the caller. <code>RK_NO_WAIT</code> is effectively a no-op on this primitive.</p>
</div>
<div class="paragraph data-line-1348">
<p><code>kSleepQueueSignal(&amp;q)</code> wakes one waiter (highest priority first).</p>
</div>
<div class="paragraph data-line-1350">
<p><code>kSleepQueueWake(&amp;q, n, &amp;u)</code> wakes at most <code>n</code> waiters.</p>
</div>
<div class="paragraph data-line-1352">
<p><code>kSleepQueueFlush(&amp;q)</code> is the wake-all form (<code>n = 0</code>).</p>
</div>
<div class="paragraph data-line-1354">
<p><code>kSleepQueueQuery(&amp;q, &amp;n)</code> returns the number of waiting tasks.</p>
</div>
<div class="paragraph data-line-1356">
<p><code>kSleepQueueSuspend(&amp;q, taskHandle)</code> can move a <code>READY</code> task to that sleep queue as <code>SLEEPING_SUSPENDED</code>. (task context or ISR).  Other states are not allowed to be changed.</p>
</div>
<div class="paragraph data-line-1358">
<p><code>kSleepQueueReady(&amp;q, taskHandle)</code> does the opposite, moving a specific task from that sleep queue to <code>READY</code>.</p>
</div>
<div class="paragraph data-line-1360">
<p><code>kSleepQueueWake()</code> is synchronous in thread context. When invoked from ISR, the wake request is queued for post-processing by the system task (<code>uTasksPtr</code> must be <code>NULL</code> in this case).</p>
</div>
<hr>
<div class="paragraph data-line-1364">
<p><em>Because Sleep Queues are stateless, they are prone to lost wake-ups when used alone. They are best used as building blocks for <em>Conditional Critical Regions</em> (monitor-like constructs).</em></p>
</div>
<hr>
</div>
<div class="sect2 data-line-1368">
<h3 id="conditional_critical_regions">5.5. Conditional Critical Regions</h3>
<div class="paragraph data-line-1371">
<p>Task Events and semaphores work by atomically updating state and testing predicates that control execution flow (for example, <code>pend</code> on a semaphore with count <code>0</code> blocks the caller).</p>
</div>
<div class="paragraph data-line-1373">
<p>A critical region guarded by a lock is either free or taken.
What if we need to wait on a richer condition?</p>
</div>
<div class="paragraph data-line-1376">
<p>We can combine a Mutex and a Sleep Queue, but there is an important detail: operations on both must be coordinated atomically.</p>
</div>
<div class="paragraph data-line-1378">
<p>When that combination is wrapped as data plus methods, it is a <em>Monitor</em>.</p>
</div>
<div class="sect3 data-line-1381">
<h4 id="monitorinvariant">5.5.1. Monitor Invariants</h4>
<div class="olist arabic data-line-1383">
<ol class="arabic">
<li class="data-line-1383">
<p>a single task can be active within a monitor;</p>
</li>
<li class="data-line-1385">
<p>only the active task within a monitor can check or change its state.</p>
</li>
</ol>
</div>
<div class="paragraph data-line-1387">
<p>Since tasks signal or sleep <em>within</em> a monitor based on its <em>internal</em> state, and only one task can be active, we need to establish how to keep both invariants true.</p>
</div>
</div>
<div class="sect3 data-line-1390">
<h4 id="signalling_discipline">5.5.2. Signalling Discipline</h4>
<div class="paragraph data-line-1392">
<p>At any moment a single task can be active within a monitor. When the sleeping task is signalled, there are 3 common disciplines to follow: signal-and-leave (Hansen), signal-and-wait (Hoare) or signal-and-continue (Mesa).</p>
</div>
<div class="paragraph data-line-1394">
<p>Arguably, the most common is <em>signal-and-continue</em> - rather than leaving or suspending itself the active task might continue within the monitor.
That is possible if the active task holds a lock the waking task needs to acquire to enter. Upon leaving, the active task must release the lock.</p>
</div>
<div class="paragraph data-line-1397">
<p>The major implication is that by the time the woken task enters the monitor, the condition it was waiting for might no longer be true.
It sounds odd because a Monitor is about encapsulating a conditional critical region so no outsiders change its state. But, either a flush, a bad design&#8201;&#8212;&#8201;or a preemption anomaly&#8201;&#8212;&#8201;can violate that somehow.</p>
</div>
<div class="paragraph data-line-1401">
<p>Mesa Monitor has a typical test-loop pattern:</p>
</div>
<div class="listingblock data-line-1403">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs"> --- snippet ---
 while (condition.isFalse())
 {
    /*unlock-wait sequence:*/
     DISABLE_PREEMPTION
     unlock(mutex);
     sleep(condition)
     ENABLE_PREEMPTION
     lock(mutex);
     /* when waking, the while clause is tested again */
 }
 --- snippet ---</code></pre>
</div>
</div>
<div class="paragraph data-line-1418">
<p>The figure below shows a producer-consumer problem if implemented
on a Monitor-idiom.</p>
</div>
<div class="listingblock data-line-1420">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">                            Entry Queue [][][]–&gt;
         .............................................
         -------------------
         | Internal Data   |
         -------------------  |[Active Task]|
         | Sleep Queues    |
         |Sleeping for Data|
         |Sleeping for Room|
         -------------------
                              -&gt; [][][] Exit Queue
        ...............................................</code></pre>
</div>
</div>
<div class="paragraph data-line-1438">
<p>The <code>UNLOCK-SLEEP</code> sequence within the testing loop has preemption disabled because after releasing the lock, the task cannot be allowed to resume within the monitor again, for any reason that is not the monitor predicate being satisfied.</p>
</div>
</div>
<div class="sect3 data-line-1440">
<h4 id="condition_variable_model_for_mesa_monitors">5.5.3. Condition Variable Model for (Mesa) Monitors</h4>
<div class="paragraph data-line-1443">
<p>The <em>Condition Variable Model</em> allows a task to wait within a monitor-construct and if active, operate using <code>signal()</code>, <code>wait()</code> and <code>broadcast()</code> respecting the monitor invariant.</p>
</div>
<div class="paragraph data-line-1445">
<p><em>Sleep Queues</em> are actually the canonical <em>Condition Variable</em> introduced by Hoare:</p>
</div>
<div class="exampleblock data-line-1447">
<div class="content">
<div class="paragraph data-line-1448">
<p><em>Note that a condition "variable" is neither true nor
false; indeed, it does not have any stored value accessible
to the program. In practice, a condition variable will be
represented by an (initially empty) queue of processes
which are currently waiting on the condition; but this
queue is invisible both to waiters and signallers. This
design of the condition variable has been deliberately
kept as primitive and rudimentary as possible (&#8230;&#8203;)</em></p>
</div>
<div class="paragraph data-line-1457">
<p>(<em>Monitors: An Operating System Structuring Concept, Hoare, 1974</em>)</p>
</div>
</div>
</div>
<div class="paragraph data-line-1462">
<p><em>RK0</em> follows <em>pthreads condition variable</em> semantics, aligned with Mesa monitors.</p>
</div>
<div class="paragraph data-line-1464">
<p>The difference is that there is no standalone <em>CondVar</em> primitive. The programmer combines Sleep Queues and Mutexes and uses these helpers:</p>
</div>
<div class="ulist data-line-1466">
<ul>
<li class="data-line-1466">
<p><code>kCondVarWait(&amp;sleepq, &amp;mutex, timeout)</code></p>
</li>
<li class="data-line-1467">
<p><code>kCondVarSignal(&amp;sleepq)</code></p>
</li>
<li class="data-line-1468">
<p><code>kCondVarBroadcast(&amp;sleepq)</code></p>
</li>
</ul>
</div>
<div class="paragraph data-line-1470">
<p>The <code>condWait</code> is the real helper. When using it, a Mesa testing-loop reduces to:</p>
</div>
<div class="listingblock data-line-1472">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">  while(!condition)
  {
    kCondVarWait(&amp;condQueue, &amp;monitorLock, timeout);
  }</code></pre>
</div>
</div>
<div class="paragraph data-line-1482">
<p>If you need a monitor policy different from Mesa, you can build it from the same primitives.</p>
</div>
<div class="admonitionblock note data-line-1485">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>kCondVarWait</code>, <code>kCondVarSignal</code>, and <code>kCondVarBroadcast</code> are task-context APIs and cannot be called from ISRs.
</td>
</tr>
</table>
</div>
<div class="sect4 data-line-1488">
<h5 id="usage_example_synchronisation_barrier">5.5.3.1. Usage Example: Synchronisation Barrier</h5>
<div class="paragraph data-line-1490">
<p>A given number of tasks must reach a point in the program before <em>all can proceed</em>, so every task calls a <code>barrWait(&amp;barrier)</code> to catch up with the set of tasks it must synchronise.</p>
</div>
<div class="paragraph data-line-1492">
<p>The last task entering the barrier will broadcast a signal to all tasks waiting for the wake condition.</p>
</div>
<div class="paragraph data-line-1494">
<p>At any moment within a Monitor a single task is RUNNING (what is an invariant of the kernel), all other tasks within the monitor are either SLEEPING (for some condition) or BLOCKED (on a mutex).</p>
</div>
<div class="listingblock data-line-1497">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* Synchronisation Barrier */

typedef struct
{
    RK_MUTEX lock;
    RK_SLEEP_QUEUE allSynch;
    UINT count; /* number of tasks in the barrier */
    UINT round; /* increased every time all tasks synch */
    UINT nRequired; /* number of tasks required */
} Barrier_t;

VOID BarrierInit(Barrier_t *const barPtr, UINT nRequired)
{
    kMutexInit(&amp;barPtr-&gt;lock, RK_INHERIT);
    kSleepQueueInit(&amp;barPtr-&gt;allSynch);
    barPtr-&gt;count = 0;
    barPtr-&gt;round = 0;
    barPtr-&gt;nRequired = nRequired;

}

VOID BarrierWait(Barrier_t *const barPtr)
{
    UINT myRound = 0;
    kMutexLock(&amp;barPtr-&gt;lock, RK_WAIT_FOREVER);

    /* save round number */
    myRound = barPtr-&gt;round;
    /* increase count on this round */
    barPtr-&gt;count++;

    if (barPtr-&gt;count == barPtr-&gt;nRequired)
    {
        /* reset counter, inc round, broadcast to sleeping tasks */
        barPtr-&gt;round++;
        barPtr-&gt;count = 0;
        kCondVarBroadcast(&amp;barPtr-&gt;allSynch);
    }
    else
    {
        /* sequence: a proper wake signal might happen after inc round */
        while ((UINT)(barPtr-&gt;round - myRound) == 0U)
        {
            RK_ERR err = kCondVarWait(&amp;barPtr-&gt;allSynch, &amp;barPtr-&gt;lock, RK_WAIT_FOREVER);
            K_ASSERT(err==RK_ERR_SUCCESS);
        }
    }
    kMutexUnlock(&amp;barPtr-&gt;lock);
}


#define N_REQUIRED 3

Barrier_t syncBarrier;

VOID kApplicationInit(VOID)
{

    K_ASSERT(!kCreateTask(&amp;task1Handle, Task1, RK_NO_ARGS, "Task1", stack1, STACKSIZE, 2, RK_PREEMPT));
    K_ASSERT(!kCreateTask(&amp;task2Handle, Task2, RK_NO_ARGS, "Task2", stack2, STACKSIZE, 3, RK_PREEMPT));
    K_ASSERT(!kCreateTask(&amp;task3Handle, Task3, RK_NO_ARGS, "Task3", stack3, STACKSIZE, 1, RK_PREEMPT));
	BarrierInit(&amp;syncBarrier, N_REQUIRED);
}
VOID Task1(VOID* args)
{
    RK_UNUSEARGS
    while (1)
    {
        kPuts("Task 1 is waiting at the barrier...\r\n");
        BarrierWait(&amp;syncBarrier);
        kPuts("Task 1 passed the barrier!\r\n");
		kSleep(8);
    }
}

VOID Task2(VOID* args)
{
    RK_UNUSEARGS
    while (1)
    {
        kPuts("Task 2 is waiting at the barrier...\r\n");
        BarrierWait(&amp;syncBarrier);
        kPuts("Task 2 passed the barrier!\r\n");
		kSleep(5);
	}
}

VOID Task3(VOID* args)
{
    RK_UNUSEARGS
    while (1)
    {
        kPuts("Task 3 is waiting at the barrier...\r\n");
        BarrierWait(&amp;syncBarrier);
        kPuts("Task 3 passed the barrier!\r\n");
        kSleep(3);
	}
}</code></pre>
</div>
</div>
<div class="imageblock data-line-1601">
<div class="content">
<img src="https://kernel0org.wordpress.com/wp-content/uploads/2025/06/syncbarr.png" alt="syncbarr" width="40%">
</div>
</div>
<div class="admonitionblock note data-line-1605">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Monitor/CondVars are not to be signalled by ISRs. Because as they do not accumulate and an ISR is not a normal task, it can&#8217;t be within a monitor and a signal might be lost.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4 data-line-1609">
<h5 id="readerswriterslock">5.5.3.2. Usage Example: Readers Writers Lock</h5>
<div class="paragraph data-line-1611">
<p>Several readers and writers share a piece of memory. Readers can concurrently access the memory to read; a single writer is allowed (otherwise, data would be corrupted).</p>
</div>
<div class="paragraph data-line-1613">
<p>When a writer finishes, it checks for any readers waiting. If there is, the writer flushes the readers waiting queue. If not, it wakes a single writer, if any.
When the last reader finishes, it signals a writer.</p>
</div>
<div class="paragraph data-line-1616">
<p>Every read or write operation begins with an acquire and finishes with a release.</p>
</div>
<div class="paragraph data-line-1618">
<p><em>PS: This RWLock implementation has a <strong>reader-preference</strong> policy, as when a writer finishes, it flushes sleeping readers.
When the last reader finishes, it will signal writer waiting queue.</em></p>
</div>
<div class="listingblock data-line-1622">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* RW-Lock */

/* a single writer is allowed if there are no readers */
/* several readers are allowed if there is no writer*/
typedef struct
{
	RK_MUTEX	 lock;
	RK_SLEEP_QUEUE	 writersGo;
	RK_SLEEP_QUEUE	 readersGo;
	INT			 rwCount; /* number of active readers if &gt; 0 */
						  /* active writer if -1             */

}RwLock_t;

VOID RwLockInit(RwLock_t *const rwLockPtr)
{

	kMutexInit(&amp;rwLockPtr-&gt;lock, RK_INHERIT);
	kSleepQueueInit(&amp;rwLockPtr-&gt;writersGo);
	kSleepQueueInit(&amp;rwLockPtr-&gt;readersGo);
	rwLockPtr-&gt;rwCount = 0;
}

/* A writer can acquire if  rwCount = 0 */
/* An active writer is indicated by rwCount = -1; */
VOID RwLockAcquireWrite(RwLock_t *const rwLockPtr)
{
	kMutexLock(&amp;rwLockPtr-&gt;lock, RK_WAIT_FOREVER);
	/* if different than 0, there are either writers or readers */
	/* sleep to be signalled */
	while (rwLockPtr-&gt;rwCount != 0)
	{
	    kCondVarWait(&amp;rwLockPtr-&gt;writersGo, &amp;rwLockPtr-&gt;lock, RK_WAIT_FOREVER);
	    /* mutex is locked when waking up*/
	}
	/* woke here, set an active writer */
	rwLockPtr-&gt;rwCount = -1;
	kMutexUnlock(&amp;rwLockPtr-&gt;lock);
}

/* a writer releases, waking up all waiting readers, if any */
/* if there are no readers, a writer can get in */
VOID RwLockReleaseWrite(RwLock_t *const rwLockPtr)
{
	kMutexLock(&amp;rwLockPtr-&gt;lock, RK_WAIT_FOREVER);

	rwLockPtr-&gt;rwCount = 0; /* indicate no writers*/

	/* if there are waiting readers, flush */
	ULONG nWaitingReaders=0;
	kSleepQueueQuery(&amp;rwLockPtr-&gt;readersGo, &amp;nWaitingReaders);
	if (nWaitingReaders &gt; 0)
	{
	    /* condVarBroadcast is just an alias for an event flush */
		kCondVarBroadcast(&amp;rwLockPtr-&gt;readersGo);
	}
	else
	{
		/* wake up a single writer if any */
		kCondVarSignal(&amp;rwLockPtr-&gt;writersGo);
	}
	kMutexUnlock(&amp;rwLockPtr-&gt;lock);
}

/* a reader can acquire if there are no writers */
VOID RwLockAcquireRead(RwLock_t *const rwLockPtr)
{
	kMutexLock(&amp;rwLockPtr-&gt;lock, RK_WAIT_FOREVER);
	/* if there is an active writer, sleep */
	while (rwLockPtr-&gt;rwCount &lt; 0)
	{
	    kCondVarWait(&amp;rwLockPtr-&gt;readersGo, &amp;rwLockPtr-&gt;lock, RK_WAIT_FOREVER);
	    /* mutex is locked when waking up*/
	}
	/* increase rwCount, so its &gt; 0, indicating readers */
	rwLockPtr-&gt;rwCount ++;
	kMutexUnlock(&amp;rwLockPtr-&gt;lock);
}

/* a reader releases and wakes a single writer */
/* if it is the last reader */
VOID RwLockReleaseRead(RwLock_t *const rwLockPtr)
{
	kMutexLock(&amp;rwLockPtr-&gt;lock, RK_WAIT_FOREVER);
	rwLockPtr-&gt;rwCount --;
	if (rwLockPtr-&gt;rwCount == 0)
	{
		kCondVarSignal(&amp;rwLockPtr-&gt;writersGo);
	}
	kMutexUnlock(&amp;rwLockPtr-&gt;lock);
}</code></pre>
</div>
</div>
<div class="paragraph data-line-1718">
<p>In the image below, 4 tasks&#8201;&#8212;&#8201;a fast writer (Task 1), a slow writer (Task 4) and two readers (Task3 is faster than Task2)&#8201;&#8212;&#8201;reading from and writing to a shared UINT variable:</p>
</div>
<div class="imageblock data-line-1720">
<div class="content">
<img src="https://kernel0org.wordpress.com/wp-content/uploads/2025/06/readerwriter-4.png" alt="readerwriter 4" width="30%">
</div>
</div>
<hr>
</div>
</div>
</div>
<div class="sect2 data-line-1724">
<h3 id="message_queue">5.6. Message Queue</h3>
<div class="paragraph data-line-1726">
<p>The key mechanism for Message Passing in <em>RK0</em> is a <em>Message Queue</em>. Messages are passed <em>by copy</em> and have a fixed-size of 4-,8-,16- or 32-byte, i.e., 1, 2, 4 or 8 words.</p>
</div>
<div class="paragraph data-line-1728">
<p>Two other abstractions are constructed on top of Queues:</p>
</div>
<div class="olist arabic data-line-1730">
<ol class="arabic">
<li class="data-line-1730">
<p><em>Port</em>, which is a server endpoint that enqueues <em>Remote Invocations</em>, or <em>Procedure Calls</em> from clients.</p>
</li>
<li class="data-line-1732">
<p><em>Mailbox</em>, a 1-word message queue. It can be used as is, and is used by the kernel as reply route from servers to clients.</p>
</li>
</ol>
</div>
<table class="tableblock frame-all grid-all stretch data-line-1735">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Message Queue Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Buffer Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Message Size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of Mesages</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write Position</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Read Position</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Server Status</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Owner Task</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Notify callback</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting queue</p></td>
</tr>
</tbody>
</table>
<div class="sect3 data-line-1748">
<h4 id="size_of_a_message">5.6.1. Size of a Message</h4>
<div class="paragraph data-line-1750">
<p>Each declared queue has a <em>fixed message-size</em> at initialisation, and can assume, 1, 2, 4 or 8 WORDs (4, 8, 16, 32 BYTEs). This constraint is intentional. Word-aligned copies are faster, predictable and safer for type casting.</p>
</div>
<div class="paragraph data-line-1752">
<p>(A word-aligned <em>single copy</em> will take ~5 cycles in Cortex-M3/4/7, and ~6 cycles on Cortex-M0/M0+.)</p>
</div>
<div class="paragraph data-line-1754">
<p><em>Ports</em> have messages whose types are labeled as:</p>
</div>
<div class="ulist data-line-1756">
<ul>
<li class="data-line-1756">
<p><code>RK_PORT_MESG_&lt;2,4,8&gt;WORD</code>, which the first two are reserved meta-data. For variable payload one uses the <code>RK_PORT_MESG_COOKIE</code>, passing an opaque spointer as payload.</p>
</li>
</ul>
</div>
</div>
<div class="sect3 data-line-1758">
<h4 id="blocking_and_non_blocking_behaviour">5.6.2. Blocking and non-blocking behaviour</h4>
<div class="paragraph data-line-1760">
<p>A producer task can optionally block on a full queue, switching its state to <code>SENDING</code>. A consumer (optionally) blocks on an empty queue switching its state to <code>RECEIVING</code>.</p>
</div>
<div class="paragraph data-line-1762">
<p>Note that when using non-blocking calls <code>(RK_NO_WAIT</code>) they immediately return if unsuccessful.</p>
</div>
<div class="paragraph data-line-1764">
<p>One can use a <code>peek()</code> to read from the head of a queue without extracting the message. A <code>jam()</code> method is used to put a message on the queue head, but it does not overwrite. <code>jam()</code> is meaningless for Mailboxes.</p>
</div>
<div class="paragraph data-line-1766">
<p>A <code>postovw()</code> overwrites the oldest message and is allowed solely for 1-message queues. If N-message queues were allowed to be overwritten, all unread messages would leak as read and write pointers are adjusted on the operation. In case one needs overwriting full queues continuously a classic ring buffer will do.</p>
</div>
<div class="paragraph data-line-1768">
<p><code>peek()</code> and <code>postovw()</code> are normally used on Mailboxes for last-message semantics&#8201;&#8212;&#8201;the Mailbox never goes empty; a new message is placed by overwriting the current one.</p>
</div>
</div>
<div class="sect3 data-line-1770">
<h4 id="ownership_and_priority_inversion">5.6.3. Ownership and Priority Inversion</h4>
<div class="paragraph data-line-1772">
<p>Message Queues (and by extension, Mailboxes) <em>can</em> have owners, and thus, only the owners can receive at these channels. One might think it makes it a <em>Port</em>, but not yet. The fact is, if a receiver is blocked on full queue, the sender can boost its priority.</p>
</div>
<div class="paragraph data-line-1774">
<p><em>Ports</em> are for _ synchronous procedure calls_. The server needs to run at the client&#8217;s priority, which means either boosting or demoting priority.</p>
</div>
</div>
<div class="sect3 data-line-1776">
<h4 id="notify_callback">5.6.4. Notify callback</h4>
<div class="paragraph data-line-1778">
<p>A callback can be registered for when a queue sends a message successfuly, as a means of event notification.</p>
</div>
</div>
<div class="sect3 data-line-1780">
<h4 id="usage_examples">5.6.5. Usage Examples</h4>
<div class="paragraph data-line-1782">
<p>Below there is a rich set of usage examples. They demonstrate how to use message-passing in RK0, its API and helper macros to declare storage and messages at the appropriate size.</p>
</div>
<div class="sect4 data-line-1784">
<h5 id="mail_queue_pattern">5.6.5.1. Mail Queue pattern</h5>
<div class="paragraph data-line-1786">
<p>In RTOS jargon, a <em>Mailbox</em> is often said to 1-slot queue carrying a pointer-sized message <code>(sizeof(VOID*))</code>. When exchanging messages which carry data to be parsed, for instance:</p>
</div>
<div class="listingblock data-line-1788">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">DATA STRUCT:
[COMMAND ID]
[PAYLOAD SIZE]
[PAYLOAD]
[CRC]</code></pre>
</div>
</div>
<div class="paragraph data-line-1795">
<p>A good pattern is combining Memory Partitions along with 1-word message queues, thus <code>Mail Queues</code>. The address of the buffer is allocated, filled and sent through the queue by the producer(s).
The consumer dequeues the address, consume data and deallocate it.
The producer-allocate, consumer-deallocate guarantees data integrity on the addresses.</p>
</div>
<div class="paragraph data-line-1799">
<p>Depending on the purpose, the producer might block if there are no buffers available, using counting semaphores.</p>
</div>
<div class="listingblock data-line-1801">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">RK_SEMAPHORE freeMemSema;
/* initialised with the total number of buffers */
RK_SEMAPHORE takenMemSema; /*initialised as 0 */

/* alloc/free routines are mutually exclusive */

Alloc routine:

 kSemaphorePend(&amp;freeMemSema, RK_WAIT_FOREVER); /* block if no bufs */
 /* do not need a lock, alloc is protected */
 &lt; kMemPartitionAlloc &gt;
 if (unsuccessful)
  kSemaphorePost(&amp;freeMemSema);
  /* shouldnt happen if does, give back a token /*
  kSemaphorePost(&amp;takenMemSema);

Free routine:
  &lt; kMemPartitionFree &gt;
  if (successful)
    kSemaphorePost(&amp;memSema);</code></pre>
</div>
</div>
<div class="paragraph data-line-1826">
<p>Mail Queue pattern is used on the Application Logger facility that happens
to use several non-blocking senders to a single blocking-receiver, aligning to the Active Object design pattern.</p>
</div>
<div class="listingblock data-line-1830">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* Application Logger pattern */

/* standard log structure */
struct log
{
    RK_TICK t; /* timestamp */
    CHAR s[LOGLEN]; /*formatted string */
    UINT    level; /* level 0=message, 1=fault */
} K_ALIGN(4);

typedef struct log Log_t;

/* logger mem allocator + mem pool */
static RK_MEM_PARTITION qMem;
static Log_t logBufPool[LOGPOOLSIZ] K_ALIGN(4);

/* backing buffer for the logger queue */
/* (messages are 1-word-size, number equals the pool) */
RK_DECLARE_MESG_QUEUE_BUF(logQBuf, VOID *, LOGPOOLSIZ)

/* logger mail queue */
static RK_MESG_QUEUE logQ;

/* a sender will allocate a buffer write the log
message and enqueue on the mail queue, not-blocking
if the queue is full it returns the buffer immediately
if the memory pool is empty it drops the operation */

```c
/* excerpt of logPost(...) */
VOID logPost(/*formatted string */)
    ---snip---
    Log_t *logPtr = (Log_t*)kMemPartitionAlloc(&amp;qMem);
    RK_BARRIER
    if (logPtr) /* available buffer */
    {

       &lt; fill the buffer &gt;

        /* enqueue address */
        if (kMesgQueueSend(&amp;logQ, &amp;p, RK_NO_WAIT) != RK_ERR_SUCCESS)
        {
            /* queue is full, deallocate buf */
            RK_ERR err = kMemPartitionFree(&amp;qMem, &amp;p);
            K_ASSERT(err==RK_ERR_SUCCESS);
        }

    }
    ---snip---

/* excerpt of the logger task */

static VOID LoggerTask(VOID *args)
{
    RK_UNUSEARGS
    while (1)
    {

        VOID *recvPtr = NULL;

        /* drain the queue: keep receiving while successful */
        while (kMesgQueueRecv(&amp;logQ, &amp;recvPtr, RK_WAIT_FOREVER) == RK_ERR_SUCCESS)
        {
            &lt; print buffer contents &gt;

            /* deallocate */
            RK_ERR err = kMemPartitionFree(&amp;qMem, recvPtr);
            K_ASSERT(err == RK_ERR_SUCCESS);

        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph data-line-1908">
<p>The entire implementation can be seen at <code>app\logger.c</code>.</p>
</div>
</div>
<div class="sect4 data-line-1911">
<h5 id="averaging_sensor_values">5.6.5.2. Averaging Sensor Values</h5>
<div class="paragraph data-line-1913">
<p>A task receives measured sensor values from an ISR on a periodic rate. (A Soft Timer emulates the ISR).</p>
</div>
<div class="paragraph data-line-1915">
<p>Then it enqueues this data to a consumer - that will process the average value for each of 4 sensors.</p>
</div>
<div class="paragraph data-line-1917">
<p>The inter-task communication is designed as follows:</p>
</div>
<div class="olist arabic data-line-1919">
<ol class="arabic">
<li class="data-line-1919">
<p>The producer pends on a Mailbox that an ISR posts to. An application timer emulates this ISR.</p>
</li>
<li class="data-line-1921">
<p>The data extracted from the Mailbox is placed in a queue with the processing task as the consumer.</p>
</li>
<li class="data-line-1923">
<p>As the producer&#8217;s priority must be higher than that of the consumer, eventually, the queue will get full.</p>
</li>
<li class="data-line-1925">
<p>The producer drops the last message when the queue is full and signals the consumer.</p>
</li>
<li class="data-line-1927">
<p>Now the consumer has a batch of data to work until the next sensor update. It will block (pend on a signal) whenever the queue is empty.</p>
</li>
</ol>
</div>
<div class="listingblock data-line-1930">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">/* helpers for pend and signal */

#define kPend(timeout)                                \
    do                                                \
    {                                                 \
        kTaskEventGet(0x1, RK_FLAGS_ANY, NULL, timeout); \
    } while (0)

#define kSignal(taskhandle)           \
    do                                \
    {                                 \
        kTaskEventSet(taskhandle, 0x01); \
    } while (0)


/* sensor type */
typedef enum
{
	TEMPERATURE=1, HUMIDITY, CO2, FLOW
}SensorType_t;

struct sensorMsg
{
    SensorType_t sensorType;
    ULONG sensorValue;

};
typedef struct sensorMsg Mesg_t;

#define N_SENSOR    4
#define AVG_WINDOW_SIZE   10 /* 10 samples */

/* the queue */
RK_MESG_QUEUE sensorStream;

/* convenience macro to declare the queue storage */
#define N_MESSAGE 8
RK_DECLARE_MESGQ_BUF(mesgBuf, Mesg_t, N_MESSAGE)

/* timer to mimic isr */
RK_TIMER timerT1;

/* the mailbox the sensor task pends */
RK_MAILBOX sensorBox;
static Mesg_t sample = {0};
static UINT sampleErr;
VOID callBackISR(VOID* args);

VOID kApplicationInit( VOID)
{
    K_ASSERT(!kMesgQueueInit(&amp;sensorStream,
                            mesgBuf,
                             RK_MESGQ_MESG_SIZE(Mesg_t), /* set mesg size */
                             N_MESSAGE));

    /* timer @ every 10 ms */
    K_ASSERT(!kTimerInit(&amp;timerT1, 0, 10, callBackISR, NULL, RK_TIMER_RELOAD));
    K_ASSERT(!kMailboxInit(&amp;sensorBox));
}

VOID callBackISR(VOID *args)
{
    RK_UNUSEARGS
    sample.sensorType = (rand() % 4) + 1;
    switch (sample.sensorType)
    {
        case TEMPERATURE:
            sample.sensorValue = ( ULONG) rand() % 50;
            break;
        case HUMIDITY:
            sample.sensorValue = ( ULONG) rand() % 100;
            break;
        case CO2:
            sample.sensorValue = ( ULONG) rand() % 1000;
            break;
        case FLOW:
            sample.sensorValue = ( ULONG) rand() % 10;
            break;
        default:
            break;
    }
    /* Mailbox carries one word: post a pointer to sample */
    Mesg_t *samplePtr = &amp;sample;
    RK_ERR err = kMailboxPost(&amp;sensorBox, &amp;samplePtr, RK_NO_WAIT);
    if (err != RK_ERR_SUCCESS)
        sampleErr ++;

}

/* Producer - higher priority, blocks on mailbox */
VOID Task1(VOID *args)
{
    RK_UNUSEARGS
    Mesg_t *recvSample = NULL;
    while (1)
    {
        /* receive a pointer */
        RK_ERR errmbox = kMailboxPend(&amp;sensorBox, &amp;recvSample,RK_WAIT_FOREVER);
        K_ASSERT( errmbox==RK_ERR_SUCCESS);

        /* enqueue by copy into the stream */
        RK_ERR err = kMesgQueueSend(&amp;sensorStream, recvSample, RK_NO_WAIT);

        K_ASSERT(err &gt;= 0); /* either succesful or unsuccesful */
        if (err == RK_ERR_SUCCESS)
        {
            CHAR const *sensorTypeStr = NULL;
            if (recvSample-&gt;sensorType == 1)
                sensorTypeStr = "TEMP";
            if (recvSample-&gt;sensorType == 2)
                sensorTypeStr = "HUM";
            if (recvSample-&gt;sensorType == 3)
                sensorTypeStr = "CO2";
            if (recvSample-&gt;sensorType == 4)
                    sensorTypeStr = "FLOW";
            printf( "ENQ: [@%lums, %s, %lu] \r\n", kTickGet(), sensorTypeStr,
                        recvSample-&gt;sensorValue);
        }
        /* full, drop this sample and signal task2 */
        else if (err == RK_ERR_MESGQ_FULL)
        {
            kSignal(task2Handle);
        }
    }
}

/* for each sensor:
     . a ring buffer of AVG_WINDOW_SIZE values
 . sum of values
 . an index table (=enum - 1 eg., HUMIDITY IDX=2-1=1)
 */
static ULONG ringBuf[N_SENSOR][AVG_WINDOW_SIZE];
static ULONG ringSum[N_SENSOR] = {0};
static UINT ringIndex[N_SENSOR] = {0};

void Task2( void *args)
{

    RK_UNUSEARGS
    Mesg_t readSample;
    while (1)
    {
        RK_ERR err = kMesgQueueRecv(&amp;sensorStream, &amp;readSample, RK_NO_WAIT);
        if (err == RK_ERR_SUCCESS)
        {
            UINT sensorIdx = readSample.sensorType - 1;

/* remove oldest sample */
            ULONG oldest = ringBuf[sensorIdx][ringIndex[sensorIdx]];
            ringSum[sensorIdx] -= oldest;

/* push new sample */
            ringBuf[sensorIdx][ringIndex[sensorIdx]] = readSample.sensorValue;
            ringSum[sensorIdx] += readSample.sensorValue;

/* index incr-wrap */
            ringIndex[sensorIdx] ++;
            ringIndex[sensorIdx] %= AVG_WINDOW_SIZE;

/* simple average */
            ULONG avg = ringSum[sensorIdx] / AVG_WINDOW_SIZE;


            CHAR const *sensorTypeStr = NULL;
            if (readSample.sensorType == 1)
                sensorTypeStr = "TEMP";
            if (readSample.sensorType == 2)
                sensorTypeStr = "HUM";
            if (readSample.sensorType == 3)
                sensorTypeStr = "CO2";
            if (readSample.sensorType == 4)
                sensorTypeStr = "FLOW";

            printf( "DEQ: [@%lums, %s, %lu] | AVG: %lu \r\n", kTickGet(),
                    sensorTypeStr, readSample.sensorValue, avg);

        }
        else
        {
            kPend(RK_WAIT_FOREVER);
        }

    }
}</code></pre>
</div>
</div>
<div class="listingblock data-line-2118">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">OUTPUT:

ENQ: [@550ms, CO2, 571]
ENQ: [@560ms, FLOW, 4]
ENQ: [@570ms, FLOW, 4]
ENQ: [@580ms, HUM, 25]
ENQ: [@590ms, CO2, 931]
ENQ: [@600ms, CO2, 487]
ENQ: [@610ms, FLOW, 7]
ENQ: [@620ms, HUM, 79]

&gt;&gt;&gt; Queue is full. Now offload and process. Note the order remains &lt;&lt;&lt;

DEQ: [@630ms, CO2, 571] | AVG: 460
DEQ: [@631ms, FLOW, 4] | AVG: 5
DEQ: [@632ms, FLOW, 4] | AVG: 5
DEQ: [@633ms, HUM, 25] | AVG: 52
DEQ: [@634ms, CO2, 931] | AVG: 553
DEQ: [@635ms, CO2, 487] | AVG: 549
DEQ: [@636ms, FLOW, 7] | AVG: 5
DEQ: [@637ms, HUM, 79] | AVG: 55

&gt;&gt;&gt; Consumer is preempted &lt;&lt;&lt;
ENQ: [@640ms, CO2, 913]
ENQ: [@650ms, CO2, 134]
ENQ: [@660ms, HUM, 47]
ENQ: [@670ms, HUM, 30]
ENQ: [@680ms, TEMP, 7]
ENQ: [@690ms, CO2, 726]
ENQ: [@700ms, FLOW, 7]
ENQ: [@710ms, TEMP, 43]

DEQ: [@720ms, CO2, 913] | AVG: 578
DEQ: [@721ms, CO2, 134] | AVG: 543
DEQ: [@722ms, HUM, 47] | AVG: 51
DEQ: [@723ms, HUM, 30] | AVG: 44
DEQ: [@724ms, TEMP, 7] | AVG: 20
DEQ: [@725ms, CO2, 726] | AVG: 592
DEQ: [@726ms, FLOW, 7] | AVG: 5
DEQ: [@727ms, TEMP, 43] | AVG: 23</code></pre>
</div>
</div>
</div>
<div class="sect4 data-line-2162">
<h5 id="queue_select_using_notify_callback">5.6.5.3. Queue Select using Notify Callback</h5>
<div class="paragraph data-line-2164">
<p>A task is receiving from many queues and need to know which one has been able to complete.</p>
</div>
<div class="paragraph data-line-2166">
<p>The <code>notifyCbk(queue*)</code> is executed every time a send is successful. In this case it is using an Event Signal to a task. The Signals Flag indicate the queue number - as a contract - of which queue has completed sends. Note that as sends may coalesce, while a flag caps at 1, the consumer will drain each queue until it is empty, or it is preempted</p>
</div>
<div class="listingblock data-line-2168">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">/* Many-to-1 queue channels */

/* Consumer Select queue based on its event
flags, that a send callback for each queue runs */

#define LOG_PRIORITY 4 /* keep logger as lowest-priority user task */
#define STACKSIZE 256

#define NQUEUES 3 /* number of queues */
#define QSIZ 8 /* depth of each queue */

#define Q0_FLAG   RK_EVENT_1 // (1&lt;&lt;0)
#define Q1_FLAG   RK_EVENT_2 // (1&lt;&lt;1)
#define Q2_FLAG   RK_EVENT_3 // (1&lt;&lt;2)
#define QFLAGS   (ULONG)(Q0_FLAG | Q1_FLAG | Q2_FLAG)

typedef struct
{
    RK_TASK_HANDLE producer;
    UINT payload;
} MESG_t;

/* Succesful Send callbacks */
/* each callback follows this pattern */
static inline
VOID sendNotify0(RK_MESG_QUEUE *qPtr)
{
    (VOID)qPtr;
    kTaskEventSet(consumerHandle, Q0_FLAG);
    /* Q1 flag for queue1 and so forth */
}

/* each callback in installed using kMesgQueueInstallSendCbk
on kApplicationInit() */

/* helper to send */
static inline
VOID enqueueSample(RK_MESG_QUEUE *qPtr UINT payload)
{
    MESG_t mesg = {
        .payload = payload,
        .producer = RK_RUNNING_HANDLE,
    };
    RK_ERR err = kMesgQueueSend(qPtr, &amp;mesg, RK_WAIT_FOREVER);
    K_ASSERT(err == RK_ERR_SUCCESS);
}


VOID Prod0Task(VOID *args)
{
    RK_UNUSEARGS
    UINT seq = 0U;

    while (1)
    {
        enqueueSample(&amp;queues[0], seq++);
        kSleepRelease(25); /* fast producer */
    }
}

VOID Prod1Task(VOID *args)
{
    UINT seq = 0U;
    RK_UNUSEARGS

    while (1)
    {
        enqueueSample(&amp;queues[1], seq++);

        /* every fourth sample, also tickle the third queue */
        if ((seq &amp; 0x3U) == 0U)
        {
            enqueueSample(&amp;queues[2], seq);
        }

        kSleepRelease(60);
    }
}

/* Consumer listens on all queues, selecting those on its signal flags. */
VOID ConsumerTask(VOID *args)
{
    RK_UNUSEARGS

    MESG_t recv = {0};
    ULONG flags = 0UL;

    while (1)
    {
        flags = 0UL;
        kTaskEventGet(QFLAGS, RK_EVENT_FLAGS_ANY, &amp;flags,
                           RK_WAIT_FOREVER);

        for (UINT i = 0; i &lt; NQUEUES; ++i)
        {
            if (flags &amp; (1UL &lt;&lt; i))
            {
                while (kMesgQueueRecv(&amp;queues[i], (VOID*)&amp;recv, RK_NO_WAIT) ==
                       RK_ERR_SUCCESS)
                {
                    logPost("Q%u &lt;- sender=%s payload=%u", i,
                            RK_TASK_NAME(recv.producer), recv.payload);
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock data-line-2283">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">       0 ms :: Q1 &lt;- sender=Prod1 payload=0
     250 ms :: Q0 &lt;- sender=Prod0 payload=1
     500 ms :: Q0 &lt;- sender=Prod0 payload=2
     600 ms :: Q1 &lt;- sender=Prod1 payload=1
     750 ms :: Q0 &lt;- sender=Prod0 payload=3
    1000 ms :: Q0 &lt;- sender=Prod0 payload=4
    1200 ms :: Q1 &lt;- sender=Prod1 payload=2
    1250 ms :: Q0 &lt;- sender=Prod0 payload=5
    1500 ms :: Q0 &lt;- sender=Prod0 payload=6
    1750 ms :: Q0 &lt;- sender=Prod0 payload=7
    1800 ms :: Q1 &lt;- sender=Prod1 payload=3
    1800 ms :: Q2 &lt;- sender=Prod1 payload=4
    2000 ms :: Q0 &lt;- sender=Prod0 payload=8
    2250 ms :: Q0 &lt;- sender=Prod0 payload=9
    2400 ms :: Q1 &lt;- sender=Prod1 payload=4
    2500 ms :: Q0 &lt;- sender=Prod0 payload=10
    2750 ms :: Q0 &lt;- sender=Prod0 payload=11
    3000 ms :: Q0 &lt;- sender=Prod0 payload=12
    3000 ms :: Q1 &lt;- sender=Prod1 payload=5
    3250 ms :: Q0 &lt;- sender=Prod0 payload=13
    3500 ms :: Q0 &lt;- sender=Prod0 payload=14
    3600 ms :: Q1 &lt;- sender=Prod1 payload=6
    3750 ms :: Q0 &lt;- sender=Prod0 payload=15
    4000 ms :: Q0 &lt;- sender=Prod0 payload=16
    4200 ms :: Q1 &lt;- sender=Prod1 payload=7
    4200 ms :: Q2 &lt;- sender=Prod1 payload=8
    4250 ms :: Q0 &lt;- sender=Prod0 payload=17
    4500 ms :: Q0 &lt;- sender=Prod0 payload=18
    4750 ms :: Q0 &lt;- sender=Prod0 payload=19
    4800 ms :: Q1 &lt;- sender=Prod1 payload=8
    5000 ms :: Q0 &lt;- sender=Prod0 payload=20
    5250 ms :: Q0 &lt;- sender=Prod0 payload=21</code></pre>
</div>
</div>
</div>
<div class="sect4 data-line-2318">
<h5 id="synchronous_client_server_procedure_call">5.6.5.4. Synchronous Client-Server Procedure Call</h5>
<div class="paragraph data-line-2320">
<p>The example below computes a CRC on the server for the client’s payload and returns it as the reply code. Logically, this is unbuffered: the client blocks until it receives the reply.</p>
</div>
<div class="paragraph data-line-2322">
<p>For <code>kPortSendRecv()</code>, each client task must register a reply mailbox using <code>kRegisterMailbox(task, &amp;mbox)</code>.
To explicitly disable RPC replies for a task, call <code>kRegisterMailbox(task, NULL)</code>.
If no mailbox is registered, use <code>kPortSendRecvFromMbox()</code> and pass the reply mailbox explicitly for each call.</p>
</div>
<div class="paragraph data-line-2326">
<p>Note that the server may temporarily adopt the client priority while serving the request. After <code>kPortReplyDone()</code>, it returns to nominal priority.</p>
</div>
<div class="listingblock data-line-2328">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">#include &lt;application.h&gt;
#include &lt;logger.h&gt;
#define STACKSIZE 256
#define PORT_MSG_WORDS 4U   /* 2 words meta + 2 words payload */
#define PORT_CAPACITY 16

/* tasks */
RK_DECLARE_TASK(serverHandle, ServerTask,    stack1, STACKSIZE)
RK_DECLARE_TASK(clientHandle, ClientTask,    stack2, STACKSIZE)

/* port */
static RK_PORT serverPort;
RK_DECLARE_PORT_BUF(portBuf, PORT_MSG_WORDS, PORT_CAPACITY)

/* 4-word message format; first two words are metadata */
typedef RK_PORT_MESG_4WORD RpcMsg;

static inline UINT crc32(const VOID *data, ULONG size);
static inline BYTE xorshift8(void);

VOID kApplicationInit(void)
{
    K_ASSERT(!kCreateTask(&amp;serverHandle, ServerTask, RK_NO_ARGS, "Server", stack1, STACKSIZE, 1, RK_PREEMPT));
    K_ASSERT(!kCreateTask(&amp;clientHandle, ClientTask, RK_NO_ARGS, "Client", stack2, STACKSIZE, 2, RK_PREEMPT));

    /* init port */
    K_ASSERT(!kPortInit(&amp;serverPort, portBuf, PORT_MSG_WORDS, PORT_CAPACITY, serverHandle));

    logInit();
}

VOID ServerTask(VOID *args)
{
    RK_UNUSEARGS
    RpcMsg msg;
    while(1)
    {
        /* receive next request; server may adopt client priority here */
        K_ASSERT(!kPortRecv(&amp;serverPort, &amp;msg, RK_WAIT_FOREVER));

        BYTE  *vector = (BYTE*) msg.payload[0];
        ULONG   size  =          msg.payload[1];
        UINT    crc   = crc32(vector, size);

        logPost("[SERVER] Will Reply CRC=0x%04X | Eff Prio=%d | Nom Prio=%d",
                crc, runPtr-&gt;priority, runPtr-&gt;prioNominal);

        /* must end with kPortReplyDone */
        K_ASSERT(!kPortReplyDone(&amp;serverPort, (ULONG const*)&amp;msg, crc));

        logPost("[SERVER] Finished. | Eff Prio: %d | Nom Prio: %d", runPtr-&gt;priority, runPtr-&gt;prioNominal);
    }
}

VOID ClientTask(VOID *args)
{
    RK_UNUSEARGS
    static BYTE vec[8];
    for (UINT i = 0; i &lt; 8; ++i)
        vec[i] = xorshift8();

    RK_MAILBOX replyBox;
    K_ASSERT(!kMailboxInit(&amp;replyBox));
    K_ASSERT(!kRegisterMailbox(clientHandle, &amp;replyBox));
    RpcMsg msg = {0};
    msg.payload[0] = (ULONG) vec;  /* pointer as one word */
    msg.payload[1] = 8;            /* number of bytes */

    UINT reply = 0;
    while(1)
    {
        /* Send-Receive: a call */
        UINT want = crc32(vec, 8);
        K_ASSERT(!kPortSendRecv(&amp;serverPort, (ULONG*)&amp;msg, &amp;reply,
                                RK_WAIT_FOREVER));
        logPost("[CLIENT] Need=0x%04X | Recvd=0x%04X", want, reply);
        /* if reply is correct, generate a new payload */
        if (want == reply)
            for (UINT i = 0; i &lt; 8; ++i) vec[i] = xorshift8();
        kSleepRelease(1000);
    }
}</code></pre>
</div>
</div>
<div class="listingblock data-line-2413">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">   28000 ms :: [CLIENT] Need=0xC2A6C337 | Recvd=0xC2A6C337
   29000 ms :: [SERVER] Will Reply CRC=0x93F4110A | Eff Prio=2 | Nom Prio=1
   29000 ms :: [SERVER] Finished. | Eff Prio: 1 | Nom Prio: 1
   29000 ms :: [CLIENT] Need=0x93F4110A | Recvd=0x93F4110A
   30000 ms :: [SERVER] Will Reply CRC=0x7A8FA006 | Eff Prio=2 | Nom Prio=1
   30000 ms :: [SERVER] Finished. | Eff Prio: 1 | Nom Prio: 1
   30000 ms :: [CLIENT] Need=0x7A8FA006 | Recvd=0x7A8FA006
   31000 ms :: [SERVER] Will Reply CRC=0x9051C8B1 | Eff Prio=2 | Nom Prio=1
   31000 ms :: [SERVER] Finished. | Eff Prio: 1 | Nom Prio: 1
   31000 ms :: [CLIENT] Need=0x9051C8B1 | Recvd=0x9051C8B1
   32000 ms :: [SERVER] Will Reply CRC=0x11F29117 | Eff Prio=2 | Nom Prio=1
   32000 ms :: [SERVER] Finished. | Eff Prio: 1 | Nom Prio: 1</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2 data-line-2431">
<h3 id="mrm">5.7. Most-Recent Message Protocol (MRM)</h3>
<table class="tableblock frame-all grid-all stretch data-line-2434">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">MRM Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MRM Buffer Allocator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Buffer Allocator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Current MRM Buffer Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Size (Message Size)</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch data-line-2443">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">MRM Buffer</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Buffer Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Readers Count</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch data-line-2451">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Data Buffer</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>Application-dependent</em></p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock tip data-line-2457">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-2458">
<p>There is little practical difference between a message that does not arrive and one with no valid (stale) data. But when wrong (or stale) data is processed - e.g., to define a set point on a loop - a system can fail badly.</p>
</div>
<div class="paragraph data-line-2460">
<p>Design Choice: provide a broadcast asynchronous message-passing scheme that guarantees data freshness and integrity for all readers.</p>
</div>
<div class="paragraph data-line-2462">
<p>Benefits: The system has a mechanism to meet strict deadlines that cannot be predicted on design time.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-2465">
<p>Control loops reacting to unpredictable time events—like a robot scanning an environment or a drive-by-wire system—require a different message-passing approach. Readers cannot "look at the past" and cannot block. The most recent data must be delivered lock-free and have guaranteed integrity.</p>
</div>
<div class="paragraph data-line-2467">
<p>As <em>Ports</em>, the <em>MRM</em> is a high-level mechanism. It was chosen to be provided as a kernel service, given its distinctive nature and suitability for <em>RK0</em> applications.</p>
</div>
<div class="sect3 data-line-2469">
<h4 id="functional_description">5.7.1. Functional Description</h4>
<div class="paragraph data-line-2471">
<p>An <em>MRM</em> works as a <em>1-to-many asynchronous Mailbox</em> - with a lock-free specialisation that enables several readers to get the most recent deposited message with no integrity issues. Whenever a reader reads an MRM buffer, it will find the most recent data transmitted. It can also be seen as an extension of the Double Buffer pattern for a 1:N communication.</p>
</div>
<div class="paragraph data-line-2473">
<p>The core idea of the MRM protocol is that readers can only access the buffer that is classified as the '<em>most recent buffer</em>'. After a writer <em>publish()</em> a message, that will be the only message readers can <em>get()</em>&#8201;&#8212;&#8201;any former message being processed by a reader was grabbed <em>before</em> a new <em>publish()</em> - and, from now on, can only be <em>unget()</em>, eventually returning to the pool.</p>
</div>
<div class="paragraph data-line-2475">
<p>To clarify further, the communication steps are listed:</p>
</div>
<div class="olist arabic data-line-2477">
<ol class="arabic">
<li class="data-line-2477">
<p>A producer first reserves an MRM Buffer - the reserved MRM Buffer is not available for reading until it is published.</p>
</li>
<li class="data-line-2479">
<p>A message buffer is allocated and filled, and its address is within an MRM Buffer. The producer <em>publishes</em> the message. From now on, it is <em>the most recent message</em>. Any former published buffer is no longer visible to new readers</p>
</li>
<li class="data-line-2481">
<p>A reader starts by <em>getting</em> an MRM Buffer.  A <code>get()</code> operation delivers a copy of the message to the reader&#8217;s scope. Importantly, this operation increases the number of readers associated to that MRM Buffer.</p>
</li>
</ol>
</div>
<div class="paragraph data-line-2483">
<p>Before ending its cycle, the task releases (<code>unget()</code>) the buffer; on releasing, the kernel checks if the caller task is the last reader and if the buffer being released is not the current MRM Buffer.</p>
</div>
<div class="paragraph data-line-2485">
<p>If the above conditions are met, the <code>unget()</code> operation will return the MRM buffer to the pool. If there are more readers, OR if it is the current buffer, it remains available.</p>
</div>
<div class="paragraph data-line-2487">
<p>When the <code>reserve</code> operation detects that the most recent buffer still has readers, a new buffer is allocated to be written and published. If it has no readers, it is reused.</p>
</div>
<div class="paragraph data-line-2489">
<p>This way, the worst case is a sequence of <code>publish()</code> with no <code>unget()</code> at all&#8201;&#8212;&#8201;this would lead to the writer finding no buffer to reserve. This is prevented by making: <code>N Buffers = N tasks + 1</code>.</p>
</div>
</div>
<div class="sect3 data-line-2491">
<h4 id="mrm_control_block_configuration">5.7.2. MRM Control Block Configuration</h4>
<div class="paragraph data-line-2494">
<p>What might lead to some confusion when initialising an MRM Control Block is the need for two different pools:</p>
</div>
<div class="ulist data-line-2496">
<ul>
<li class="data-line-2496">
<p>One pool will be the storage for the MRM Buffers, which is the data structure for the mechanism.</p>
</li>
<li class="data-line-2498">
<p>Another pool is for the actual payload. The messages.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-2500">
<p>Both pools must have the same number of elements: the number of tasks communicating + 1.</p>
</div>
<div class="ulist data-line-2502">
<ul>
<li class="data-line-2502">
<p>The size of the data buffers is application-dependent - and is passed as a number of <em>words</em>. The minimal message size is 32-bit.</p>
</li>
<li class="data-line-2504">
<p>If using data structures, keep it aligned to 4 to take advantage of the performance of aligned memory.</p>
</li>
</ul>
</div>
</div>
<div class="sect3 data-line-2507">
<h4 id="usage_example">5.7.3. Usage Example</h4>
<div class="paragraph data-line-2509">
<p>Consider a modern car - speed variations are of interest in many modules. With a somehow "naive" approach, let us consider three modules and how they should react when speed varies:</p>
</div>
<div class="olist arabic data-line-2511">
<ol class="arabic">
<li class="data-line-2511">
<p><strong>Cruiser Control:</strong> For the Cruiser Control, a speed increase might signify the driver wants manual control back, and it will likely turn off.</p>
</li>
<li class="data-line-2513">
<p><strong>Windshield Wipers:</strong> If they are on, a speed change can affect the electric motor&#8217;s adjustments to the air resistance.</p>
</li>
<li class="data-line-2515">
<p><strong>Radio:</strong> Speed changes reflect the aerodynamic noise - the radio volume might need adjustment.</p>
</li>
</ol>
</div>
<div class="paragraph data-line-2517">
<p>As the variations are unpredictable, we need a mechanism to deliver the last speed in order of importance for all these modules. From highest to lowest priority, Cruise, Wipers, and Radio are the three modules that range from safety to comfort.</p>
</div>
<div class="paragraph data-line-2519">
<p>To emulate this scenario, we can write an application with a higher priority task that sleeps and wakes up at pseudo-random times to produce random values that represent the (unpredictable) speed changes.</p>
</div>
<div class="paragraph data-line-2521">
<p>The snippet below has 4 periodic tasks. Tasks are periodic using the <code>kSleepRelease()</code> primitive.</p>
</div>
<div class="paragraph data-line-2523">
<p>There is a sequential counter. When a task wakes and see it was not incremented it just runs.</p>
</div>
<div class="paragraph data-line-2525">
<p>The producer publishes new data at a random interval, preempting whatever task is running at the moment. Given tha random updates,</p>
</div>
<div class="exampleblock data-line-2527">
<div class="content">
<div class="listingblock data-line-2529">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">typedef struct
{
    UINT speed;
    ULONG timeStamp;
} Mesg_t;

#define STACKSIZE 256
#define N_MRM (5)                          /* Number of MRMs N Tasks + 1 */
#define MRM_MESG_SIZE (sizeof(Mesg_t) / 4) /* In WORDS */
RK_MRM MRMCtl;                             /* MRM control block */
RK_MRM_BUF buf[N_MRM];                     /* MRM pool */
Mesg_t data[N_MRM];                        /* message data pool */

RK_DECLARE_TASK(speedSensorHandle, SpeedSensorTask, stack1, STACKSIZE)
RK_DECLARE_TASK(cruiserHandle, CruiserTask, stack2, STACKSIZE)
RK_DECLARE_TASK(wiperHandle, WiperTask, stack3, STACKSIZE)
RK_DECLARE_TASK(radioHandle, RadioTask, stack4, STACKSIZE)
volatile UINT seq = 0;
VOID kApplicationInit(VOID)
{

    kCreateTask(&amp;speedSensorHandle, SpeedSensorTask, RK_NO_ARGS, "SpeedTsk",
                stack1, STACKSIZE, 1, RK_PREEMPT);

    kCreateTask(&amp;cruiserHandle, CruiserTask, RK_NO_ARGS, "CruiserTsk", stack2,
                STACKSIZE, 2, RK_PREEMPT);

    kCreateTask(&amp;wiperHandle, WiperTask, RK_NO_ARGS, "WiperTsk", stack3,
                STACKSIZE, 3, RK_PREEMPT);

    kCreateTask(&amp;radioHandle, RadioTask, RK_NO_ARGS, "RadioTsk", stack4,
                STACKSIZE, 4, RK_PREEMPT);

    kMRMInit(&amp;MRMCtl, buf, data, N_MRM, MRM_MESG_SIZE);

    logInit(5);
}

VOID SpeedSensorTask(VOID *args)
{
    RK_UNUSEARGS

    Mesg_t sendMesg = {0};
    while (1)
    {
        RK_TICK sleepTicks = ((RK_TICK)rand() % 18) + 1;
        kSleep(sleepTicks);
        RK_TICK currTick = kTickGetMs();
        UINT speedValue = (UINT)(rand() % 170) + 1;
        sendMesg.speed = speedValue;
        sendMesg.timeStamp = currTick;
        /* grab a buffer */
        RK_MRM_BUF *bufPtr = kMRMReserve(&amp;MRMCtl);
        if (bufPtr != NULL)
        {
            K_ASSERT(!kMRMPublish(&amp;MRMCtl, bufPtr, &amp;sendMesg));
            printf("!!!!! @%lums SPEED UPDATE: %u mph\r\n", kTickGetMs(), speedValue);
            seq += 1;
        }
        else
        { /* cannot fail */
            logError("MRM protocol could not find a free buffer\r\n");
        }
        /* publish  */
    }
}

VOID CruiserTask(VOID *args)
{
    RK_UNUSEARGS
    Mesg_t recvMesg = {0};
    while (1)
    {
        RK_MRM_BUF *readBufPtr = kMRMGet(&amp;MRMCtl, &amp;recvMesg);
        if (readBufPtr)
        {
            logPost("CRUISER: (%u mph, %lu ms)", recvMesg.speed, recvMesg.timeStamp);

            kMRMUnget(&amp;MRMCtl, readBufPtr);
        }
        kSleepRelease(4);
    }
}

VOID WiperTask(VOID *args)
{
    RK_UNUSEARGS
    Mesg_t recvMesg = {0};

    while (1)
    {

        RK_MRM_BUF *readBufPtr = kMRMGet(&amp;MRMCtl, &amp;recvMesg);
        if (readBufPtr)
        {
            logPost("WIPERS: (%u mph, %lu ms)", recvMesg.speed, recvMesg.timeStamp);

            kMRMUnget(&amp;MRMCtl, readBufPtr);
        }
        kSleepRelease(7);
    }
}
VOID RadioTask(VOID *args)
{
    RK_UNUSEARGS
    Mesg_t recvMesg = {0};
    while (1)

    {

        RK_MRM_BUF *readBufPtr = kMRMGet(&amp;MRMCtl, &amp;recvMesg);

        if (readBufPtr)
        {
            logPost("RADIO: (%u mph, %lu ms) ", recvMesg.speed, recvMesg.timeStamp);
            kMRMUnget(&amp;MRMCtl, readBufPtr);
        }
        kSleepRelease(11);
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph data-line-2655">
<p>Thus, different situations can happen:</p>
</div>
<div class="ulist data-line-2657">
<ul>
<li class="data-line-2657">
<p>All tasks read the updated pair (speed, time)</p>
</li>
<li class="data-line-2658">
<p>Not all tasks receive the updated pair because another update happens in between.</p>
</li>
<li class="data-line-2659">
<p>No tasks receive an update - because another happens too soon.</p>
</li>
<li class="data-line-2660">
<p>No update happens between in the period of a given task. It receives
the same value. No problems.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-2664">
<p>All these cases are on the log:</p>
</div>
<div class="listingblock data-line-2665">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Logs show: (last speed record, record time)

  !!!@120ms SPEED UPDATE: 164 mph
     120 ms :: CRUISER: (164 mph, 120 ms)
     140 ms :: WIPERS: (164 mph, 120 ms)
 !!! @150ms SPEED UPDATE: 80 mph
     160 ms :: CRUISER: (80 mph, 150 ms)
     200 ms :: CRUISER: (80 mph, 150 ms)
     210 ms :: WIPERS: (80 mph, 150 ms)
     220 ms :: RADIO: (80 mph, 150 ms)
     240 ms :: CRUISER: (80 mph, 150 ms)
  !!!@280ms SPEED UPDATE: 49 mph
     280 ms :: CRUISER: (49 mph, 280 ms)
     280 ms :: WIPERS: (49 mph, 280 ms)
     320 ms :: CRUISER: (49 mph, 280 ms)
     330 ms :: RADIO: (49 mph, 280 ms)
     350 ms :: WIPERS: (49 mph, 280 ms)
     360 ms :: CRUISER: (49 mph, 280 ms)
     400 ms :: CRUISER: (49 mph, 280 ms)
     420 ms :: WIPERS: (49 mph, 280 ms)
     440 ms :: CRUISER: (49 mph, 280 ms)
     440 ms :: RADIO: (49 mph, 280 ms)
  !!!@450ms SPEED UPDATE: 87 mph
     480 ms :: CRUISER: (87 mph, 450 ms)
     490 ms :: WIPERS: (87 mph, 450 ms)
     520 ms :: CRUISER: (87 mph, 450 ms)
 !!! @540ms SPEED UPDATE: 110 mph
     550 ms :: RADIO: (110 mph, 540 ms)
     560 ms :: CRUISER: (110 mph, 540 ms)
     560 ms :: WIPERS: (110 mph, 540 ms)
     600 ms :: CRUISER: (110 mph, 540 ms)
     630 ms :: WIPERS: (110 mph, 540 ms)
 !!! @640ms SPEED UPDATE: 22 mph
     640 ms :: CRUISER: (22 mph, 640 ms)
     660 ms :: RADIO: (22 mph, 640 ms)</code></pre>
</div>
</div>
<div class="paragraph data-line-2704">
<p><em>The highlight is that controllers can keep their pace, while receiving fresh data - you can see it on the timestamp on the image.</em></p>
</div>
<div class="paragraph data-line-2706">
<p>Again, they might receive the same data more than once or miss samples; what is important is that <em>they are not lagging and consuming stale data.</em></p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-2708">
<h2 id="error_handling">6. <em><strong>Error Handling</strong></em></h2>
<div class="sectionbody">
<div class="sect2 data-line-2710">
<h3 id="fail_fast">6.1. Fail fast</h3>
<div class="paragraph data-line-2712">
<p>While tracing and error handling are yet to be largely improved (and that is when the 1.0.0 version will be released), currently
<em>RK0</em> employs a policy of <em>failing fast</em> in <strong>debug mode</strong>.</p>
</div>
<div class="paragraph data-line-2715">
<p>When Error Checking is enabled, every kernel call will be 'defensive', checking for correctness of parameters and invariants, null dereferences, etc.</p>
</div>
<div class="paragraph data-line-2717">
<p>In these cases is more useful to allow the first error to halt the execution by calling an Error Handler function to observe the program state.</p>
</div>
<div class="paragraph data-line-2719">
<p>A trace structure records the address of the running TCB, its current stack pointer, the link register (that is, the PC at kErrHandler was called), and a time stamp.</p>
</div>
<div class="paragraph data-line-2721">
<p>This record is on a <code>.noinit</code> RAM section, so it is visible if CPU resets. A fault code is stored in a global <code>faultID</code> and on the trace structure.
Developers can hook in custom behaviour.</p>
</div>
<div class="paragraph data-line-2724">
<p>If the kernel is configured to not halt on a fault, but Error Checking is enabled, functions will return negative values in case of an error.</p>
</div>
<div class="paragraph data-line-2726">
<p>On the other hand, when Error Checking is disabled or <code>NDEBUG</code> is defined nothing is checked, reducing code size and improving performance.</p>
</div>
<div class="paragraph data-line-2728">
<p>(<em>Some deeper internal calls have assertion. For those, only <code>NDEBUG</code> defined ensures they are disabled.</em>)</p>
</div>
</div>
<div class="sect2 data-line-2730">
<h3 id="stack_overflow">6.2. Stack Overflow</h3>
<div class="paragraph data-line-2732">
<p>Stack overflow is detected (not prevented) using a "stack painting" with a sentinel word. Stack Overflow detection is enabled by defining the assembler preprocessor <code>__KDEF_STACKOVFLW</code> when compiling.</p>
</div>
<div class="paragraph data-line-2735">
<p>As a matter of fact, sizing your stack is something you must do diligently when programming a system. I would say a mechanism for stack overflow detection is on the bottom of the list of 'must-have' features.</p>
</div>
<div class="paragraph data-line-2737">
<p>One can take advantage of the static task model - <em>it is possible to predict offline</em> the deepest call within any task. The compiler flag <code>-fstack-usage</code> creates <code>.su</code> files indicating the depth of every function within a module. This is an example of compilation-unit output:</p>
</div>
<div class="listingblock data-line-2739">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">core/src/ksema.c:34:8:kSemaphoreInit	88	static
core/src/ksema.c:74:8:kSemaphorePend	96	static
core/src/ksema.c:189:8:kSemaphorePost	88	static
core/src/ksema.c:265:8:kSemaphoreFlush	72	static
core/src/ksema.c:306:5:kSemaphoreQuery	40	static
core/src/kmutex.c:128:8:kMutexInit	16	static
core/src/kmutex.c:165:8:kMutexLock	120	static
core/src/kmutex.c:325:8:kMutexUnlock	96	static
core/src/kmutex.c:425:6:kMutexQuery	56	static</code></pre>
</div>
</div>
<div class="paragraph data-line-2751">
<p>These are the worst cases. Now, you identify the depth of the longest <em>chain of calls</em> for a task using these services and add a generous safety margin&#8201;&#8212;&#8201;30%. The cap depends on your budget.</p>
</div>
<div class="paragraph data-line-2753">
<p>Importantly, you also have to size the System Stack. This initial size is defined in <code>linker.ld</code> by the symbol <code>Min_Stack_Size</code>. In this case, account for the depth of <code>main()</code>, <code>kApplicationInit()</code>, and all interrupt handlers; again, inspect the longest call chain depth. Assume interrupts always add to the worst static depth, and account for <em>nested interrupts</em>.</p>
</div>
</div>
<div class="sect2 data-line-2755">
<h3 id="deadlocks">6.3. Deadlocks</h3>
<div class="paragraph data-line-2757">
<p>There are deadlock-recovery techniques in the literature, but they are generally unfeasible here. The kernel provides bounded waiting, enforces priority-ordered waiting queues, applies mutex priority inheritance, and offers lock-free primitives and period-drift compensation. None of these techniques prevents deadlocks by itself (and with bounded blocking plus lock-free primitives, one can still get <em>livelocks</em>).</p>
</div>
<div class="ulist data-line-2760">
<ul>
<li class="data-line-2760">
<p>Ordered Locking:</p>
</li>
</ul>
</div>
<div class="paragraph data-line-2762">
<p>For those programming the application, despite following the RMS rule of higher priority for higher request rate tasks, the golden rule for locking is acquiring resources in an unidirectional order <em>throughout the entire application</em>:</p>
</div>
<div class="listingblock data-line-2763">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">acquire(A);
acquire(B);
acquire(C);
   .
   .
   .
release(C);
release(B);
release(A);</code></pre>
</div>
</div>
<div class="paragraph data-line-2779">
<p>This breaks circular waiting.</p>
</div>
<div class="paragraph data-line-2781">
<p>For instance:</p>
</div>
<div class="listingblock data-line-2783">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">TaskA:
   wait(R1);
   wait(R2);
    /* critical section */
   signal(R2);
   signal(R1);

TaskB:
   wait(R1);
   wait(R2);
    /* critical section */
   signal(R2);
   signal(R1);</code></pre>
</div>
</div>
<div class="paragraph data-line-2801">
<p>But, if:</p>
</div>
<div class="listingblock data-line-2803">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">TaskA:
    wait(R1);
    wait(R2);
    .
    .

TaskB:
    wait(R2);
    wait(R1);
    .
    .</code></pre>
</div>
</div>
<div class="paragraph data-line-2817">
<p>There are some possible outcomes:</p>
</div>
<div class="olist arabic data-line-2819">
<ol class="arabic">
<li class="data-line-2819">
<p>Deadlock:</p>
<div class="ulist data-line-2821">
<ul>
<li class="data-line-2821">
<p>TaskA runs: acquires R1</p>
</li>
<li class="data-line-2822">
<p>TaskB runs: acquires R2</p>
</li>
<li class="data-line-2823">
<p>TaskA runs: tries to acquire R2 — blocked</p>
</li>
<li class="data-line-2824">
<p>TaskB runs: tries to acquire R1 — blocked</p>
</li>
</ul>
</div>
</li>
<li class="data-line-2826">
<p>No deadlock:</p>
<div class="ulist data-line-2828">
<ul>
<li class="data-line-2828">
<p>TaskA runs: acquires R1</p>
</li>
<li class="data-line-2830">
<p>TaskA runs: acquires R2 (nobody is holding R2)</p>
</li>
<li class="data-line-2832">
<p>TaskA releases both; TaskB runs and acquires both (in either order)</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph data-line-2835">
<p>Overall, there is no deadlock if tasks do not overlap in critical sections. That is why systems run for years without deadlocks and eventually: <em>ploft</em>.</p>
</div>
<div class="ulist data-line-2838">
<ul>
<li class="data-line-2838">
<p>Use a 'master-lock' with 'try' semantics:</p>
</li>
</ul>
</div>
<div class="paragraph data-line-2840">
<p>Another technique that can be employed is if one needs to acquire multiple locks—acquire them all or none using a try-lock (<code>RK_NO_WAIT</code>). If any of the tries fail, the task gives up on acquiring the resources and backs off, releasing all successful locks to retry later (most simply, using a sleep queue). That is easier said than done, though, and, as mentioned, if not well done, instead of deadlocks, one gets livelocks.</p>
</div>
<div class="paragraph data-line-2842">
<p>(<em>Livelocks</em> are when a couple of tasks keep running, but the program does not advance.)</p>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-2845">
<h2 id="rk0_services_api">7. <em><strong>RK0 Services API</strong></em></h2>
<div class="sectionbody">
<div class="sect2 data-line-2847">
<h3 id="convention">7.1. Convention</h3>
<div class="ulist data-line-2849">
<ul>
<li class="data-line-2849">
<p>A kernel call starts with a lowercase <code>k</code>. Typically it is followed by a kernel object identifier and an action.</p>
</li>
</ul>
</div>
<div class="listingblock data-line-2851">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">kSemaphorePend(&amp;sema, 800); /* pend on a semaphore; 800 ticks time-out */</code></pre>
</div>
</div>
<div class="ulist data-line-2855">
<ul>
<li class="data-line-2855">
<p>When <code>k</code> is followed by an action, it is acting on the caller task.</p>
</li>
</ul>
</div>
<div class="listingblock data-line-2857">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">kSleep(150); /* sleep the caller task for 150 ticks */</code></pre>
</div>
</div>
<div class="ulist data-line-2861">
<ul>
<li class="data-line-2861">
<p>Some calls can act either on the caller or on another task:</p>
</li>
</ul>
</div>
<div class="listingblock data-line-2863">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* stores the signal flags of the task identified by task1Handle on queryValue */
kTaskEventQuery(task1Handle, &amp;queryValue);

/* retrieves its own signal flags */
kTaskEventQuery(NULL, &amp;queryValue);</code></pre>
</div>
</div>
</div>
<div class="sect2 data-line-2871">
<h3 id="return_values">7.2. Return Values</h3>
<div class="paragraph data-line-2873">
<p>With a few exceptions, kernel calls return a <code>RK_ERR</code> error code. <code>0</code> is a successful operation <code>(RK_ERR_SUCCESS)</code> and any negative value is an error that indicates failure.
A positive value is an unsuccessful operation, but will not lead the system to failure (e.g., any unsuccessful <code>try</code> operation).</p>
</div>
<hr>
<div class="paragraph data-line-2877">
<p><code>kapi.h</code>:
<a href="https://github.com/antoniogiacomelli/RK0/blob/main/core/inc/kapi.h">RK0 API</a></p>
</div>
<hr>
<div class="imageblock text-center data-line-2883">
<div class="content">
<img src="https://kernel0org.wordpress.com/wp-content/uploads/2024/12/k0ba_logo.png" alt="k0ba logo" width="20%">
</div>
</div>
<div class="paragraph data-line-2885">
<p>&#169; <em>2026 Antonio Giacomelli | All Rights Reserved | <a href="http://kernel0.org/">www.kernel0.org</a></em></p>
</div>
</div>
</div>
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
</body>
</html>
