<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.20">
<meta name="author" content="System: 0.4.0-dev | Docbook: 2503261">
<title>RK0: The Real-Time Kernel '0'</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/styles/github.min.css">
</head>
<body class="article toc2 toc-left data-line-1">
<div id="header">
<h1>RK0: The Real-Time Kernel '0'</h1>
<div class="details">
<span id="author" class="author">System: 0.4.0-dev | Docbook: 2503261</span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#the_kernel_on_a_glance">1. THE KERNEL ON A GLANCE</a>
<ul class="sectlevel2">
<li><a href="#the_design_approach">1.1. The design approach</a></li>
<li><a href="#a_real_time_executive">1.2. A Real-Time <em>Executive</em></a></li>
<li><a href="#flat_model">1.3. Flat Model</a></li>
<li><a href="#rk0_is_not_different">1.4. <strong>RK</strong><em>0</em> is (not) different</a></li>
</ul>
</li>
<li><a href="#core_mechanisms">2. <strong><em>Core Mechanisms</em></strong></a>
<ul class="sectlevel2">
<li><a href="#data_structures">2.1. Data Structures</a>
<ul class="sectlevel3">
<li><a href="#task_control_block">2.1.1. Task Control Block</a></li>
<li><a href="#task_queues">2.1.2. Task Queues</a></li>
<li><a href="#ready_queue_table">2.1.3. Ready Queue Table</a></li>
<li><a href="#waiting_queues">2.1.4. Waiting Queues</a></li>
</ul>
</li>
<li><a href="#rate_monotonic_scheduler">2.2. Rate Monotonic Scheduler</a>
<ul class="sectlevel3">
<li><a href="#the_scheduling_algorithm">2.2.1. The scheduling algorithm</a></li>
</ul>
</li>
<li><a href="#scheduler_determinism">2.3. Scheduler Determinism</a>
<ul class="sectlevel3">
<li><a href="#preemptive_scheduling">2.3.1. Preemptive Scheduling</a></li>
<li><a href="#cooperative_scheduling">2.3.2. Cooperative Scheduling</a></li>
<li><a href="#time_slice_scheduling">2.3.3. Time-Slice Scheduling</a></li>
<li><a href="#common_scheduling_pitfalls">2.3.4. Common scheduling pitfalls</a></li>
</ul>
</li>
<li><a href="#timers">2.4. <strong>Timers</strong></a>
<ul class="sectlevel3">
<li><a href="#sleep_timers">2.4.1. Sleep Timers</a></li>
<li><a href="#blocking_time_out">2.4.2. Blocking Time-out</a></li>
<li><a href="#callout_timers">2.4.3. Callout Timers</a></li>
</ul>
</li>
<li><a href="#system_tick">2.5. <strong>System Tick</strong></a></li>
<li><a href="#memory_allocator">2.6. <strong>Memory Allocator</strong></a>
<ul class="sectlevel3">
<li><a href="#how_it_works">2.6.1. How it works</a></li>
<li><a href="#memory_allocator_determinism">2.6.2. Memory Allocator Determinism</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#inter_task_communication_itc">3. <strong><em>Inter-task communication (ITC)</em></strong></a></li>
<li><a href="#synchronisation_mechanisms">4. <strong>Synchronisation mechanisms</strong></a>
<ul class="sectlevel2">
<li><a href="#events_sleepwake">4.1. Events (Sleep/Wake)</a></li>
<li><a href="#semaphores">4.2. Semaphores</a>
<ul class="sectlevel3">
<li><a href="#counter_semaphore">4.2.1. Counter Semaphore</a></li>
<li><a href="#private_binary_semaphores">4.2.2. Private Binary Semaphores</a></li>
<li><a href="#mutex_semaphore">4.2.3. Mutex Semaphore</a>
<ul class="sectlevel4">
<li><a href="#priority_inversion">4.2.3.1. Priority Inversion</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#condition_variables">4.3. Condition Variables</a></li>
<li><a href="#task_flags_signals">4.4. Task Flags (Signals)</a></li>
<li><a href="#event_flags_or_event_group">4.5. Event Flags (or Event Group)</a>
<ul class="sectlevel3">
<li><a href="#usage_example">4.5.1. Usage Example</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#message_passing">5. <strong>Message Passing</strong></a>
<ul class="sectlevel2">
<li><a href="#mailbox">5.1. Mailbox</a>
<ul class="sectlevel3">
<li><a href="#usage_example_zero_buffer_channel">5.1.1. Usage Example: <em>Zero-Buffer</em> Channel</a></li>
<li><a href="#usage_example_2_multi_client_server_synchronous_command_response">5.1.2. Usage Example 2: Multi-client-server synchronous command-response</a></li>
</ul>
</li>
<li><a href="#mail_queue">5.2. Mail Queue</a>
<ul class="sectlevel3">
<li><a href="#usage_example_asynchronous_zero_copy_message_passing">5.2.1. Usage Example: Asynchronous 'Zero-copy' Message Passing</a></li>
</ul>
</li>
<li><a href="#stream_queue">5.3. Stream Queue</a>
<ul class="sectlevel3">
<li><a href="#stream_message_size">5.3.1. Stream Message-Size</a></li>
<li><a href="#usage_example_averaging_sensor_values">5.3.2. Usage Example: Averaging Sensor Values</a></li>
<li><a href="#summing_up_stream_queues_vs_mail_queues">5.3.3. Summing Up: Stream Queues vs Mail Queues</a></li>
</ul>
</li>
<li><a href="#message_passing_ownership">5.4. Message Passing ownership</a>
<ul class="sectlevel3">
<li><a href="#priority_inversion_on_message_passing">5.4.1. Priority Inversion on Message Passing</a></li>
</ul>
</li>
<li><a href="#most_recent_message_protocol_mrm">5.5. Most-Recent Message Protocol (MRM)</a>
<ul class="sectlevel3">
<li><a href="#functional_description">5.5.1. Functional Description</a></li>
<li><a href="#mrm_control_block_configuration">5.5.2. MRM Control Block Configuration</a></li>
<li><a href="#usage_example_2">5.5.3. Usage Example</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#what_is_missing">6. <strong>What is missing</strong></a></li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1 data-line-11">
<h2 id="the_kernel_on_a_glance">1. THE KERNEL ON A GLANCE</h2>
<div class="sectionbody">
<div class="admonitionblock note data-line-15">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist data-line-17">
<ul>
<li class="data-line-17">
<p>This Docbook is not meant to cover API details. API details can be found at the project repository:
<a href="https://github.com/antoniogiacomelli/RK0/blob/master/Inc/kapi.h">RK0 API</a></p>
</li>
<li class="data-line-20">
<p><strong><em>RK0</em></strong> is a work in progress.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2 data-line-23">
<h3 id="the_design_approach">1.1. The design approach</h3>
<div class="admonitionblock warning data-line-26">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph data-line-27">
<p><em><strong>RK0</strong></em> is <em>NOT that</em> RTOS which&#8230;&#8203;</p>
</div>
<div class="quoteblock data-line-29">
<blockquote>
IPC was inspired on NextSTEP&#8212;&#8203;with some Amoeba; a piconanomicrokernel, but as hardened as OpenBSD. Indeed it is a '<em>little OpenVMS brother</em>', for 16KB RAM, and no MMU.
<em>&lt;audience&#8217;s laughter&gt;</em>
</blockquote>
</div>
<div class="paragraph data-line-33">
<p>It is a plain <em>"Real-Time Executive"</em>; it is <em>'ridiculously' <strong>embedded real-time</strong></em> - as-we-know-it. Every design choice documented here is driven by the goal of making it as deterministic as a pendulum.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-36">
<p><strong>RK<em>0</em></strong> (or simply <em>K0</em>) is built on the fundamental understanding that systems programming in general, particularly embedded systems programming, is (very) unique and requires a direct approach - rather than an application-like framework model.</p>
</div>
<div class="paragraph data-line-38">
<p>One programming an embedded system with <em>K0</em> does not approach the endeavour as an application programmer but as a <em>systems programmer</em>, looking to maintain complete control to ensure efficiency and predictable behaviour.</p>
</div>
<div class="paragraph data-line-40">
<p>Feature-wise, <em>K0</em> aims providing a balanced set of composable simple primitives - yielding more controllability and observability than opaque, complex features.</p>
</div>
</div>
<div class="sect2 data-line-42">
<h3 id="a_real_time_executive">1.2. A Real-Time <em>Executive</em></h3>
<div class="paragraph data-line-44">
<p>If no more details are to be provided, the kernel has a top and a bottom layer - on the top, the <em>Executive</em>  manages the resources needed by the application; on the bottom, the <em>Low-level Scheduler</em> works as a software extension of the CPU.</p>
</div>
<div class="paragraph data-line-46">
<p>Together, they implement the <em>Task</em> concept and provide the primitives for a programmable multitasking environment.</p>
</div>
<div class="imageblock data-line-48">
<div class="content">
<img src="images/images/layeredkernel.png" alt="layeredkernel">
</div>
</div>
<div class="paragraph data-line-50">
<p>A process is composed of an execution image and an address space. A thread is a logical sequence of instructions. Several threads coexist in the same address space within the same process.</p>
</div>
<div class="paragraph data-line-52">
<p>On the embedded realm, probably because we lack a better abstraction, we use multithreading to fine-tune our load balance and, therefore, responsiveness to achieve real-time.</p>
</div>
<div class="paragraph data-line-54">
<p>This is an arrangement: instead of having a single super-loop, we have many, each running on its own execution stack.</p>
</div>
<div class="paragraph data-line-56">
<p>This arrangement yields an operating system entity to handle—a (logical) <em>Execution Unit</em>: in K0, we name it a <em>Task</em> (the terms task and thread are used interchangeably in this document).</p>
</div>
</div>
<div class="sect2 data-line-58">
<h3 id="flat_model">1.3. Flat Model</h3>
<div class="paragraph data-line-60">
<p>The <em>K0</em> multitasking engine is wired to a single process on a single address space - as the majority of small kernels you see around (regardless the claims of being <em>micro</em>, <em>nano</em> or <em>pico</em> kernels).</p>
</div>
<div class="paragraph data-line-62">
<p>Low-end MCUs based on the supported architecture (ARMv7M) often do not come with a Memory Protection Unit - so privilege levels are limited to the CPU scope: instructions and registers. This level of safety does not compensate for the overhead of system calls, as they harm determinism and responsiveness.</p>
</div>
<div class="paragraph data-line-64">
<p>As of today, <em>K0</em> is a one-man effort. Thus, supporting a wide range of CPU architectures is not on the radar. The plan is to support a few with quality.</p>
</div>
</div>
<div class="sect2 data-line-67">
<h3 id="rk0_is_not_different">1.4. <strong>RK</strong><em>0</em> is (not) different</h3>
<div class="paragraph data-line-69">
<p><em>RK0</em> adheres to traditional RTOS coding practice and style (uCOS/OS, ThreadX, Nucleus, to name a few)&#8201;&#8212;&#8201;the code diverges from application-level practices that are incompatible with systems programming requirements.</p>
</div>
<div class="paragraph data-line-71">
<p>At this design phase, performance prevails. Close second comes debuggability and observability. For instance, pattern repetition is preferred over abstractions that would introduce unnecessary coupling and complicate maintenance. Opaque generalisations hardly have a place&#8201;&#8212;&#8201;this approach extends to the final artifact: <em>nevermind</em> a pre-compiled library with opaque handles.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1 data-line-75">
<h2 id="core_mechanisms">2. <strong><em>Core Mechanisms</em></strong></h2>
<div class="sectionbody">
<div class="paragraph data-line-77">
<p>This section provides a high-level description of the kernel core mechanisms: scheduler, timers, and memory allocator.</p>
</div>
<div class="sect2 data-line-80">
<h3 id="data_structures">2.1. Data Structures</h3>
<div class="sect3 data-line-82">
<h4 id="task_control_block">2.1.1. Task Control Block</h4>
<div class="paragraph data-line-84">
<p>Threads are represented as Tasks. Every task is associated to a Task Control Block structure. This is a record for stack, resources and time management. The table below represent a Task Control Block with all optional features enabled.</p>
</div>
<table class="tableblock frame-all grid-all stretch data-line-87">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Task Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Task name</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Saved Stack Pointer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stack Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stack Size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Status (ready, running, sending…​)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Assigned Priority</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Current Priority</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Time-Slice</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remaining time-slice</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Last wake-time</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Binary Semaphore Status</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Event Flags</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Self-Assigned ID</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Run-To-Completion Flag</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Time-out Flag</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aggregated Timeout Node</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aggregated Task List Node</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-108">
<p>Tasks are static - they cannot be created on runtime, to be destroyed, to fork or join.</p>
</div>
<div class="paragraph data-line-110">
<p>In practice, tasks are either <em>RUNNING</em> or '<em>waiting</em>' for their turn to run. Now, we need to clearly define  <em>WAITING</em> and <em>READY</em>.</p>
</div>
<div class="olist arabic data-line-112">
<ol class="arabic">
<li class="data-line-112">
<p>A <em>READY</em> task will be dispatched - therefore, switch to <em>RUNNING</em>, whenever it is the highest priority <em>READY</em> task.</p>
</li>
<li class="data-line-114">
<p>A <em>WAITING</em> (or <em>SLEEPING</em>) task depends on a condition, generalised as an <em>event</em> to switch to <em>READY</em>.</p>
</li>
</ol>
</div>
<div class="imageblock data-line-117">
<div class="content">
<img src="images/images/taskstates.png" alt="taskstates">
</div>
</div>
<div class="paragraph data-line-119">
<p>Logically, the <em>WAITING</em> state will assume different pseudo-states, related to the kind of event that will switch a task to <em>READY</em>:</p>
</div>
<div class="ulist data-line-121">
<ul>
<li class="data-line-121">
<p>PENDING/PENDING_FLAGS : the task suspended itself waiting for a direct signal, or for a combination of signal flags.</p>
</li>
<li class="data-line-123">
<p>SLEEPING: A task is normally sleeping for an event. We explore this broad concept a bit later.</p>
</li>
<li class="data-line-125">
<p>BLOCKED: A task is blocked in a critical region when trying to access a busy resource.</p>
</li>
<li class="data-line-127">
<p>SENDING/RECEIVING: This is the same as blocked, but the busy resource is a kernel object for the message passing (or similar) mechanism.</p>
</li>
</ul>
</div>
<div class="admonitionblock tip data-line-131">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-132">
<p><em>Problem</em>: Dynamically creating and destroying tasks in an embedded system can lead to unpredictable timing and possible memory fragmentation.</p>
</div>
<div class="paragraph data-line-134">
<p><em>Design Choice</em>: RK0 uses static tasks (no creation at runtime).</p>
</div>
<div class="paragraph data-line-136">
<p><em>Benefit</em>: Eliminates runtime overhead or fragmentation from task creation/destruction, contributing to strict timing guarantees.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="exampleblock data-line-139">
<div class="content">
<div class="paragraph data-line-140">
<p><strong><em>The scheduler rules, not the heap.</em></strong></p>
</div>
<div class="paragraph data-line-142">
<p><em>RK0</em> tasks are static.</p>
</div>
<div class="paragraph data-line-144">
<p>It’s a design decision rooted in real-time correctness.</p>
</div>
<div class="paragraph data-line-146">
<p>Stacks are defined and passed explicitly when creating a task.</p>
</div>
<div class="paragraph data-line-148">
<p>The wins:</p>
</div>
<div class="ulist data-line-150">
<ul>
<li class="data-line-150">
<p>A memory layout the systems programmer actually knows.</p>
</li>
<li class="data-line-151">
<p>No alignment traps.</p>
</li>
<li class="data-line-152">
<p>Link-time visibility:</p>
<div class="ulist data-line-153">
<ul>
<li class="data-line-153">
<p>Each task’s stack is a named symbol in the linker map.</p>
</li>
<li class="data-line-154">
<p>You can inspect and verify the memory layout before flashing.</p>
</li>
<li class="data-line-155">
<p>A simple <code>objdump</code> reveals all stack allocations — that’s peace of mind.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="imageblock data-line-160">
<div class="content">
<img src="images/images/schdatastruct.png" alt="schdatastruct" width="85%">
</div>
</div>
</div>
<div class="sect3 data-line-162">
<h4 id="task_queues">2.1.2. Task Queues</h4>
<div class="paragraph data-line-163">
<p>The backbone of the queues where tasks will wait for their turn to run is a circular doubly linked list: removing any item from a doubly list takes O(1) (provided we don’t need to search the item). As the kernel knows each task’s address, adding and removing is always O(1). Singly linked lists, can’t achieve O(1) for removal in any case.</p>
</div>
</div>
<div class="sect3 data-line-165">
<h4 id="ready_queue_table">2.1.3. Ready Queue Table</h4>
<div class="paragraph data-line-167">
<p>Another design choice towards achieving O(1) is the global ready queue, which is a table of FIFO queues—each queue dedicated to a priority—and not a single ordered queue. So, enqueuing a ready task is always O(1). Given the sorting needed, if tasks were placed on a single ready queue, the time complexity would be O(n).</p>
</div>
</div>
<div class="sect3 data-line-169">
<h4 id="waiting_queues">2.1.4. Waiting Queues</h4>
<div class="paragraph data-line-171">
<p>The scheduler does not have a unique waiting queue. Every kernel object that has the ability to block a task has an associated waiting queue. Because these  queues are a scheduler component, <em>they follow a priority discipline</em>: the highest priority task is dequeued first, <em>always</em>.</p>
</div>
<div class="paragraph data-line-173">
<p>When an event capable to switch tasks from <em>WAITING</em> to <em>READY</em> happens, one or more tasks (depending on the mechanism) are then placed on the ready list, unique to is priority. Now they are waiting to be picked by the scheduler - that is <em>READY</em> definition.</p>
</div>
</div>
</div>
<div class="sect2 data-line-175">
<h3 id="rate_monotonic_scheduler">2.2. Rate Monotonic Scheduler</h3>
<div class="paragraph data-line-177">
<p><em>RK0</em> employs a Rate Monotonic Scheduler. Tasks are assigned priorities accordingly to their request rates - i.e., tasks with shorter periods are assigned to higher priorities.</p>
</div>
<div class="paragraph data-line-179">
<p>Theoretically a set of tasks is schedulable up to a utilisation factor of ~69%. As a sanity check, the programmer must ensure the Idle Task is running at the very least, ~30% of the time.</p>
</div>
<div class="paragraph data-line-181">
<p>The design leverages a highly efficient and deterministic algorithm, to select the highest priority task amongst a set of <em>READY</em> tasks of different priorities. This is detailed and demonstrated on the following sections.</p>
</div>
<div class="sect3 data-line-183">
<h4 id="the_scheduling_algorithm">2.2.1. The scheduling algorithm</h4>
<div class="admonitionblock tip data-line-186">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-187">
<p>Searching a single ready-queue for the highest-priority task can introduce variable latencies if it requires sorting or scanning.</p>
</div>
<div class="paragraph data-line-189">
<p>Design Choice: Per-priority queues indexed by a 32-bit bitmask (one queue per priority).</p>
</div>
<div class="paragraph data-line-191">
<p>Benefit: O(1) scheduling lookups—finding the highest-priority ready task is always immediate, even under heavy load.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-194">
<p>As the ready queue table is indexed by priority - the index 0 points to the queue of ready tasks with priority 0, and so forth, and there are 32 possible priorities - a 32-bit integer can represent the state of the ready queue table. It is a BITMAP:</p>
</div>
<div class="listingblock data-line-196">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">The BITMAP computation: ((1a) OR (1b)) AND (2), s.t.:

(1a) Every Time a task is readied, update: BITMAP |= (1U &lt;&lt; task-&gt;priority );
(1b) Every Time an empty READY QUEUE becomes non-empty, update: BITMAP |= (1U &lt;&lt; queueIndex)
(2): Every Time READY QUEUE becomes empty, update: BITMAP &amp;= ~(1U &lt;&lt; queueIndex);
EXAMPLE:

  Ready Queue Index :     (6)5 4 3 2 1 0
          Not empty :      1 1 1 0 0 1 0
                           -------------&gt;
                 (LOW)  Effective Priority  (HIGH)
In this case, the scenario is a system with 7 priority task levels. Queues with priorities 6, 5, 4, and 1 are not empty.</code></pre>
</div>
</div>
<div class="paragraph data-line-213">
<p>In RK0 source code, you will find the following to implement the bitmap update:</p>
</div>
<div class="listingblock data-line-215">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* Enqueue a TCBs on a List Of TCBs */
RK_ERR kTCBQEnq( RK_TCBQ *const kobj, RK_TCB *const tcbPtr)
{

    RK_CR_AREA
    RK_CR_ENTER
    if (kobj == NULL || tcbPtr == NULL)
    {
        kErrHandler( RK_FAULT_OBJ_NULL);
    }
    RK_ERR err = kListAddTail( kobj, &amp;(tcbPtr-&gt;tcbNode));
    if (err == 0)
    {
        /* if the list in the ready queue table */
         /* update ready task bitmap */
        if (kobj == &amp;readyQueue[tcbPtr-&gt;priority])
            readyQBitMask |= 1 &lt;&lt; tcbPtr-&gt;priority;
    }
    RK_CR_EXIT
    return (err);
}
/* Dequeue the head task on a list of TCBs */
RK_ERR kTCBQDeq( RK_TCBQ *const kobj, RK_TCB **const tcbPPtr)
{
    if (kobj == NULL)
    {
        kErrHandler( RK_FAULT_OBJ_NULL);
    }
    RK_NODE *dequeuedNodePtr = NULL;
    RK_ERR err = kListRemoveHead( kobj, &amp;dequeuedNodePtr);

    if (err != RK_SUCCESS)
    {
        return (err);
    }
    *tcbPPtr = RK_LIST_GET_TCB_NODE( dequeuedNodePtr, RK_TCB);

    if (*tcbPPtr == NULL)
    {
        kErrHandler( RK_FAULT_OBJ_NULL);
        return (RK_ERR_OBJ_NULL);
    }
    RK_TCB *tcbPtr_ = *tcbPPtr;
    RK_PRIO prio_ = tcbPtr_-&gt;priority;

    /* if the list in the ready queue table */
    /* update ready task bitmap */
    if ((kobj == &amp;readyQueue[prio_]) &amp;&amp; (kobj-&gt;size == 0))
        readyQBitMask &amp;= ~(1U &lt;&lt; prio_);

    return (RK_SUCCESS);
}

/* Remove an specific TCB from a TCB List */
RK_ERR kTCBQRem( RK_TCBQ *const kobj, RK_TCB **const tcbPPtr)
{
    if (kobj == NULL || tcbPPtr == NULL)
    {
        kErrHandler( RK_FAULT_OBJ_NULL);
    }
    RK_NODE *dequeuedNodePtr = &amp;((*tcbPPtr)-&gt;tcbNode);
    RK_ERR err = kListRemove( kobj, dequeuedNodePtr);
    if (err != RK_SUCCESS)
    {
        return (err);
    }
    *tcbPPtr = RK_LIST_GET_TCB_NODE( dequeuedNodePtr, RK_TCB);
    if (*tcbPPtr == NULL)
    {
        kErrHandler( RK_FAULT_OBJ_NULL);
    }
    RK_TCB *tcbPtr_ = *tcbPPtr;
    RK_PRIO prio_ = tcbPtr_-&gt;priority;

   /* if list is in ready queue table */
   /* update ready task bitmap        */
    if ((kobj == &amp;readyQueue[prio_]) &amp;&amp; (kobj-&gt;size == 0))
          readyQBitMask &amp;= ~(1U &lt;&lt; prio_);

    return (RK_SUCCESS);
}</code></pre>
</div>
</div>
<div class="paragraph data-line-300">
<p>The idle task priority is assigned by the kernel, during initialisation, taking into account all priorities the system programmer has defined. Unless user tasks are occupying all 32 priorities, the Idle Task is treated as an ordinary lowest priority and has a position in the queue. If not, the idle task on practice will have no queue position and will be selected when the BITMAP is 0. In the above bitmap, the idle task is in readyQueue[6].</p>
</div>
<div class="paragraph data-line-302">
<p>Given this mask, we know that we shall start inspecting on the LSBit and stop when the first 1 is found. There are uncountable manners of doing this. The approach I chose is:</p>
</div>
<div class="paragraph data-line-304">
<p>(1) Isolate the rightmost '1':</p>
</div>
<div class="listingblock data-line-306">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">RBITMAP = BITMAP &amp; -BITMAP. (- is the bitwise operator for two's complement: ~BITMAP + 1) `</code></pre>
</div>
</div>
<div class="paragraph data-line-310">
<p>In this case:</p>
</div>
<div class="listingblock data-line-312">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">                           [31]       [0]  :  Bit Position
                             0...1110010   :  BITMAP
                             1...0001110   : -BITMAP
                            =============
                             0...0000010   :  RBITMAP
                                     [1]</code></pre>
</div>
</div>
<div class="paragraph data-line-322">
<p><em>The rationale here is that, for a number N, its 2’s complement -N, flips all bits - except the rightmost '1' (by adding '1') . Then, N &amp; -N results in a word with all 0-bits except for the less significant '1'.</em></p>
</div>
<div class="paragraph data-line-324">
<p>(2) Extract the rightmost '1' position:</p>
</div>
<div class="paragraph data-line-326">
<p>Within GCC, the <em>_builtin_ctz()</em> function does the trick: it returns the number of <em>trailing</em> 0 bits within an integer, starting from the LSbit. The number of 'trailing zeroes' equals the position where the first '1' is found, which is also the ready queue index (and hence the priority) of the next task to be dispatched.</p>
</div>
<div class="paragraph data-line-328">
<p>Using ARMv7M instructions, a possible solution is to use the CLZ (count lead zeros):</p>
</div>
<div class="listingblock data-line-330">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">.global __getReadyPrio
.type __getReadyPrio, %function
.thumb_func
__getReadyPrio:
CLZ  R12, R0
MOV  R0, R12
NEG  R0, R0
ADD  R0, #31

BX LR</code></pre>
</div>
</div>
<div class="paragraph data-line-343">
<p>Thus, we subtract 31 from the number of leading zeroes, and get the index.</p>
</div>
<div class="paragraph data-line-345">
<p>The source code in RK0 looks like:</p>
</div>
<div class="listingblock data-line-347">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">static inline PRIO kCalcNextTaskPrio_()
{
    if (readyQBitMask == 0U)
    {
        return (idleTaskPrio);
    }
    readyQRightMask = readyQBitMask &amp; -readyQBitMask;
    PRIO prioVal = (PRIO) (__getReadyPrio(readyQRightMask));
    return (prioVal);
    /* or GCC builtin (more portable): */
    /* return (PRIO)(__builtin_ctz(readyQRightMask)); */
}

VOID kSchSwtch(VOID)
{
    /* O(1) complexity */
	nextTaskPrio = calcNextTaskPrio_();

	RK_TCB* nextRunPtr = NULL;

	/* O(1) complexity */
	RK_ERR err = kTCBQDeq( &amp;readyQueue[nextTaskPrio], &amp;nextRunPtr);
	if ((nextRunPtr == NULL) || (err != RK_SUCCESS))
	{
	    kErrHandler(FAULT_READYQ);
	}
	runPtr = nextRunPtr;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2 data-line-379">
<h3 id="scheduler_determinism">2.3. Scheduler Determinism</h3>
<div class="sect3 data-line-380">
<h4 id="preemptive_scheduling">2.3.1. Preemptive Scheduling</h4>
<div class="paragraph data-line-381">
<p>This is a simple test to establish some evidence the scheduler obeys the pre-emption criteria: a higher priority task always pre-empts a lower priority task.</p>
</div>
<div class="paragraph data-line-383">
<p>Task1, 2, 3, 4 are in descending order of priority. If the scheduler is well-behaved, we shall see counters differing by "1".</p>
</div>
<div class="listingblock data-line-385">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">VOID Task1(VOID* args)
{
    RK_UNUSEARGS
	while(1)
	{
		counter1++;
		kPend(RK_WAIT_FOREVER);
	}
}

VOID Task2(VOID* args)
{
    RK_UNUSEARGS
	while(1)
	{
		counter2++;
		kSignal(task1Handle); /* shall immediately be preempted by task1 */
		kPend(RK_WAIT_FOREVER);    /* suspends again */
	}
}


VOID Task3(VOID* args)
{
    RK_UNUSEARGS
	while(1)
	{
		counter3++;
		kSignal(task2Handle);  /* shall immediately be preempted by task2 */
		kPend(RK_WAIT_FOREVER); /* suspends again */
	}
}

VOID Task4(VOID* args)
{
    RK_UNUSEARGS
	while(1)
	{
	    counter4++;
	    /* shall immediately be preempted by task3 */
	    kSignal(task3Handle); /
	    /* only resumes after all tasks are pending again */
	}
}</code></pre>
</div>
</div>
<div class="paragraph data-line-434">
<p>This is the output after some time running:</p>
</div>
<div class="imageblock data-line-436">
<div class="content">
<img src="images/images/signaldet.png" alt="signaldet">
</div>
</div>
<div class="paragraph data-line-438">
<p>In the above example we have used direct signals. Using semaphores:</p>
</div>
<div class="listingblock data-line-440">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">RK_SEMA sema1;
RK_SEMA sema2;
RK_SEMA sema3;
RK_SEMA sema4;

VOID kApplicationInit(VOID)
{
	kSemaInit(&amp;sema1, 0);
	kSemaInit(&amp;sema2, 0);
	kSemaInit(&amp;sema3, 0);
	kSemaInit(&amp;sema4, 0);

}

VOID Task1(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		counter1++;
		kSemaWait(&amp;sema1, RK_WAIT_FOREVER);
	}
}

VOID Task2(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		counter2++;
		kSemaSignal(&amp;sema1);
		kSemaWait(&amp;sema2, RK_WAIT_FOREVER);
	}
}

VOID Task3(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		counter3++;
		kSemaSignal(&amp;sema2);
		kSemaWait(&amp;sema3, RK_WAIT_FOREVER);
	}
}

VOID Task4(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{

		counter4++;
		kSemaSignal(&amp;sema3);
	}
}</code></pre>
</div>
</div>
<div class="imageblock data-line-500">
<div class="content">
<img src="images/images/determsema.png" alt="determsema">
</div>
</div>
<div class="paragraph data-line-502">
<p>Here tick is running @ 0.5us</p>
</div>
</div>
<div class="sect3 data-line-504">
<h4 id="cooperative_scheduling">2.3.2. Cooperative Scheduling</h4>
<div class="paragraph data-line-506">
<p>If we set all tasks at the same priority and every tasks yields the processor, they will run on a round-robin fashion, one after another. So, every time we pause chances are we will be "somewhere in the middle" of a round.</p>
</div>
<div class="paragraph data-line-508">
<p>If every task increases a counter before yielding what we expect to see is a set of counters on a fashion {K, K, K, K-1, K-1, K-1}. Importantly a counter will not offset another by more than 1 if the scheduler is deterministic.</p>
</div>
<div class="listingblock data-line-510">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* All tasks have the same priority */
VOID Task1(VOID* args)
{
    RK_UNUSEARGS

	while (1)
	{
		count1 += 1;
		kYield();
	}
}

VOID Task2(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		count2 += 1;
		kYield();
	}
}

VOID Task3(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		count3 += 1;
		kYield();
	}
}

VOID Task4(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		count4 += 1;
		kYield();
	}

}

VOID Task5(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		count5 += 1;
		kYield();
	}

}</code></pre>
</div>
</div>
<div class="paragraph data-line-566">
<p>The picture below show the results after ~ 13 million rounds.</p>
</div>
<div class="imageblock data-line-569">
<div class="content">
<img src="images/images/determrr.png" alt="determrr">
</div>
</div>
</div>
<div class="sect3 data-line-573">
<h4 id="time_slice_scheduling">2.3.3. Time-Slice Scheduling</h4>
<div class="paragraph data-line-575">
<p>Now we turn time-slice scheduling ON. It means every task will have a fixed-time to run, and the scheduler itself will switch a task to <em>READY</em> after this time is due.</p>
</div>
<div class="listingblock data-line-577">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">volatile UINT count1, count2, count3, count4, count5;

VOID kApplicationInit( VOID)
{
	count1=0;
	count2=0;
	count3=0;
	count4=0;
	count5=0;
}

VOID Task1( VOID* args)
{
    RK_UNUSEARGS
 	while (1)
	{
 		count1++;
    	}
}

VOID Task2( VOID* args)
{
    RK_UNUSEARGS
 	while (1)
	{
 		count2++;

	}
}

VOID Task3( VOID* args)
{
    RK_UNUSEARGS
 	while (1)
	{

 		count3++;

	}
}

VOID Task4( VOID* args)
{
    RK_UNUSEARGS
 	while (1)
	{
 		count4++;
 	}
}

VOID Task5( VOID* args)
{
    RK_UNUSEARGS
 	while (1)
	{
 		count5++;

   	}
}</code></pre>
</div>
</div>
<div class="paragraph data-line-640">
<p>The configuration here is all tasks with the same priority (so they round-robin), and 1 single tick as time-slice. The System Tick is at <em>0.5 ms</em>.
So, each task has 500us to run.
The results on the picture show the variable counters within each task, and the "<em>run counter</em>" of each task - the number of times each task has been dispatched, after ~2.1 million ticks.</p>
</div>
<div class="imageblock data-line-644">
<div class="content">
<img src="images/images/determtimeslice.png" alt="determtimeslice" width="70%">
</div>
</div>
<div class="paragraph data-line-646">
<p><em>500us</em> is a quite tight pocket. Let us see some numbers:</p>
</div>
<div class="ulist data-line-649">
<ul>
<li class="data-line-649">
<p>Mean Count: 320,225,964</p>
</li>
<li class="data-line-650">
<p>Standard Deviation: 332.21</p>
</li>
<li class="data-line-651">
<p>Min Count: 320,225,382 (Task5)</p>
</li>
<li class="data-line-652">
<p>Max Count: 320,226,167 (Task1)</p>
</li>
<li class="data-line-653">
<p>Range (Max - Min): 785</p>
</li>
</ul>
</div>
<div class="paragraph data-line-656">
<p>The variation is already negligibile - <em>~0.00025%</em> relative to the mean. Plus further tests have shown the range remains constant over time - that is to say, on a 24/7 system, we can talk about near-perfect fairness scheduling.</p>
</div>
<div class="admonitionblock tip data-line-659">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-660">
<p>The mindful design choices for data structures and algorithms yielded a core system with highly deterministic behaviour - maintained even under stringent time constraints.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3 data-line-663">
<h4 id="common_scheduling_pitfalls">2.3.4. Common scheduling pitfalls</h4>
<div class="paragraph data-line-665">
<p>To avoid the most common pitfalls when scheduling tasks the system programmer should be aware that:</p>
</div>
<div class="ulist data-line-667">
<ul>
<li class="data-line-667">
<p>The scheduler behaviour is to choose the highest priority READY task to run. Always.</p>
</li>
<li class="data-line-669">
<p>A task must switch to <em>READY</em> state before being eligible for scheduling. A task will switch from <em>RUNNING</em> to <em>READY</em> if yielding or if having its time-slice due. Otherwise it can only go from <em>RUNNING</em> to <em>WAITING</em> (equivalent to) and, eventually, to <em>READY</em>.</p>
</li>
<li class="data-line-671">
<p>Make sure the number of tasks and the highest (lowest effective) assigned priority is correct in <code>kconfig.h</code>. If wrong, the scheduler might not run one or more tasks or have a hard fault when switching.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-673">
<p><strong>When using time-slice, consider:</strong></p>
</div>
<div class="ulist data-line-675">
<ul>
<li class="data-line-675">
<p>A time-slice is a means of a task switching to READY within a given time. It is not a means of modelling deadlines.  Then,</p>
<div class="ulist data-line-677">
<ul>
<li class="data-line-677">
<p>Time-slices are not turning the scheduler on a deadline-aware scheduler. RK0 employs an RMS scheduler:  higher priorities are to be assigned to tasks with the shorter periods (i.e., the shorter deadlines)</p>
</li>
<li class="data-line-679">
<p>Say TaskN&#8217;s time-slice is due. It switches to ready. If no task with priority equal or higher than TaskN is ready, TaskN runs again!</p>
</li>
</ul>
</div>
</li>
<li class="data-line-681">
<p>A time slice is not a burst. A higher priority task, when ready, will pause a lower priority task in the middle of its time slice. So, a time-slice can be split into several <em>RUNNING</em> states.</p>
</li>
<li class="data-line-683">
<p>A <code>yield()</code> switches a task from <em>RUNNING</em> to <em>READY</em>. So, yielding when time-slice is enabled, means giving up the remaining of a time-slice.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2 data-line-687">
<h3 id="timers">2.4. <strong>Timers</strong></h3>
<div class="paragraph data-line-689">
<p>Every task is prone to events triggered by timers, which are described in this section. Every Task Control Block has a node to <em>a timeout list</em>.</p>
</div>
<div class="paragraph data-line-691">
<p>This list is a doubly linked list, ordered as a delta list. For instance, three timers (T1,8), (T2,6) and (T3,10) will be ordered as a sequence &lt;(T2,6), (T1,2), (T3,2)&gt; - so it counts &lt;6, (6)+2, ((6)+2)+2&gt;.</p>
</div>
<div class="paragraph data-line-693">
<p>Thus, for every system tick, only the head element on the list needs to be decreased - yielding O(1)  - another design choice towards deterministic behaviour.</p>
</div>
<div class="sect3 data-line-695">
<h4 id="sleep_timers">2.4.1. Sleep Timers</h4>
<div class="paragraph data-line-697">
<p>The primitive <code>sleep(t)</code> suspends a task on a SLEEPING state, for <code>t</code> ticks start to count when called.</p>
</div>
<div class="paragraph data-line-699">
<p>For periodic activations, use <code>sleepuntil(p)</code> in which p is an absolute suspension period in ticks. The kernel adjusts any time drift/jitters that might happen in between calls. If time-slice scheduler is enabled, this primitive is not available.</p>
</div>
</div>
<div class="sect3 data-line-701">
<h4 id="blocking_time_out">2.4.2. Blocking Time-out</h4>
<div class="paragraph data-line-703">
<p>These are timers associated with kernel calls that are blocking. Thus, establishing an upper bound waiting time might benefit them. When the time for unblocking is up, the kernel call returns, indicating a timeout error.</p>
</div>
</div>
<div class="sect3 data-line-705">
<h4 id="callout_timers">2.4.3. Callout Timers</h4>
<div class="paragraph data-line-707">
<p>These are Application Timers that will issue a callback when expiring.
In addition to a callout function, an Application Timer receives an initial phase delay and a period and can choose to run once (one-shot) or auto-reload itself.</p>
</div>
<div class="paragraph data-line-710">
<p>The callback runs within a System Task with priority 0 and is run-to-completion - what makes the scheduler prioritise it over other tasks. Callouts must be made short and unblocking - as they can cause high CPU contention.</p>
</div>
<div class="paragraph data-line-712">
<p>For clarity, Timer Callouts are on a separate list in the kernel, although they share the same <code>TIMEOUT</code> node.</p>
</div>
</div>
</div>
<div class="sect2 data-line-714">
<h3 id="system_tick">2.5. <strong>System Tick</strong></h3>
<div class="paragraph data-line-716">
<p>A dedicated peripheral that generates an interrupt after a defined period provides the kernel time reference. For ARMv7M, this peripheral is the built-in SysTick, a 24-bit counter timer.
On every tick, the handler performs some housekeeping and assesses the need to call a context switch.</p>
</div>
<div class="paragraph data-line-719">
<p>The "housekeeping" accounts for global timer tracking and any tick-dependent condition that might change a task status.
When a timer expires, it might switch a task from <code>WAITING</code> to <code>READY</code> or dispatch a callback. In the case of a callback, this will also trigger a context-switching for the TimerHandler System Task in which the callback is executed and the related timer(s) are updated properly.</p>
</div>
<div class="paragraph data-line-722">
<p>Note that tasks might switch from <code>WAITING</code> to <code>READY</code> for reasons other than tick-related. In these cases, context switching might be triggered immediately if the readied task can preempt the running task.</p>
</div>
</div>
<div class="sect2 data-line-724">
<h3 id="memory_allocator">2.6. <strong>Memory Allocator</strong></h3>
<table class="tableblock frame-all grid-all stretch data-line-727">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Memory Allocator Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Associated Block Pool</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of Blocks</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Block Size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of Free Blocks</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Free Block List</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-736">
<p>Remember that the standard <code>malloc()</code>  leads to fragmentation and (also, because of that) is highly indeterministic. Unless we use it once - to allocate memory before starting up, it doesn’t fit. But often, we need to 'multiplex' memory amongst tasks over time, that is, to dynamically allocate and deallocate.</p>
</div>
<div class="paragraph data-line-738">
<p>To avoid fragmentation, we use fixed-size memory blocks. A simple approach would be a static table marking each block as free or taken. With this pattern, you will need to 'search' for the next available block, if any - the time for searching changes - what is indeterministic.
A suitable approach is to keep track of what is free using a dynamic table—a linked list of addresses.</p>
</div>
<div class="paragraph data-line-741">
<p>We use "meta-data" to initialise the linked list. Every address holds the "next" address value. All addresses are within the range of a pool of fixed-size blocks.
This approach limits the minimal size of a block to the size of a memory address - 32-bit for our supported architecture.</p>
</div>
<div class="paragraph data-line-744">
<p>Yet, this is the cheapest way to store meta-data. If not stored on the empty address itself, an extra 32-bit variable would be needed for each block, so it could have a size that is less than 32-bit.</p>
</div>
<div class="admonitionblock tip data-line-747">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-748">
<p>Allocating memory on run-time is a major source of latency (1), indeterministic (2) behaviour and footprint overhead (3).</p>
</div>
<div class="paragraph data-line-750">
<p>Design choice: the allocator&#8217;s design achieves low-cost, deterministic, fragmentation-free memory management by using fixed-size word-aligned block sizes (1)(2), and embedding metadata within the memory blocks themselves (3).</p>
</div>
<div class="paragraph data-line-752">
<p>Benefits: run-time memory allocation benefits are provided with  no real-time drawbacks.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-756">
<p><em>Importantly, the kernel will always round up the block size to the next multiple of 4. Say the user creates a memory pool, assining blocks to 6-byte wide; they will turn into 8-byte blocks.</em></p>
</div>
<div class="sect3 data-line-758">
<h4 id="how_it_works">2.6.1. How it works</h4>
<div class="paragraph data-line-760">
<p>When a routine calls <code>alloc()</code>, the address to be returned is the one a "free list" is pointing to, say <code>addr1</code>. Before returning <code>addr1</code> to the caller, we update the free list to point to the value stored within <code>addr1</code> - say <code>addr8</code> at that moment.</p>
</div>
<div class="paragraph data-line-762">
<p>When a routine calls <code>free(addr1)</code>, we overwrite whatever has been written in addr1 with the value-free list point to (if no more <code>alloc()</code> were issued, it would still be <code>addr8</code>), and <code>addr1</code> becomes the free list head again.</p>
</div>
<div class="paragraph data-line-764">
<p>Allocating and deallocating fixed-size blocks using this structure and storing meta-data this way is as deterministic (<em>O(1)</em>) and economic as we can get for dynamic memory allocation.</p>
</div>
<div class="paragraph data-line-766">
<p>A drawback is if having a routine writing  non-allocated memory within a pool it will spoil the meta-data and the Allocator will fail.</p>
</div>
</div>
<div class="sect3 data-line-768">
<h4 id="memory_allocator_determinism">2.6.2. Memory Allocator Determinism</h4>
<div class="paragraph data-line-770">
<p>The memory allocator (if well employed) will never fail; it might take the same amount of time to allocate and free a block. In the test below, three tasks with the same priority are allocating, increasing a counter, and freeing a block of <em>128 bytes</em>. If the allocator exhibits deterministic behaviour, these counters might differ by at most 1 whenever we pause the device.</p>
</div>
<div class="exampleblock data-line-772">
<div class="content">
<div class="listingblock data-line-773">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">#include "application.h"

INT stack1[STACKSIZE];
INT stack2[STACKSIZE];
INT stack3[STACKSIZE];

RK_MEM bufPool;
#define BLOCK_SIZE	128
#define	N_BLOCKS	3
BYTE buf[N_BLOCKS][BLOCK_SIZE];


VOID kApplicationInit(VOID)
{
	kMemInit(&amp;bufPool, buf, BLOCK_SIZE, N_BLOCKS);
}

volatile int counter1, counter2, counter3=0;

VOID Task1(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{
		BYTE* addr = kMemAlloc(&amp;bufPool);
		kassert(addr!=NULL);
		RK_ERR err = kMemFree(&amp;bufPool, addr);
		kassert(err==0);
		counter1++;
		kYield();
	}
}

VOID Task2(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{

		BYTE* addr = kMemAlloc(&amp;bufPool);
		kassert(addr!=NULL);
		RK_ERR err = kMemFree(&amp;bufPool, addr);
		kassert(err==0);
		counter2++;
		kYield();
	}
}

VOID Task3(VOID* args)
{
    RK_UNUSEARGS
	while (1)
	{

		BYTE* addr = kMemAlloc(&amp;bufPool);
		kassert(addr!=NULL);
		RK_ERR err = kMemFree(&amp;bufPool, addr);
		kassert(err==0);
		counter3++;
		kYield();
	}

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph data-line-841">
<p>Below are the results after ~2.5 million ticks of 0.5 ms.</p>
</div>
<div class="imageblock data-line-843">
<div class="content">
<img src="images/images/determmem.png" alt="determmem" width="75%">
</div>
</div>
<hr>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-847">
<h2 id="inter_task_communication_itc">3. <strong><em>Inter-task communication (ITC)</em></strong></h2>
<div class="sectionbody">
<div class="paragraph data-line-849">
<p>This section presents a high-level description of the mechanisms used for communication between tasks.</p>
</div>
<div class="admonitionblock tip data-line-853">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-854">
<p>A task waiting indefinitely on a resource can cause deadlocks and missed deadlines if the resource never arrives.</p>
</div>
<div class="paragraph data-line-856">
<p>Design Choice: All blocking calls accept a timeout parameter.</p>
</div>
<div class="paragraph data-line-858">
<p>Benefit: Bounded waiting ensures the system remains responsive; tasks can regain control if resources remain unavailable.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1 data-line-861">
<h2 id="synchronisation_mechanisms">4. <strong>Synchronisation mechanisms</strong></h2>
<div class="sectionbody">
<div class="sect2 data-line-863">
<h3 id="events_sleepwake">4.1. Events (Sleep/Wake)</h3>
<table class="tableblock frame-all grid-all stretch data-line-866">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Event Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sleeping Queue</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-871">
<p>An event is a condition in time that will trigger a reaction: a countdown timer reaching zero, or the 7th bit of the 7th received stream on the 7th pin in the 7th whole moon night in the 7th year of system uptime - is 0. These are two events. The reactions we don’t bother - can even be 'to ignore the event'.</p>
</div>
<div class="paragraph data-line-873">
<p>Events are pure signals - <em>they are either absent or present, and we don’t have the notion of time for an event.</em> An "outsider" has no idea of what a signal means.</p>
</div>
<div class="paragraph data-line-875">
<p>The general nomenclature for methods that check for an event might be <code>sleep()</code>, <code>wait()</code>, or <code>pend()</code>. Methods that notify the existence of an event are commonly labelled with <code>signal()</code>, <code>post()</code>, or <code>wake()</code>. The actual behaviour depends on the system and the mechanism.</p>
</div>
<div class="paragraph data-line-877">
<p>An Event in K0 is a kernel object that encapsulates a queue of tasks waiting for a condition (event) to be true. Purposely, nothing within the Event object records whether this condition is true or false (has happened or not). It is a queue, initially empty.</p>
</div>
<div class="paragraph data-line-879">
<p>The primitives are <code>sleep()</code>, <code>signal()</code> and <code>wake()</code>. A <code>sleep()</code> always results in a task suspending in a <code>SLEEPING</code> state. In <code>K0</code> tasks <code>sleep()</code> for an event that <em>will happen</em>.</p>
</div>
<div class="paragraph data-line-881">
<p>Another task/ISR might be responsible for notifying those waiting for the event. <code>wake()</code> affects all functions that are sleeping for an event: they all switch to <code>READY</code> at once. On the other hand, a <code>signal()</code> will dequeue a single task. Queue discipline is by priority.</p>
</div>
</div>
<div class="sect2 data-line-884">
<h3 id="semaphores">4.2. Semaphores</h3>
<div class="sect3 data-line-886">
<h4 id="counter_semaphore">4.2.1. Counter Semaphore</h4>
<table class="tableblock frame-all grid-all stretch data-line-888">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Semaphore Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Counter (Signed Integer)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting Queue</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-893">
<p>A <em>counter</em> semaphore is an event counter. It means the primitives <code>post()</code> and <code>pend()</code> will increase (record the event) and decrease (consume the event), respectively, the signed value 'N' of a given semaphore (a semaphore cannot be initialised with a negative value).</p>
</div>
<div class="paragraph data-line-895">
<p>When <code>pend()</code> returns a negative value, the caller is blocked within the semaphore queue. The negative value of a counter semaphore immediately informs us how many tasks are blocked waiting for a signal.</p>
</div>
<div class="paragraph data-line-897">
<p>After becoming negative, every signal issued to a semaphore releases a task until its counter reaches 0—meaning there are no enqueued tasks or recorded events.</p>
</div>
</div>
<div class="sect3 data-line-900">
<h4 id="private_binary_semaphores">4.2.2. Private Binary Semaphores</h4>
<table class="tableblock frame-all grid-all stretch data-line-902">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Within Task Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signalled (Boolean)</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-907">
<p>A binary semaphore is a special case of a counter semaphore. It can count up to 1 and down to 0.
So, it records that one Event happened and that one event has been consumed.</p>
</div>
<div class="paragraph data-line-910">
<p>Each Task has a built-in binary semaphore. Since it is a private semaphore, only the task can issue a <code>pend()</code> on its binary semaphore, but any other task can issue a <code>signal()</code> on it.</p>
</div>
<div class="paragraph data-line-912">
<p>A binary semaphore will record one event at most. So a binary semaphore whose value is <code>0</code> will block when <code>pend()</code>. A signal on a binary semaphore in which the task is <code>PENDING</code> switches the task to <code>READY</code>, but the value will remain <code>0</code> (as it had transitioned to 1, and decreased again). A signal on a binary semaphore that is <code>1</code> will not increase its value.</p>
</div>
<div class="paragraph data-line-914">
<p>Private binary semaphores are useful for bilateral synchronisation with other tasks or simply for task notification.</p>
</div>
<div class="paragraph data-line-916">
<p>Private Binary Semaphores do not have a dedicated queue unlike public Counter Semaphores. Only the owner can block it.</p>
</div>
</div>
<div class="sect3 data-line-918">
<h4 id="mutex_semaphore">4.2.3. Mutex Semaphore</h4>
<table class="tableblock frame-all grid-all stretch data-line-921">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Mutex Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Locked State (Boolean)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Owner</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting Queue</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Timeout Node</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-929">
<p>Some code regions are critical in that they cannot be accessed by more than one task at once. Acquiring a mutex before entering a region and releasing it when leaving makes that region mutually exclusive.
A mutex is a lock with a notion of ownership: only the task that owns a mutex can unlock it.</p>
</div>
<div class="paragraph data-line-932">
<p>If a task without an owner tries to lock it, it switches to a <code>BLOCKED</code> state until the mutex is unlocked—as on semaphores. However, unlike semaphores, the complementary operation <code>unlock()</code>, when issued by a non-owner, has undefined behaviour. In K0, it will be a hard fault.</p>
</div>
<div class="paragraph data-line-934">
<p>Mutexes are solely for mutual exclusion; they cannot be used for signalling. Although it is common (mainly in textbooks) to see Counter Semaphores initialised as 1 to create mutual exclusion, it can work fine if all tasks accessing the region have the same priority. But, if the semaphore count increases twice in a row, the mutual exclusion behaviour is gone.</p>
</div>
<div class="paragraph data-line-936">
<p>Additionaly, <em>Priority Inversion</em> can become a problem, as will be explained.</p>
</div>
<div class="admonitionblock note data-line-940">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph data-line-941">
<p>On typical terminology a mutex is not referred to as a semaphore. If someone says, “This object is a semaphore,” it implies the non-ownership model and other typical semaphore properties—not the mutual-exclusion contract of a mutex. Anyway, i f</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect4 data-line-944">
<h5 id="priority_inversion">4.2.3.1. Priority Inversion</h5>
<div class="paragraph data-line-946">
<p>Let TH, TM, and TL be three tasks with priority high (H), medium (M) and low (L), respectively. Say TH is dispatched to be blocked on a semaphore 'TL' has acquired. Say 'TM' is dispatched, and it does not need the resource 'TL' holds. It will pre-empt 'TL'.</p>
</div>
<div class="paragraph data-line-948">
<p>Now 'TH' has an <em>unbounded waiting time</em> because any task with priority higher than 'L' that does not need the resource indirectly prevents it from being unblocked.</p>
</div>
<div class="paragraph data-line-950">
<p>Mutexes in K0 can (by default, but optionally) implement a protocol called priority inheritance. While holding the resource, 'TL' will have its priority raised to 'H', so 'TM' can no longer pre-empt it. Thus, consider using mutexes for resource sharing.</p>
</div>
</div>
</div>
</div>
<div class="sect2 data-line-952">
<h3 id="condition_variables">4.3. Condition Variables</h3>
<div class="paragraph data-line-954">
<p>Composing <em>Events</em> and <em>Mutexes</em>   leverages <em>Condition Variables</em>. Whenever a task needs to test for a condition before accessing a shared resource, it first locks the mutex associated with that resource. Within the mutex critical region, it tests for the condition. If the condition evaluates true, the resource is used, and then the mutex is unlocked. The condition is also refered to as a <em>predicate</em>.</p>
</div>
<div class="paragraph data-line-956">
<p>If the condition is evaluated as false, the task goes to sleep - to wait for a wake signal when the condition is true. The detail is that it goes to sleep and unlocks the mutex all in an atomic operation (the mutex must be unlocked so another task can access the resource afterwards).</p>
</div>
<div class="paragraph data-line-958">
<p>When receiving a wake signal, the task repeats the processes. This is illustrated on the snippet below:</p>
</div>
<div class="exampleblock data-line-960">
<div class="content">
<div class="listingblock data-line-961">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* Shared-Buffer (Mailbox) using Condition Variable */

UINT*       mailPtr = NULL; /* points to nothing, is empty */
RK_EVENT     empty;
RK_EVENT     full;
RK_MUTEX     lockMail;
VOID kApplicationInit( VOID)
{
    kEventInit(&amp;empty);
    kEventInit(&amp;full);
    kMutexInit(&amp;lockMail);
}
VOID PostMail( UINT* sendPtr)
{
     kMutexLock(&amp;lockMail, RK_WAIT_FOREVER);
     while (mailPtr != NULL) /* predicate check loop */
     {
        /*atomic unlock and sleep*/
         kDisableIRQ();
         kMutexUnlock(&amp;lockMail);
         kSleep(&amp;empty, RK_WAIT_FOREVER);
         kEnableIRQ();
         /* wake and lock */
         kMutexLock(&amp;lockMail, RK_WAIT_FOREVER);
     }
     /* deposit mail address, signal any sleeping for mail and unlock */
      mailPtr = sendPtr;
      kEventSignal(&amp;full);/* release highest priority consumer waiting */
      kMutexUnlock(&amp;lockMail);
      return;
}
VOID PendMail( UINT** recvPPtr)
{
     kMutexLock(&amp;lockMail, RK_WAIT_FOREVER);
     while (mailPtr == NULL)
     {
         kDisableIRQ();
         kMutexUnlock(&amp;lockMail);
         kSleep(&amp;full, RK_WAIT_FOREVER);
         kEnableIRQ();
         kMutexLock(&amp;lockMail, RK_WAIT_FOREVER);
     }
     /* extract mail, signal any sleeping for an empty box and unlock */
      *recvPPtr = mailPtr; /*  copies the value of mailPtr to *recvPPtr */
      mailPtr = NULL; /* empty mailbox*/
      kEventSignal(&amp;empty); /* release highest priority producer waiting */
      kMutexUnlock(&amp;lockMail);
      return;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2 data-line-1018">
<h3 id="task_flags_signals">4.4. Task Flags (Signals)</h3>
<table class="tableblock frame-all grid-all stretch data-line-1021">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Within Task Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Current Flags</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Required Flags</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Options</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-1028">
<p>Task Flags provides a flexible mechanism for direct task notification of a <em>combination</em> of events. They can be thought as a pack of binary semaphores&#8201;&#8212;&#8201;thus, if Task Flags are enabled you do not need the task&#8217;s binary semaphore&#8201;&#8212;&#8201;unless you will be using Task Flags on a less typical way.</p>
</div>
<div class="paragraph data-line-1030">
<p>The flags within a Task Control Block are represented by a 32-bit unsigned integer. A task <code>pend()</code> on its own flags, passing a combination of events it is waiting for (each bit can represent an event). This combination is conditioned to be satisfied either if <code>ANY</code> of the 'required flags' are set, or if <code>ALL</code> 'required flags' are set.</p>
</div>
<div class="paragraph data-line-1032">
<p>When pending, if the condition is not met the task can optionally suspends&#8201;&#8212;&#8201;with a timeout. When a <code>post()</code> operation satisfies the waiting condition, the <em>matched flags are consumed</em> (cleared).</p>
</div>
<div class="paragraph data-line-1034">
<p>The <code>post()</code> operation receives an input <code>mask</code> as a parameter. This mask will operate over the current task flags using <code>OR</code>, <code>AND</code> or <code>OVW</code>. The former means that current flags are just replaced, what can be useful to have the mechanism to work as a direct message. A <code>post()</code> operation never blocks: it can always write on the target task flags.</p>
</div>
<div class="paragraph data-line-1036">
<p>Besides <code>post()`and `pend()</code> the other operations are <code>clear()</code>&#8201;&#8212;&#8201;the caller task clears its flags; <code>query()</code>&#8201;&#8212;&#8201;the caller task inspects its current flags.</p>
</div>
<div class="paragraph data-line-1038">
<p>An interesting use-case for Task Flags is to non-blocking checking for flags on the beginning of the task cycle, and execute a callback accordingly. Thus every time a task is dispatched it will verify for pending signals to meet the requests.
If the task has a higher priority&#8201;&#8212;&#8201;say, a supervisor&#8201;&#8212;&#8201;it can create a neat event-driven design for a soft real-time system.</p>
</div>
<div class="listingblock data-line-1041">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">VOID SupervisorTask(VOID *args)
{
    RK_UNUSEARGS

    while(1)
    {
        ULONG gotFlags;
        /* suppose the number of events is constrained to 16, 0xFFFF covers them all */
        RK_ERR err = kFlagsPend(0xFFFF, &amp;gotFlags, RK_FLAGS_ANY, RK_NO_WAIT); /* requires any of the 16 flags, and do not block */
        if (err == RK_SUCCESS)
        {
            switch(gotFlags)
            {
                case (gotFlags &amp; PENDING_AIRFLOW_CTL):
                   /* ready task that controls air flow */
                   kSignal(airFlowTaskHandle);
                   break;
                /* other handles */
            }

        }

        kSleepUntil(SUPERVISOR_T_PERIOD);
    }

}</code></pre>
</div>
</div>
<div class="paragraph data-line-1073">
<p><em>Event Flags</em>  is the 'public' version of this mechanism.</p>
</div>
</div>
<div class="sect2 data-line-1076">
<h3 id="event_flags_or_event_group">4.5. Event Flags (or Event Group)</h3>
<div class="paragraph data-line-1078">
<p>Event Flags use a 32-bit unsigned value to represent multiple events in a bitwise manner. Each bit corresponds to one event, allowing for multi-condition notification within the system.</p>
</div>
<div class="paragraph data-line-1080">
<p>When a task is waiting for a (combination of) events—e.g., a resource to be released and/or data to be ready—it describes whether ALL (AND logic) events are required to happen or whether ANY of (OR logic) events will satisfy the condition.</p>
</div>
<div class="paragraph data-line-1082">
<p>Different from Task Flags, an event can either be <em>consumed</em> or <em>kept</em> - if to be consumed, after meeting the waiting condition of a task, the bit is cleared. A higher priority task if consuming an event will prevent lower priority tasks to sense that event.</p>
</div>
<table class="tableblock frame-all grid-all stretch data-line-1086">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Event Control Block (Extended)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Current Flags (32-bit)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting Queue</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch data-line-1092">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Within Task Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Required Flags</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Received Flags</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Options</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-1099">
<p>When Event Flags are enabled the <code>EVENT</code> kernel object includes a 32-bit integer.</p>
</div>
<div class="paragraph data-line-1101">
<p>For <em>Event Flags</em>, there are two main primitives:</p>
</div>
<div class="ulist data-line-1103">
<ul>
<li class="data-line-1103">
<p><em>Pend</em></p>
</li>
</ul>
</div>
<div class="paragraph data-line-1105">
<p>A task performs a Pend on the bit string by specifying:</p>
</div>
<div class="olist arabic data-line-1107">
<ol class="arabic">
<li class="data-line-1107">
<p>A bit mask representing the event(s) it’s waiting for.</p>
</li>
<li class="data-line-1108">
<p>The options (<code>ALL(_KEEP/CONSUME)</code> or <code>ANY(_KEEP/CONSUME)</code>).</p>
</li>
</ol>
</div>
<div class="paragraph data-line-1110">
<p>If the condition is not yet satisfied at the time of a <em>Pend</em>, the task is optionally suspended.</p>
</div>
<div class="paragraph data-line-1112">
<p>A task suspended for a combination of event flags assumes the status <code>PENDING_FLAGS</code>.</p>
</div>
<div class="ulist data-line-1114">
<ul>
<li class="data-line-1114">
<p><em>Post (Bitwise OR/AND)</em></p>
</li>
</ul>
</div>
<div class="paragraph data-line-1116">
<p>A task can set/clear one or more bits in the Event Flags bit string by using <code>OR</code>/<code>AND</code> as options when issuing a <code>post()</code>.</p>
</div>
<div class="paragraph data-line-1118">
<p>Additionally, there is the option <code>OVW</code> to overwrite whatever is set&#8212;&#8203;no logical operation.</p>
</div>
<div class="paragraph data-line-1121">
<p><em>Importantly,</em> a <code>post()</code> operation sweeps the waiting list on priority order, switching to <code>READY</code> a task that has its required conditions met. If events are to be consumed, they are cleared before inspecting the next task&#8217;s required condition.</p>
</div>
<div class="admonitionblock note data-line-1124">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph data-line-1125">
<p>Public Event Flags is a mechanism that allows a straight implementation of the <em>Observer Pattern</em>, very useful for reactive systems, it easily becomes a problem.</p>
</div>
<div class="paragraph data-line-1127">
<p>Although you can represent 32 events within a single public EVENT object it does not mean you should. Clustering events by concerns, while increasing the memory overhead will improve responsiveness&#8201;&#8212;&#8201;as a <code>post()</code> operation needs to iterate the waiting list (<em>O(n)</em>) and check for the conditions each task is expecting&#8201;&#8212;&#8201;it does has a cost. You can consider a non-blocking approach, depending on the functional requiremens.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3 data-line-1131">
<h4 id="usage_example">4.5.1. Usage Example</h4>
<div class="paragraph data-line-1133">
<p>Tasks are notified for updates on sensors.
Every task is interested on a specific pair.
When a task has its condition met, the flags are cleared. (i.e., every task uses the option <code>RK_FLAGS_ALL_CONSUME</code>)</p>
</div>
<div class="exampleblock data-line-1138">
<div class="content">
<div class="listingblock data-line-1139">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">#define TEMPERATURE (1&lt;&lt;0)
#define HUMIDITY    (1&lt;&lt;1)
#define CO2         (1&lt;&lt;2)
#define FLOW        (1&lt;&lt;3)
#define PRESSURE    (1&lt;&lt;4)

RK_EVENT eventFlags;

VOID kApplicationInit( VOID)
{
    kEventInit( &amp;eventFlags);
}

VOID Task1( VOID *args)
{
    RK_UNUSEARGS
    ULONG sensorType = 0;
    ULONG updatedFlags;
    ULONG values[5] = {TEMPERATURE, HUMIDITY, CO2, FLOW, PRESSURE};
    while (1)
    {
        INT index = rand() % 5;
        sensorType = values[index];/* index will range 0-4, randomly  */
        RK_ERR err = kEventFlagsPost( &amp;eventFlags, sensorType, &amp;updatedFlags, RK_FLAGS_OR);
        kassert(err==RK_SUCCESS);
        kSleepUntil( 4);
    }
}

VOID Task2( VOID *args)
{
    RK_UNUSEARGS
    ULONG gotFlags = 0;
    ULONG requiredFlags = (TEMPERATURE | FLOW);
    while (1)
    {
        RK_ERR err = -1;
        err = kEventFlagsPend( &amp;eventFlags, requiredFlags, &amp;gotFlags,
        RK_FLAGS_ALL_CONSUME, RK_WAIT_FOREVER);
        UNUSED( gotFlags);
        if (err == RK_SUCCESS)
        {
            kprintf( "[@ %lu ticks: T2 Got TEMPERATURE  and FLOW  updated.\n\r",
                    kTickGet());
        }
        kSleep( 10);

    }
}

VOID Task3( VOID *args)
{
    RK_UNUSEARGS
    ULONG gotFlags = 0;
    ULONG requiredFlags = (CO2 | HUMIDITY);
    while (1)
    {
        RK_ERR err = -1;
        err = kEventFlagsPend( &amp;eventFlags, requiredFlags, &amp;gotFlags,
        RK_FLAGS_ALL_CONSUME, RK_WAIT_FOREVER);
        /* this parameter is for inspection when pending with timeout 0, or for general inspection upon condition satisfied.
        Note that gotFlags will contain all flags
        within the event group, even those that
        were not required by the task
        */
        UNUSED( gotFlags);
        if (err == RK_SUCCESS)
        {
            kprintf( "[@ %lu ticks: T3 CO2 and HUMIDITY updated.\n\r",
                    kTickGet());
        }
        kSleep( 10);

    }
}

VOID Task4( VOID *args)
{
    RK_UNUSEARGS
    ULONG gotFlags = 0;
    ULONG requiredFlags = (PRESSURE | TEMPERATURE);
    while (1)
    {

        RK_ERR err = -1;
        err = kEventFlagsPend( &amp;eventFlags, requiredFlags, &amp;gotFlags,
        RK_FLAGS_ALL_CONSUME, RK_WAIT_FOREVER);
        UNUSED( gotFlags);
        if (err == RK_SUCCESS)
        {
            kprintf( "[@ %lu ticks: T4 PRESSURE and TEMPERATURE updated.\n\r",
                    kTickGet());
        }
        kSleep( 10);

    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="imageblock data-line-1243">
<div class="content">
<img src="images/images/evflags.png" alt="evflags" width="30%">
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-1246">
<h2 id="message_passing">5. <strong>Message Passing</strong></h2>
<div class="sectionbody">
<div class="paragraph data-line-1248">
<p>So far, we have seen mechanisms to handle <em>events</em>. The communication using events does not carry data to be processed - it observes conditions and takes actions. Message Passing is about conveying data while also being able to represent events.</p>
</div>
<div class="paragraph data-line-1250">
<p>The message-passing mechanisms in RK0 are primitives in their own right, and they do not reuse any synchronisation primitives presented so far.</p>
</div>
<div class="admonitionblock note data-line-1254">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph data-line-1255">
<p>In real-time applications, Message Passing often encounters the following scenarios:</p>
</div>
<div class="ulist data-line-1257">
<ul>
<li class="data-line-1257">
<p>Some messages are consumed by tasks that can&#8217;t do anything before processing information — thus, these messages end up also being signals. For Example, a server needs (so it blocks) for a command to process and/or a client that blocks for an answer.</p>
</li>
<li class="data-line-1259">
<p>A particular case of the above scenario is fully synchronous: client and server run on <em>lockstep</em>.</p>
</li>
<li class="data-line-1261">
<p>Two tasks with different rates need to communicate, and cannot lockstep. A faster producer might use a buffer to accommodate a relatively small burst of generated data, or a quicker consumer will drop repeated received data.</p>
</li>
<li class="data-line-1263">
<p>Other times, we need to correlate data with time for processing, so using a queue gives us the idea of data motion. <em>Eg., when calculating the mean value of a transductor on a given period</em>.</p>
</li>
<li class="data-line-1265">
<p>For <em>real-time</em> tasks such as servo-control loops, past data is useless. Consumers need the most recent data for processing. For example, a <em>drive-by-wire</em> system, or a robot deviating from obstacles. In these cases the message-passing must be lock-free while guaranteeing data integrity.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2 data-line-1269">
<h3 id="mailbox">5.1. Mailbox</h3>
<table class="tableblock frame-all grid-all stretch data-line-1271">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Mailbox Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mail Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting queue</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Owner Task*</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-1278">
<p>While in GPOS jargon, mailboxes are queues of messages - as a distinction from pipes (that are byte streams) - in embedded system software, often mailboxes are said to have a capacity of a single item, and more recently, you will not find it as a distinct mechanism - you use a 1-item queue.</p>
</div>
<div class="paragraph data-line-1280">
<p>A Mailbox allows a task to exclusively write (post) and read (pend) a memory region and to be notified when another task writes or reads to it. Therefore its typical operation provides mutual exclusion and notification altogether: <em>very handy</em>.</p>
</div>
<div class="paragraph data-line-1282">
<p>A message within a mailbox is the address of an object. The sender and receiver agree on the concrete mail implementation as part of the mail interface contract; also the data pointed to has to remain unchanged until the receiver 'consumes' it. That is another part of the contract.</p>
</div>
<div class="paragraph data-line-1284">
<p>The semantics are simple: a Mailbox will be <code>EMPTY</code> when its storage points to <code>NULL</code>; otherwise, it is <code>FULL</code>. The mailbox will be empty/full after a successful <code>pend()</code>/<code>post()</code> operation.</p>
</div>
<div class="admonitionblock note data-line-1288">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A mailbox can be initialised as FULL if the initial pointer provided is non-null.
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-1290">
<p>Typical use-case is when one wants to deliver a signal along with a payload&#8212;&#8203;a <em>message as a signal</em>.</p>
</div>
<div class="paragraph data-line-1292">
<p>The concrete type of mail is application-defined, and the sender and receiver must agree on its implementation. When a producer <code>post()</code> to a <code>FULL</code> mailbox, it (optionally) blocks and is placed in the Mailbox waiting queue. The associated task will switch to the state <code>SENDING</code>.</p>
</div>
<div class="paragraph data-line-1294">
<p>Likewise, a consumer (optionally) blocks when issuing a <code>pend()</code> on an empty Mailbox. The task status switches to <code>RECEIVING,</code> and is enqueued in the mailbox waiting queue.</p>
</div>
<div class="paragraph data-line-1296">
<p>Besides <code>post()</code> and <code>pend()</code>, other primitives are <code>peek()</code> to read without removing (non-destructive) and <code>postovw()</code> to overwrite whatever is in a full mailbox.</p>
</div>
<div class="paragraph data-line-1299">
<p><em>* we discuss ownership on message passing later.</em></p>
</div>
<div class="sect3 data-line-1302">
<h4 id="usage_example_zero_buffer_channel">5.1.1. Usage Example: <em>Zero-Buffer</em> Channel</h4>
<div class="paragraph data-line-1304">
<p>On a <em>zero-buffer</em> channel, the sender blocks, waiting for a confirmation that the message was not only deposited (buffered) on the mailbox but also retrieved by the receiver:</p>
</div>
<div class="exampleblock data-line-1306">
<div class="content">
<div class="listingblock data-line-1307">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/*(...) details ommited */

/* sender needs to be sure message has arrived */
SenderTask:

   err = kMboxPost(...., timeout);
   if (err=ERR_TIMEOUT)
       retryPost();
   if (err==success)
   {
       /* pend on private bin semaphore, to wait for confirmation it was read */
       err = kPend(timeout);
       if (err == ERR_TIMEOUT)
       /* receiver did not ack before time-out */

   }


ReceiverTask:
    err = kMboxPend( ..., timeout);
    if (err==ERR_TIMEOUT)
        retryPend();
    if(err==SUCCESS)
       /* post to sender's semaphore, to ack message was received */
       kSignal(senderTaskHandle);


/* using a mailbox instead of a binary semaphore */


/* the acknowledgment mail can be a dummy message */
K_MBOX reqBox; /* request message */
K_MBOX ackBox; /* ack message */

SenderTask:

   err = kMboxPost(&amp;reqBox, &amp;reqMesg, timeout);
   if (err=ERR_TIMEOUT)
       retryPost();
   if (err==SUCCESS)
   {

       err = kMboxPend(&amp;ackBox, &amp;recvmesg, timeout);
       if (err == ERR_TIMEOUT)
       /* receiver did not ack before time-out */

   }


ReceiverTask:
    err = kMboxPend( ..., timeout);
    if (err==ERR_TIMEOUT)
        retryPend();
    if(err==SUCCESS)
    {
       err = kMboxPost(&amp;ackBox, &amp;ackMesg, timeout);
       if (err==ERR_TIMEOUT)
       /* in this case, the sender has not retrieved
          a previous ack */
    }</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph data-line-1373">
<p>Mailboxes are well-suited for 1:1 communication - fully synchronous (lockstep) command-response or when a task waits for a notification plus a payload (say, the last data read by an Interrupt routine).</p>
</div>
</div>
<div class="sect3 data-line-1375">
<h4 id="usage_example_2_multi_client_server_synchronous_command_response">5.1.2. Usage Example 2: Multi-client-server synchronous command-response</h4>
<div class="paragraph data-line-1377">
<p>The previous example presented a pattern known as 'extended rendez-vous': a Task signals and suspends until is signalled back. If both signals are messages, we have a synchronous command-reponse.</p>
</div>
<div class="paragraph data-line-1379">
<p>The snippet below presents a synchronous 2:1 communication channel with mailboxes.</p>
</div>
<div class="exampleblock data-line-1381">
<div class="content">
<div class="listingblock data-line-1383">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* this example includes  &lt;string.h&gt; for convenience */

RK_MBOX serverReqMbox; /*  server incoming commands */
RK_MBOX serverAckMbox; /*  server incoming reponse acks */
RK_MBOX clientMbox1;   /*  response for client 1 */
RK_MBOX clientMbox2;   /* response for client 2 */

/* Command Requests are assembled on an Application Data Unit */
typedef struct
{
    BYTE length; /* Length of the APDU payload */
    BYTE payload[32]; /* APDU payload */
    RK_MBOX *replyMbox; /* Pointer to the client's reply mailbox */
} APDU __attribute__((aligned(4)));

void kApplicationInit(VOID)
{
    kMboxInit(&amp;serverReqMbox,  NULL);
    kMboxInit(&amp;serverAckMbox, NULL);
    kMboxInit(&amp;clientMbox1, NULL);
    kMboxInit(&amp;clientMbox2, NULL);

}

/* Highest Priority */
/* the server response is to ECHO the request back to the client; then it pends on a mailbox waiting the client to acknowledge the response. so it proceeds to process further requests.  */

VOID ServerTask(VOID* args)
{
    RK_UNUSEARGS

    APDU *request, response;
    UINT* ackResp;
    while (1)
    {
        /* Wait for a request */
        if (kMboxPend(&amp;serverReqMbox, (ADDR*)&amp;request, RK_WAIT_FOREVER) == RK_SUCCESS)
        {
            kprintf("[SERVER] RECV: %s\n\r", request-&gt;payload);

            /* Process the request */
            response.length = (BYTE) snprintf((char*) response.payload,
                    sizeof(response.payload), "ECHO %s",
                    request-&gt;payload);

            /* Echo to client's reply mailbox */
            if (kMboxPost(request-&gt;replyMbox, &amp;response, RK_WAIT_FOREVER) != RK_SUCCESS)
            {
                kprintf("ECHO fail\n\r");
            }
            if (kMboxPend(&amp;serverAckMbox, (ADDR*)&amp;ackResp, RK_WAIT_FOREVER) == RK_SUCCESS)
                kprintf("[SERVER] CLIENT %d SERVED.\n\r", *ackResp);

        }
    }
}
/* same priority as Client2 */
VOID Client1Task(VOID* args)
{
    RK_UNUSEARGS

    APDU request, *response;

    while (1)
    {
        /* Prepare the request */
        snprintf((char*) request.payload, sizeof(request.payload),
                "Hello from Client 1");
        request.length = (BYTE) strlen((char*) request.payload);
        request.replyMbox = &amp;clientMbox1; /* Specify the reply mailbox */

        /* Send the request to the server */
        if (kMboxPost(&amp;serverReqMbox, &amp;request, RK_WAIT_FOREVER) == RK_SUCCESS)
        {

            /* Wait for the response */
            if (kMboxPend(&amp;clientMbox1, (ADDR*)&amp;response, RK_WAIT_FOREVER)
                    == RK_SUCCESS)
            {
                kprintf("[CLIENT #1] RECV: %s\n\r", response-&gt;payload);
                UINT ack=1;
                kMboxPost(&amp;serverAckMbox, &amp;ack, RK_WAIT_FOREVER);
            }
            else
            {
                kprintf("1F\n\r");
            }
        }
        else
        {
            kprintf("1F\n\r");
        }

    }
}
VOID Client2Task(VOID* args)
{
    RK_UNUSEARGS
    APDU request, *response;

    while (1)
    {
        /* Prepare the request */
        snprintf((char*) request.payload, sizeof(request.payload),
                "Hello from Client 2");
        request.length = (BYTE) strlen((char*) request.payload);
        request.replyMbox = &amp;clientMbox2; /* Specify the reply mailbox */

        /* Send the request to the server */
        if (kMboxPost(&amp;serverReqMbox, &amp;request, RK_WAIT_FOREVER) == RK_SUCCESS)
        {

            /* Wait for the response */
            if (kMboxPend(&amp;clientMbox2, (ADDR*)&amp;response, RK_WAIT_FOREVER)
                    == RK_SUCCESS)
            {
                kprintf("[CLIENT #2] RECV: %s\n\r", response-&gt;payload);
                UINT ack=2;
                kMboxPost(&amp;serverAckMbox, &amp;ack, RK_WAIT_FOREVER);
            }
            else
            {
                kprintf("2FAIL\n\r");
            }
        }
        else
        {
            kprintf("2FAIL\n\r");
        }

    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="imageblock data-line-1519">
<div class="content">
<img src="images/images\clientserver.png" alt="images\clientserver" width="30%">
</div>
</div>
<div class="paragraph data-line-1522">
<p>Note the zero-buffer (synchronous) behaviour: client and server are running on <em>lockstep</em> - a request from #1 is followed by a reponse to #1, and so forth.</p>
</div>
<div class="paragraph data-line-1524">
<p>Importantly, this is what allows to write the code with a single pointer for request and response and pass the message by reference.</p>
</div>
<div class="exampleblock data-line-1526">
<div class="content">
<div class="paragraph data-line-1528">
<p><strong>Asynchronous communication and the need for buffering</strong></p>
</div>
<div class="paragraph data-line-1530">
<p>Had we wanted to implement the previous example without allowing the Server and Client to lockstep, we would need to buffer the requests and responses, because:</p>
</div>
<div class="olist arabic data-line-1532">
<ol class="arabic">
<li class="data-line-1532">
<p>As the server runs at highest priority (thus at a highest rate), if not blocking after replying to a client, it pends again for a request. In this specific example, say it posts a reply to Client 1&#8201;&#8212;&#8201;that is blocked waiting for an answer&#8201;&#8212;&#8201;and pends for another request.</p>
</li>
<li class="data-line-1534">
<p>Then&#8201;&#8212;&#8201;given that Client 1 and Client 2 have the same priority&#8201;&#8212;&#8201;when the server pends, the next READY task the scheduler picks is Client 2, that deposits its request - and blocks for an answer.</p>
</li>
<li class="data-line-1536">
<p>Again, the scheduler runs and picks the Server Task (that was unblocked when Client 2 issued a request and is the highest priority task). The server will process Client 2 request and writes the response.</p>
</li>
<li class="data-line-1538">
<p>If this response is written on the same address the response for Client 1 was written, Client 1 would run next to find its mailbox pointing to the response meant for Client 2. Indeed, Client 1 would always have its reponse overwritten.</p>
</li>
</ol>
</div>
<div class="paragraph data-line-1541">
<p>Enabling asynchronous communication by buffering requests can be done as follows:</p>
</div>
<div class="listingblock data-line-1543">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* buffers */

#define N_CLIENTS 2

static APDU *request[N_CLIENTS], response[N_CLIENTS];
static UINT idx=0;

VOID ServerTask(VOID* args)
{
    RK_UNUSEARGS

    while (1)
    {
        /* Wait for a request */
        if (kMboxPend(&amp;serverReqMbox, (ADDR*)&amp;request[idx], RK_WAIT_FOREVER) == RK_SUCCESS)
        {
            kprintf("[SERVER] RECV: %s\n\r", request[idx]-&gt;payload);

            /* Process the request */
            response[idx].length = (BYTE) snprintf((char*) response[idx].payload,
                    sizeof(response[idx].payload), "ECHO %s",
                    request[idx]-&gt;payload);

            /* Echo to client's reply mailbox */
            if (kMboxPost(request[idx]-&gt;replyMbox, &amp;response[idx], RK_WAIT_FOREVER) != RK_SUCCESS)
            {
                kprintf("ECHO fail\n\r");
            }
            else
            {   /* update buffer index */
                idx+=1;
                idx%=N_CLIENTS;

            }

        }
    }
}
VOID Client1Task(VOID* args)
{
    RK_UNUSEARGS

    APDU request, *response;

    while (1)
    {
        /* Prepare the request */
        snprintf((char*) request.payload, sizeof(request.payload),
                "Hello from Client 1");
        request.length = (BYTE) strlen((char*) request.payload);
        request.replyMbox = &amp;clientMbox1; /* Specify the reply mailbox */

        /* Send the request to the server */
        if (kMboxPost(&amp;serverReqMbox, &amp;request, RK_WAIT_FOREVER) == RK_SUCCESS)
        {

            /* Wait for the response */
            if (kMboxPend(&amp;clientMbox1, (ADDR*)&amp;response, RK_WAIT_FOREVER)
                    == RK_SUCCESS)
            {
                kprintf("[CLIENT #1] RECV: %s\n\r", response-&gt;payload);
            }
            else
            {
                kprintf("1F\n\r");
            }
        }
        else
        {
            kprintf("1F\n\r");
        }

    }
}

VOID Client2Task(VOID* args)
{
    RK_UNUSEARGS
    APDU request, *response;

    while (1)
    {
        /* Prepare the request */
        snprintf((char*) request.payload, sizeof(request.payload),
                "Hello from Client 2");
        request.length = (BYTE) strlen((char*) request.payload);
        request.replyMbox = &amp;clientMbox2; /* Specify the reply mailbox */

        /* Send the request to the server */
        if (kMboxPost(&amp;serverReqMbox, &amp;request, RK_WAIT_FOREVER) == RK_SUCCESS)
        {

            /* Wait for the response */
            if (kMboxPend(&amp;clientMbox2, (ADDR*)&amp;response, RK_WAIT_FOREVER)
                    == RK_SUCCESS)
            {
                kprintf("[CLIENT #2] RECV: %s\n\r", response-&gt;payload);
            }
            else
            {
                kprintf("2FAIL\n\r");
            }
        }
        else
        {
            kprintf("2FAIL\n\r");
        }

    }
}</code></pre>
</div>
</div>
<div class="paragraph data-line-1657">
<p>The image below shows a request from Client 1 is followed by a response to Client 2.</p>
</div>
<div class="imageblock data-line-1659">
<div class="content">
<img src="images/images/clientserverasynch.png" alt="clientserverasynch" width="30%">
</div>
</div>
</div>
</div>
<div class="admonitionblock tip data-line-1664">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Sometimes the best 'mailbox' for your need is a local global guarded by a mutex.
</td>
</tr>
</table>
</div>
<div class="exampleblock data-line-1666">
<div class="content">
<div class="admonitionblock note data-line-1669">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<strong>Message Queues</strong>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-1671">
<p>The classic Message Queue on UNIX SVR4 is defined as the 'head of a linked list of messages'. Some RTOSes implement Message Queues using linked lists, in which case a central pool of buffers might exist.</p>
</div>
<div class="paragraph data-line-1673">
<p>The design approach in RK0 does not use lists for message queues. Two mechanisms for enqueueing messages are offered:</p>
</div>
<div class="ulist data-line-1675">
<ul>
<li class="data-line-1675">
<p>A <em>Mail Queue</em> is a 'multi-item' Mailbox—it holds multiple generic pointers as messages.</p>
</li>
<li class="data-line-1677">
<p>A <em>Stream Queue</em> is a ring buffer of N fixed-size messages (word-aligned). <em>Streams perform deep copies</em> - from sender storage to queue buffer and from queue buffer to receiver storage.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-1679">
<p>They are offered as different mechanisms because they have different best-use cases and semantics.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2 data-line-1683">
<h3 id="mail_queue">5.2. Mail Queue</h3>
<table class="tableblock frame-all grid-all stretch data-line-1686">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Queue Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Buffer Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write Position</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Read Position</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Max. number of mails</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Current number of mails</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Waiting queue</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Owner Task</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-1697">
<p>Mail Queues are Mailboxes that can hold several messages in a FIFO queue. Indeed, a Mail Queue with a size of 1 will behave as a Mailbox.</p>
</div>
<div class="paragraph data-line-1699">
<p>The programmer must provide a buffer to hold N message addresses for a queue. The main primitives for queues are <code>post(), pend(), peek(), and jam().</code></p>
</div>
<div class="paragraph data-line-1701">
<p><em>Peek</em> reads the queue front message without extracting it, and <em>Jam</em> places a message on the queue front so that this message will be <em>Last-In-First-Out</em>.</p>
</div>
<div class="paragraph data-line-1703">
<p>Mails will be enqueued in a FIFO order (except when using <code>jam()</code>).</p>
</div>
<div class="admonitionblock note data-line-1706">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph data-line-1707">
<p>A single-slot Queue behaves as a Mailbox. Still Mailboxes are provided as a distinct service from Queues because a Queue Control Block is roughly three times larger than a Mailbox, plus Queue methods are considerably heavier. As Mailboxes are extremely handy, providing them as a standalone mechanism allows composing them with other features while keeping Queues disabled entirely.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3 data-line-1710">
<h4 id="usage_example_asynchronous_zero_copy_message_passing">5.2.1. Usage Example: Asynchronous 'Zero-copy' Message Passing</h4>
<div class="paragraph data-line-1712">
<p>Mail Queues purpose is to transmit the pointer of a message that is kept on a memory block. The example below demonstrates its usage.</p>
</div>
<div class="exampleblock data-line-1714">
<div class="content">
<div class="listingblock data-line-1715">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">struct mesg
{
    UINT key;
    const CHAR* string; /* a shallow copy will not get this */
};

#define N_MESG 8
#define MESG_SIZE sizeof(struct mesg)

BYTE mesgPool[N_MESG][MESG_SIZE]; /* pool of mesg buffers */
struct mesg* buf[8]; /* to store addresses */

RK_MEM mem; /* allocator */
RK_QUEUE mqueue; /* queue */

/* for testbench */
const CHAR *messages[8] =
{ "Message 0", "Message 1", "Message 2", "Message 3", "Message 4", "Message 5",
        "Message 6", "Message 7" };

VOID kApplicationInit(VOID)
{
    /* init allocator */
    kMemInit(&amp;mem, (ADDR) mesgPool, MESG_SIZE, N_MESG);
    /* init mailbox */
    kQueueInit(&amp;mqueue, (ADDR) buf, 8);
}
VOID Task1(VOID* args)
{
    RK_UNUSEARGS
    UINT i = 0;
    struct mesg *sendPtr;
    while (1)
    {
        /* allocate buffer */
        sendPtr = NULL;
        /* sendPtr points to a pool mesgPool address */
        sendPtr = (struct mesg*) kMemAlloc(&amp;mem);
        if (sendPtr != NULL)
        {

            sendPtr-&gt;key = i;
            sendPtr-&gt;string = messages[i];
            kprintf("Sending: %s \n\r", sendPtr-&gt;string);
            /* mesgPool address is enqueued */
            kQueuePost(&amp;mqueue, sendPtr, RK_WAIT_FOREVER);
            i += 1;
            i %= 8;
        }
        else
        {
            kYield(); /* no more mesg buffers, yield */
        }
    }
}

VOID Task2(VOID* args)
{
    RK_UNUSEARGS
    struct mesg *recvPtr = NULL;
    while (1)
    {
        kQueuePend(&amp;mqueue, (ADDR*) &amp;recvPtr, RK_WAIT_FOREVER); /* will block when empty */
        kprintf("Received: %s \n\r", recvPtr-&gt;string);
        kBusyDelay(2); /* pretend working */
        kMemFree(&amp;mem, (ADDR) recvPtr); /* free memory */
    }
}</code></pre>
</div>
</div>
<div class="imageblock data-line-1787">
<div class="content">
<img src="images/images/mboxqueue.png" alt="mboxqueue" width="25%">
</div>
</div>
</div>
</div>
<div class="paragraph data-line-1790">
<p>The data scope is managed by allocating a different buffer for every <code>post()</code>, and the receiver is accountable for deallocating the buffer after consuming the message.
The receiver gets an address of a message. The design must guarantee its integrity. After consuming the contents, the receiver frees the memory block.</p>
</div>
<div class="admonitionblock note data-line-1794">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you find yourself having to perform two deep copies&#8201;&#8212;&#8201;<em>producer&#8594;intermediate buffer&#8594;consumer</em>&#8201;&#8212;&#8201;a Stream Queue as below is preferable.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip data-line-1797">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
One or two semaphores, a mutex and a memory allocator implement a mail queue.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2 data-line-1799">
<h3 id="stream_queue">5.3. Stream Queue</h3>
<table class="tableblock frame-all grid-all stretch data-line-1801">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Message Stream Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Read Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Message Block Size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Max of messages</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Message Count</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Owner Task</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-1811">
<p>Streams resemble classic (named) Pipes. The difference is that messages have <em>a fixed size</em>. On the other hand, pipes transmit and receive any number of bytes for each operation.</p>
</div>
<div class="paragraph data-line-1813">
<p>For each Stream, the user provides a buffer address with enough capacity (number of messages <em>x</em> message size). Ther kernel will handle it as a ring buffer.</p>
</div>
<div class="paragraph data-line-1815">
<p>The message size associated with a Message Stream instance is defined on its initialisation. On transmission, a <em>deep copy</em>  of a message from the sender&#8217;s storage to the queue takes place; on reception, it moves from the queue to the receiver&#8217;s storage.</p>
</div>
<div class="admonitionblock note data-line-1818">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Although a message size is associated with a Stream Queue object, the concrete message type depends on the application.
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-1821">
<p>The important primitives for Message Streams are <code>send()</code>, <code>recv()</code>, <code>jam()</code> and <code>peek()</code>.</p>
</div>
<div class="paragraph data-line-1823">
<p>Sending to a full queue (optionally) blocks the sender. Likewise, receiving from an empty queue.</p>
</div>
<div class="sect3 data-line-1825">
<h4 id="stream_message_size">5.3.1. Stream Message-Size</h4>
<div class="paragraph data-line-1827">
<p><strong>Stream Queues must have <em>fixed</em> message-sizes multiples of a <em>WORD</em>. Besides, they must be a power-of-two: 1, 2, 4, 8, 16, 32&#8230;&#8203; (words).</strong></p>
</div>
<div class="paragraph data-line-1829">
<p><em>RK0</em> does not establish an upper bound, although I would say that a good cap is 8 words for the regular <em>RK0</em> target. One has to experiment, though. If a message becomes too large it is introducing prohibitive latency, the user needs to transmit the message address - i.e., configure the Stream to carry 1-word message-size.</p>
</div>
<div class="paragraph data-line-1831">
<p>Establishing power-of-two word-aligned sizes speeds up the copy, achieves more deterministic behaviour, improves run-time safety and simplifies debugging—all good reasons.</p>
</div>
<div class="admonitionblock tip data-line-1834">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="ulist data-line-1836">
<ul>
<li class="data-line-1836">
<p>Load/Store instructions are optimised to fetch 32-bit words. If message size (and addresses) are bounded on a 4-byte boundary, these operations can be executed in a single cycle.</p>
</li>
<li class="data-line-1838">
<p>Misaligned memory makes castings unsafe, leading to complex faults, performance penalties or undefined behaviour.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-1841">
<p>Code-wise, we optimise using pointer arithmetics on pointer to words:</p>
</div>
<div class="listingblock data-line-1843">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">/* Optimised deep copy; guaranteed mesgSize&gt;0 */
/* destPtr and srcPtr are pointers to a word */
#define RK_CPY(destPtr, srcPtr, mesgSize) \
do {                                   \
      while (--mesgSize)               \
      {                                \
     /* if mesgSize is 1, this is NOT executed */
        *(destPtr++) = *(srcPtr++)     \
      };                               \
     /* the last or the only copy is executed now */
     *(destPtr++) = *(srcPtr++)       \
     DMB \ /* ensure completeness  */
   } while(0U)</code></pre>
</div>
</div>
</div>
<div class="sect3 data-line-1860">
<h4 id="usage_example_averaging_sensor_values">5.3.2. Usage Example: Averaging Sensor Values</h4>
<div class="paragraph data-line-1862">
<p>Below is an illustrative snippet of a <em>Queueing Pattern</em>.</p>
</div>
<div class="paragraph data-line-1864">
<p>The goal is to calculate the average value of 4 types of sensors.</p>
</div>
<div class="paragraph data-line-1866">
<p>Here is convienient to highlight an important aspect&#8201;&#8212;&#8201;given its reactive nature, real-time system software is typically <em>I/O bounded</em>, tasks that are sensitive to I/O activity have higher priority than <em>CPU-bounded</em> tasks, i.e., those processing data.</p>
</div>
<div class="paragraph data-line-1868">
<p>A task receives measured sensor values from an ISR on a periodic rate. (The ISR is emulated by a Soft Timer).</p>
</div>
<div class="paragraph data-line-1870">
<p>Then it enqueues this data to a consumer - that will process the average value for each of 4 sensors.</p>
</div>
<div class="paragraph data-line-1872">
<p>The inter-task communication is designed as follows:</p>
</div>
<div class="olist arabic data-line-1874">
<ol class="arabic">
<li class="data-line-1874">
<p>The producer pends on a Mailbox that ISR posts to.</p>
</li>
<li class="data-line-1876">
<p>The data extracted from the Mailbox is placed on a queue that has the processing task as the consumer.</p>
</li>
<li class="data-line-1878">
<p>As the producer priority must be higher than the consumer, eventually the queue will get full.</p>
</li>
<li class="data-line-1880">
<p>The first enqueued item is received by the consumer; then it pends on its private binary semaphore, when the dequeue operation results on an empty queue error.</p>
</li>
<li class="data-line-1882">
<p>From now on, the consumer will only be activated when the queue is full - the producer checks the number of items within the queue and signals the consumer.</p>
</li>
<li class="data-line-1884">
<p>This is done with a purpose: the consumer will use the inactive producer time to offload the queue and process the average value.</p>
</li>
</ol>
</div>
<div class="paragraph data-line-1886">
<p>Here the queue size was set as 8 items. This is an arbritrary value; the optimal queue size would take into account the producer-consumer ratio and the worst execution time of both.</p>
</div>
<div class="exampleblock data-line-1889">
<div class="content">
<div class="listingblock data-line-1890">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c hljs" data-lang="c">/* sensor types */
struct sensorMsg
{
    SensorType_t sensorType;
    ULONG sensorValue;

};

typedef struct sensorMsg Mesg_t;

#define N_MESSAGE 8
#define MESSAGE_SIZE (sizeof(Mesg_t))/4 /* WORDS! */
#define N_SENSOR    4
#define AVG_WINDOW_SIZE   10 /* 10 samples */

RK_STREAM sensorStream;/* the stream kobject */
Mesg_t mesgBuf[N_MESSAGE] = {0};/* queue buffer */
RK_TIMER timerT1;
RK_MBOX sensorBox;
static Mesg_t sample = {0};
static UINT sampleErr;
VOID callBackISR( VOID *args)
{
    RK_UNUSEARGS
    sample.sensorType = (rand() % 4) + 1;
    switch (sample.sensorType)
    {
        case TEMPERATURE:
            sample.sensorValue = ( ULONG) rand() % 50;
            break;
        case HUMIDITY:
            sample.sensorValue = ( ULONG) rand() % 100;
            break;
        case CO2:
            sample.sensorValue = ( ULONG) rand() % 1000;
            break;
        case FLOW:
            sample.sensorValue = ( ULONG) rand() % 10;
            break;
        default:
            break;
    }
    RK_ERR err = kMboxPost( &amp;sensorBox, &amp;sample, RK_NO_WAIT);
    if (err != RK_SUCCESS)
        sampleErr ++;

}

VOID kApplicationInit( VOID)
{
    RK_ERR err = kStreamInit( &amp;sensorStream, ( ADDR) mesgBuf, MESSAGE_SIZE,
    N_MESSAGE);
    kassert( err==RK_SUCCESS);
    err = kTimerInit( &amp;timerT1, 3, 3, callBackISR, NULL, RK_TIMER_RELOAD);
    kassert( err==RK_SUCCESS);
    err = kMboxInit( &amp;sensorBox, NULL);
    kassert( err==RK_SUCCESS);
}

VOID ProducerTask( VOID *args)
{
    RK_UNUSEARGS
    Mesg_t *recvSample = NULL;
    while (1)
    {
        RK_ERR errmbox = kMboxPend( &amp;sensorBox, ( ADDR*) &amp;recvSample,
                RK_WAIT_FOREVER);
        kassert( errmbox==RK_SUCCESS);
        ULONG nMesg = kStreamQuery( &amp;sensorStream);
        if (nMesg &lt;= N_MESSAGE - 1)
        {
            RK_ERR err = kStreamSend( &amp;sensorStream, &amp;sample, RK_NO_WAIT);
/* fill up queue and signal consumer task */
            if (err == RK_SUCCESS)
            {
                CHAR const *sensorTypeStr = NULL;
                if (recvSample-&gt;sensorType == 1)
                    sensorTypeStr = "TEMP";
                if (recvSample-&gt;sensorType == 2)
                    sensorTypeStr = "HUM";
                if (recvSample-&gt;sensorType == 3)
                    sensorTypeStr = "CO2";
                if (recvSample-&gt;sensorType == 4)
                    sensorTypeStr = "FLOW";

                RK_TICK_DIS
                kprintf( "ENQ: [@%lu, %s, %lu] \n\r", kTickGet(), sensorTypeStr,
                        recvSample-&gt;sensorValue);
                RK_TICK_EN
            }
        }
        else
        {
            kSignal( task2Handle);
        }
    }
}

/* for each sensor:
 . a ring buffer of AVG_WINDOW_SIZE values
 . sum of values
 . an index table (=enum - 1 eg., HUMIDITY IDX=2-1=1)
 */
static ULONG ringBuf[N_SENSOR][AVG_WINDOW_SIZE];
static ULONG ringSum[N_SENSOR] = {0};
static UINT ringIndex[N_SENSOR] = {0};

void ConsumerTask( void *args)
{

    RK_UNUSEARGS
    Mesg_t readSample;
    while (1)
    {

        RK_ERR err = kStreamRecv( &amp;sensorStream, ( ADDR) &amp;readSample,
        RK_NO_WAIT);
        if (err == RK_SUCCESS)
        {
            UINT sensorIdx = readSample.sensorType - 1;

/* remove oldest sample */
            ULONG oldest = ringBuf[sensorIdx][ringIndex[sensorIdx]];
            ringSum[sensorIdx] -= oldest;

/* push new sample */
            ringBuf[sensorIdx][ringIndex[sensorIdx]] = readSample.sensorValue;
            ringSum[sensorIdx] += readSample.sensorValue;

/* index incr-wrap */
            ringIndex[sensorIdx] ++;
            ringIndex[sensorIdx] %= AVG_WINDOW_SIZE;

/* simple average */
            ULONG avg = ringSum[sensorIdx] / AVG_WINDOW_SIZE;

/* we disable tick to display */
            RK_TICK_DIS

            CHAR const *sensorTypeStr = NULL;
            if (readSample.sensorType == 1)
                sensorTypeStr = "TEMP";
            if (readSample.sensorType == 2)
                sensorTypeStr = "HUM";
            if (readSample.sensorType == 3)
                sensorTypeStr = "CO2";
            if (readSample.sensorType == 4)
                sensorTypeStr = "FLOW";

            kprintf( "DEQ: [@%lu, %s, %lu] | AVG: %lu \n\r", kTickGet(),
                    sensorTypeStr, readSample.sensorValue, avg);

            RK_TICK_EN

        }
        else
        {

             kPend( RK_WAIT_FOREVER);

        }
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="imageblock data-line-2057">
<div class="content">
<img src="images/images/streamqueue.png" alt="streamqueue" width="30%">
</div>
</div>
</div>
<div class="sect3 data-line-2061">
<h4 id="summing_up_stream_queues_vs_mail_queues">5.3.3. Summing Up: Stream Queues vs Mail Queues</h4>
<div class="paragraph data-line-2063">
<p>While both are Message Queues, they are distinct designs that lead to distinct ideal use cases. Note that Mail Queues are particularly difficult to generalise.</p>
</div>
<table class="tableblock frame-all grid-all stretch data-line-2066">
<colgroup>
<col style="width: 30%;">
<col style="width: 35%;">
<col style="width: 35%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Feature</th>
<th class="tableblock halign-left valign-top">Mail Queue (Pointer-Based)</th>
<th class="tableblock halign-left valign-top">Stream Queue (Deep Copy-Based)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Message Storage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stores <strong>pointers</strong> to messages</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stores <strong>deep copies</strong> of messages</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Message Size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If not pointer-sized,  application-dependent.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fixed (defined at queue initialisation)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Memory Management</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Internal pre-allocated (1 pointer/message). Might need a second storage.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Internal (pre-allocated buffer, N-words/message).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Ownership</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sender/receiver manage lifecycle</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kernel.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Performance</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A 'zero-copy' transmission is faster.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Deterministic. Kernel Optimised deep-copy.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Best Use Case</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Variable-size ITC (e.g., client-server communication)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real-time data streaming (e.g., sensor pipelines, inter-device communication).</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2 data-line-2077">
<h3 id="message_passing_ownership">5.4. Message Passing ownership</h3>
<div class="admonitionblock tip data-line-2080">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-2081">
<p>Priority Inversion happens on Message-Passing for similar but subtle different reasons from resource sharing.</p>
</div>
<div class="paragraph data-line-2083">
<p><em>Design Choice</em>: add an ownership mechanism for a message passing object&#8201;&#8212;&#8201;a well-defined receiver, so priority propagation can be applied.</p>
</div>
<div class="paragraph data-line-2085">
<p>Benefit: This preserves strict real-time guarantees, making sure a high-priority task never waits indefinitely for a lower-priority task to finish message operations</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-2088">
<p>Using queues to communicate between multiple tasks is chaos. Many senders to many receivers ends up unpredictable. We often want N:1 (senders:receiver, N can be 1). This <em>1</em> makes it easier to reason on the dynamics.</p>
</div>
<div class="paragraph data-line-2090">
<p>On real-time design, we often expect to see blocking <em>send()</em> operations, on 1:1 or N:1 channels - a blocking <em>send()</em> on a 1:N (broadcast) would be very odd.</p>
</div>
<div class="sect3 data-line-2092">
<h4 id="priority_inversion_on_message_passing">5.4.1. Priority Inversion on Message Passing</h4>
<div class="paragraph data-line-2094">
<p>While sharing some similarities, there are subtle differences on blocking on a shared-resource (by blocking on a locked mutex), and blocking on a message passing object.</p>
</div>
<div class="paragraph data-line-2096">
<p><em>Assuming cases we do not want messages to be overwritten</em>, a sender when accessing a queue is acquiring an empty buffer. A receiver is acquiring a full buffer. They are competing for the same object but on different states. Thus, they depend on each other to change the object state.</p>
</div>
<div class="paragraph data-line-2099">
<p>When a sender blocks on a full shared message object, it does not mean there is another writer using the resource; By design it is also unlikely there is a reader blocked on the waiting queue of the object, since every time a write operation completes, any reader blocked on the queue is readied. Whether it is dispatched or not is a scheduler concern. If its priority is higher than the task that has just finished, it will be immediately dispatched. If not, it is enqueued on the ready queue until it is eventually picked.</p>
</div>
<div class="admonitionblock tip data-line-2102">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
This means the problem of priority inversion arises from waiting for the consumer rather than from direct contention among multiple senders.
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-2104">
<p>So if the sender priority is higher, maybe it could be propagated to the reader. But, <em>which</em> reader? (This is the reason semaphores cannot implement priority inheritance protocol&#8201;&#8212;&#8201;the waiter task cannot a know potential signaller).</p>
</div>
<div class="paragraph data-line-2106">
<p>With that in mind, there is the option to set <em>ownership</em>: <code>setowner(mesgpass, taskhandle)</code>. From now own, only the owner task can receive from that service object&#8201;&#8212;&#8201;a blocking <code>send()</code> knows the the target task and can raise its priority.</p>
</div>
<div class="paragraph data-line-2108">
<p>(As 1:N communication normally non-blocking on real-time systems, there is no mechanism to establish 'sender ownership'.)</p>
</div>
<div class="paragraph data-line-2110">
<p>If other task that not the owner tries to receive from a kernel message-passing object that has an owner, it fails.</p>
</div>
<div class="paragraph data-line-2112">
<p>These kernel objects now will <em>resemble an aspect of Ports</em> - a common way of representing tasks on <em>message-passsing kernels</em>. (Strictly they are not Ports,  as RK0 is not a message-passing kernel - although I do like the approach.)</p>
</div>
</div>
</div>
<div class="sect2 data-line-2115">
<h3 id="most_recent_message_protocol_mrm">5.5. Most-Recent Message Protocol (MRM)</h3>
<table class="tableblock frame-all grid-all stretch data-line-2118">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">MRM Control Block</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MRM Buffer Allocator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Buffer Allocator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Current MRM Buffer Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Size (Message Size)</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch data-line-2127">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">MRM Buffer</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Buffer Address</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Readers Count</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch data-line-2135">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Data Buffer</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>Application-dependent</em></p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock tip data-line-2141">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph data-line-2142">
<p>There is not much of a practical difference between a message that does not arrive and one with no useful (stale) data. But when wrong (or stale) data is processed - e.g., to define a set point on a loop - a system can fail badly.</p>
</div>
<div class="paragraph data-line-2144">
<p>Design Choice: provide a broadcast asynchronous message-passing scheme that guarantees data freshness and integrity for all readers.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph data-line-2147">
<p>Control loops reacting to unpredictable time events - like a robot scanning an environment or a drive-by-wire system - require a different message-passing approach - readers cannot "look at the past" and cannot block. The most recent data must be delivered lock-free and have guaranteed integrity.</p>
</div>
<div class="sect3 data-line-2149">
<h4 id="functional_description">5.5.1. Functional Description</h4>
<div class="paragraph data-line-2151">
<p>An <em>MRM</em> works as a <em>1-to-many asynchronous Mailbox</em> - with a lock-free specialisation that enables several readers to get the most recent deposited message with no integrity issues. Whenever a reader reads an MRM buffer, it will find the most recent data transmitted (which also implies always finding data).
A writer will always have a buffer to deposit a message.</p>
</div>
<div class="paragraph data-line-2154">
<p>The core idea on he MRM protocol is that readers can only access the buffer that is classified as the '<em>the most recent buffer</em>'. After a writer <em>publish()</em> a message, that will be the only message readers can <em>get()</em>&#8201;&#8212;&#8201;any former message being processed by a reader, was grabbed <em>before</em> a new <em>publish()</em> - and, from now on can only be <em>unget()</em>.</p>
</div>
<div class="paragraph data-line-2156">
<p>To clarify further, the communication steps are listed:</p>
</div>
<div class="olist arabic data-line-2158">
<ol class="arabic">
<li class="data-line-2158">
<p>A producer first reserves an MRM Buffer - the reserved MRM Buffer is not available for reading until it is published.</p>
</li>
<li class="data-line-2160">
<p>A message is copyied into the MRM Buffer and the buffer is <em>published</em>. From now on, it is <em>the most recent buffer</em>. The former published message is no longer visibile for new readers.</p>
</li>
<li class="data-line-2162">
<p>A reader starts by <em>getting</em> an MRM Buffer.  A <code>get()</code> operation delivers a copy of the message to the reader&#8217;s scope and a pointer to the buffer where the message is. Importantly, this operation increases the number of readers associated to that MRM Buffer.</p>
</li>
<li class="data-line-2164">
<p>Before ending its cycle, the task releases (<code>unget()</code>) the buffer; on releasing, the kernel checks if the caller task <em>is the last reader</em>, <em>and</em> if it is <em>not the current MRM Buffer</em>.</p>
</li>
<li class="data-line-2166">
<p>If the above conditions are met, the the <code>unget()</code> operation will cause return the buffer to the pool. If there are more readers OR it is the current buffer, it remains as available for new readers, until the writer issues a <code>reserve()</code>.</p>
</li>
<li class="data-line-2168">
<p>When <code>reserve</code> operation detects the most recent buffer still has readers - a new buffer is allocated to be written and published.</p>
</li>
<li class="data-line-2170">
<p>As explained, whenever a new message is published, the former buffer is no longer visibile for new reader, and eventually drops to 0 readers - when it will be returned to the pool by an <code>unget()</code> operation.</p>
</li>
</ol>
</div>
</div>
<div class="sect3 data-line-2172">
<h4 id="mrm_control_block_configuration">5.5.2. MRM Control Block Configuration</h4>
<div class="paragraph data-line-2175">
<p>What might lead to some confusion when initialising an MRM Control Block is the need for two different pools:</p>
</div>
<div class="ulist data-line-2177">
<ul>
<li class="data-line-2177">
<p>One pool will be the storage for the MRM Buffers - a structure that stores the <em>address on which the data representing a message is</em>, plus the number of readers attached to that message.</p>
</li>
<li class="data-line-2179">
<p>Another pool is for the message itself, which is the buffer that will keep the raw message data. Let&#8217;s call it <em>data buffers</em>.</p>
</li>
<li class="data-line-2181">
<p>Both pools have the same number of elements: the number of tasks communicating + 1.</p>
</li>
<li class="data-line-2183">
<p>The size of the data buffers is application-dependent - and is passed as a number of <em>words</em>. The minimal message size is 32-bit.</p>
</li>
<li class="data-line-2185">
<p>If using data structures, keep it aligned to 4 to take advantage of the performance of aligned memory.</p>
</li>
</ul>
</div>
</div>
<div class="sect3 data-line-2188">
<h4 id="usage_example_2">5.5.3. Usage Example</h4>
<div class="paragraph data-line-2190">
<p>Consider a modern car - speed variations are of interest in many modules. With a somehow "naive" approach, let us consider three modules and how they should react when speed varies:</p>
</div>
<div class="olist arabic data-line-2192">
<ol class="arabic">
<li class="data-line-2192">
<p><strong>Cruise Control:</strong> For the Cruise Control, a speed increase might signify the driver wants manual control back, and it will likely turn off.</p>
</li>
<li class="data-line-2194">
<p><strong>Windshield Wipers:</strong> If they are on, a speed change can reflect on the electric motor&#8217;s adjustments to the air resistance.</p>
</li>
<li class="data-line-2196">
<p><strong>Radio:</strong> Speed changes reflect the aerodynamic noise - the radio volume might need adjustment.</p>
</li>
</ol>
</div>
<div class="paragraph data-line-2198">
<p>As the variations are unpredictable, we need a mechanism to deliver the last speed in order of importance for all these modules. From highest to lowest priority, Cruise, Whipers, and Radio are the three modules that range from safety to comfort.</p>
</div>
<div class="paragraph data-line-2200">
<p>To emulate this scenario, we can write an application with a higher priority task that sleeps and wakes up at pseudo-random times to produce random values that represent the (unpredictable) speed changes.</p>
</div>
<div class="paragraph data-line-2202">
<p>We assume readers are periodic - as on most control loops - with a priority that decreases with its period increase. This is represented in the snippet below.</p>
</div>
<div class="paragraph data-line-2204">
<p><em>Callout Timers</em> are used to periodically <code>post()</code> to a listener&#8217;s private semaphore, releasing the task that started blocked on it. The snippet does nothing besides printing its current pair <em>(last read speed, time when it was read)</em>.</p>
</div>
<div class="exampleblock data-line-2207">
<div class="content">
<div class="listingblock data-line-2209">
<div class="content">
<pre class="highlightjs highlight"><code class="language-C hljs" data-lang="C">#define N_MRM (5)        /* Number of MRMs N Tasks + 1 */
#define MRM_MESG_SIZE (2) /* In WORDS */

RK_MRM MRMCtl;/* MRM control block */

RK_MRM_BUF buf[N_MRM];/* MRM pool */

UINT data[MRM_MESG_SIZE][N_MRM];/* message data pool */

RK_TIMER timerT2;
RK_TIMER timerT3;
RK_TIMER timerT4;

VOID kApplicationInit( VOID)
{
    kMRMMemInit( &amp;MRMCtl, buf, data, N_MRM, MRM_MESG_SIZE);

}

/* timers callbacks */
VOID callbackT2( VOID *args)
{
    RK_UNUSEARGS
    kSignal( task2Handle);
}

VOID callbackT3( VOID *args)
{
    RK_UNUSEARGS
    kSignal( task3Handle);
}
VOID callbackT4( VOID *args)
{
    RK_UNUSEARGS
    kSignal( task4Handle);
}

VOID Task1( VOID *args)
{
    RK_UNUSEARGS
    UINT write[2];
    while (1)
    {

        RK_TICK sleepTicks = (( RK_TICK) rand() % 14) + 1;
        kSleepUntil( sleepTicks);

        UINT currTick = kTickGet();
        UINT speedValue = ( UINT) rand() % 170;
        write[1] = currTick;
        write[0] = speedValue;
/* grab a buffer */
        RK_MRM_BUF *bufPtr =  kMRMReserve( &amp;MRMCtl);
        if (bufPtr != NULL)
        {
            kMRMPublish( &amp;MRMCtl, bufPtr, write);
        }
        else
        {/* cannot fail */
            kassert( 0);
        }
/* publish  */
        kprintf( "! @ %uT: SPEED UPDATE: %u \n\r", currTick, speedValue);

    }
}

void Task2( void *args)
{
    RK_UNUSEARGS
    UINT read[2];
/* parms: timer, phase delay, period, callout function, args,
     RELOAD/ONESHOT */
    kTimerInit( &amp;timerT2, 0, 3, callbackT2, NULL, RK_TIMER_RELOAD);
    while (1)
    {
        SLEEP: /* pend on its own semaphore */
        kPend( RK_WAIT_FOREVER);
/* copy the current buffer data to read and return its address */
        RK_MRM_BUF *readBuf = kMRMGet( &amp;MRMCtl, read);
        if (readBuf == NULL)
        {
            goto SLEEP;
        }
/* use read[] to process the contents */
        kprintf( "@ %luT CRUISE: (%u, %uT) \n\r", kTickGet(), read[0], read[1]);
/* use the buffer address to release the buffer */
        kMRMUnget( &amp;MRMCtl, readBuf);

    }
}

VOID Task3( VOID *args)
{
    RK_UNUSEARGS
    UINT read[2];
/* parms: timer, phase delay, period, callout function, args,
       RELOAD/ONESHOT */
    kTimerInit( &amp;timerT3, 0, 5, callbackT3, NULL, RK_TIMER_RELOAD);
    while (1)
    {
        SLEEP: /* pend on its own semaphore */
        kPend( RK_WAIT_FOREVER);
/* copy the current buffer data to read and return its address */
        RK_MRM_BUF *readBuf = kMRMGet( &amp;MRMCtl, read);
        if (readBuf == NULL)
        {
            goto SLEEP;
        }
        kprintf( "@ %luT WHIPERS: (%u, %uT) \n\r", kTickGet(), read[0], read[1]);
        kMRMUnget( &amp;MRMCtl, readBuf);/* release buffer */

    }
}
VOID Task4( VOID *args)
{
    RK_UNUSEARGS
    UINT read[2];
/* parms: timer, phase delay, period, callout function, args,
       RELOAD/ONESHOT */
    kTimerInit( &amp;timerT4, 0, 7, callbackT4, NULL, RK_TIMER_RELOAD);
    while (1)
    {
        SLEEP: /* pend on its own semaphore */
        kPend( RK_WAIT_FOREVER);
/* copy the current buffer data to read and return its address */
        RK_MRM_BUF *readBuf = kMRMGet( &amp;MRMCtl, read);
        if (readBuf == NULL)
        {
            goto SLEEP;
        }
        kprintf( "@ %luT RADIO: (%u, %uT) \n\r", kTickGet(), read[0], read[1]);
        kMRMUnget( &amp;MRMCtl, readBuf);/* release the buffer */
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph data-line-2349">
<p>As the speed update interval is randomly chosen in the range [1,14], when an update happens, we expect to see the following cases:</p>
</div>
<div class="ulist data-line-2351">
<ul>
<li class="data-line-2351">
<p>All tasks read the updated pair (speed, time)</p>
</li>
<li class="data-line-2352">
<p>Not all tasks receive the updated pair because another update happens in between.</p>
</li>
<li class="data-line-2353">
<p>No tasks receive an update - because another happens too soon.</p>
</li>
<li class="data-line-2354">
<p>All tasks receive an update and will keep rereading the same values - because another update takes longer than the task period.</p>
</li>
</ul>
</div>
<div class="paragraph data-line-2356">
<p>All these cases are on the image of what was printed on a terminal:</p>
</div>
<div class="imageblock data-line-2358">
<div class="content">
<img src="images/images/pumpdrop.png" alt="pumpdrop" width="30%">
</div>
</div>
<div class="paragraph data-line-2360">
<p><em>PS: MRMs are found as 'CABs' (Cyclical Asynchronous Buffers) in the HARTIK Operating System (Buttazzo, 1993)</em>.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-2362">
<h2 id="what_is_missing">6. <strong>What is missing</strong></h2>
<div class="sectionbody">
<div class="paragraph data-line-2364">
<p>Near-future:</p>
</div>
<div class="ulist data-line-2366">
<ul>
<li class="data-line-2366">
<p>Feature-wise:</p>
<div class="ulist data-line-2367">
<ul>
<li class="data-line-2367">
<p>Profiling/Tracing/Information features as services;</p>
</li>
<li class="data-line-2368">
<p>Some special operations on the already provided services as flushing queues, stop for timers;</p>
</li>
</ul>
</div>
</li>
<li class="data-line-2370">
<p>Documentation</p>
<div class="ulist data-line-2371">
<ul>
<li class="data-line-2371">
<p>Demonstrate Error Recovery approaches;</p>
</li>
<li class="data-line-2372">
<p>Elaborate on feature overlap and guidelines for selecting the feature-set;</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<hr>
<div class="imageblock text-center data-line-2378">
<div class="content">
<img src="images/images/mascott.png" alt="mascott" width="10%">
</div>
</div>
<div class="paragraph data-line-2380">
<p>&#169; <em>2025 Antonio Giacomelli | All Rights Reserved | <a href="http://kernel0.org/">www.kernel0.org</a></em></p>
</div>
</div>
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
</body>
</html>
